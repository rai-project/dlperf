{
  "context": {
    "date": "2019-10-13 17:20:11",
    "executable": "./scope",
    "num_cpus": 8,
    "mhz_per_cpu": 3601,
    "cpu_scaling_enabled": true,
    "caches": [
      {
        "type": "Data",
        "level": 1,
        "size": 32000000,
        "num_sharing": 1
      },
      {
        "type": "Instruction",
        "level": 1,
        "size": 32000000,
        "num_sharing": 1
      },
      {
        "type": "Unified",
        "level": 2,
        "size": 1024000000,
        "num_sharing": 1
      },
      {
        "type": "Unified",
        "level": 3,
        "size": 11264000000,
        "num_sharing": 8
      }
    ],
    "library_build_type": "release"
  },
  "benchmarks": [
    {
      "name": "LAYER_CUBLAS_GEMM_FWD_TENSORCOREHALF__BatchSize_32__11956895750046217564/input[0]:32/input[1]:1000/input[2]:2048/input[3]:0/input[4]:1/input[5]:1/input[6]:1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 31428,
      "real_time": 2.2211236877769628e+04,
      "cpu_time": 2.8093324646811281e+04,
      "time_unit": "ns",
      "items_per_second": 2.9505785904967974e+12,
      "K": 2.0480000000000000e+03,
      "M": 3.2000000000000000e+01,
      "N": 1.0000000000000000e+03,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemm_fwd.cpp": 7.2770906096155412e+18,
      "benchmark_func:void iLAYER_CUBLAS_GEMM_FWD_Impl(benchmark::State&) [with T = __half]": 1.8015355583317387e+19,
      "beta": 1.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMM_FWD_Impl": 1.7610984762236383e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0000000000000000e+03,
      "input[2]": 2.0480000000000000e+03,
      "input[3]": 0.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": 1.0000000000000000e+00,
      "input[6]": 1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "lda": 3.2000000000000000e+01,
      "ldb": 1.0000000000000000e+03,
      "num_iterations": 3.1428000000000000e+04,
      "predicted_flops": 5.9011571809935947e+12,
      "predicted_flops_count": 1.3107200000000000e+08,
      "transA": 0.0000000000000000e+00,
      "transB": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_32__7775878044185740217<CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 3531,
      "real_time": 1.9821538552144688e+05,
      "cpu_time": 2.0468203936561864e+05,
      "time_unit": "ns",
      "items_per_second": 1.2960705311758119e+11,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 7.3033908785557658e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 3.5310000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 1.2960705311758119e+11,
      "predicted_flops_count": 2.5690112000000000e+07,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_32__7775878044185740217<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 3525,
      "real_time": 1.9851840347636177e+05,
      "cpu_time": 2.0490162099290080e+05,
      "time_unit": "ns",
      "items_per_second": 1.2940922126174065e+11,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 7.3051544952070380e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 3.5250000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 1.2940922126174065e+11,
      "predicted_flops_count": 2.5690112000000000e+07,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_32__15502269001705697265<CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 12948,
      "real_time": 5.3866304162240514e+04,
      "cpu_time": 6.0043776645041071e+04,
      "time_unit": "ns",
      "items_per_second": 1.1923090139349300e+11,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 7.3033908785557658e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 1.2948000000000000e+04,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 1.1923090139349300e+11,
      "predicted_flops_count": 6.4225280000000000e+06,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_32__15502269001705697265<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 12909,
      "real_time": 5.3942479386992651e+04,
      "cpu_time": 6.0124396467582708e+04,
      "time_unit": "ns",
      "items_per_second": 1.1906252869697881e+11,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 7.3051544952070380e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 1.2909000000000000e+04,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 1.1906252869697881e+11,
      "predicted_flops_count": 6.4225280000000000e+06,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_32__2199439482817643333<CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 12979,
      "real_time": 5.3856814416675057e+04,
      "cpu_time": 6.0047488173198450e+04,
      "time_unit": "ns",
      "items_per_second": 1.1925191026544392e+11,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 7.3033908785557658e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.2979000000000000e+04,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.1925191026544392e+11,
      "predicted_flops_count": 6.4225280000000000e+06,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_32__2199439482817643333<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 12984,
      "real_time": 5.3947567043701478e+04,
      "cpu_time": 6.0119809303749935e+04,
      "time_unit": "ns",
      "items_per_second": 1.1905130021521234e+11,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 7.3051544952070380e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.2984000000000000e+04,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.1905130021521234e+11,
      "predicted_flops_count": 6.4225280000000000e+06,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_32__14236164353165190578<CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 23715,
      "real_time": 2.9518611274421481e+04,
      "cpu_time": 3.5687064516126658e+04,
      "time_unit": "ns",
      "items_per_second": 1.0878777358956010e+11,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 7.3033908785557658e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 2.3715000000000000e+04,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.0878777358956010e+11,
      "predicted_flops_count": 3.2112640000000000e+06,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_32__14236164353165190578<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 23694,
      "real_time": 2.9544290120447724e+04,
      "cpu_time": 3.5735103739338847e+04,
      "time_unit": "ns",
      "items_per_second": 1.0869321912654355e+11,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 7.3051544952070380e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 2.3694000000000000e+04,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.0869321912654355e+11,
      "predicted_flops_count": 3.2112640000000000e+06,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_32__13442301249643377801<CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 3533,
      "real_time": 1.9814475131101967e+05,
      "cpu_time": 2.0455017095952420e+05,
      "time_unit": "ns",
      "items_per_second": 1.2965325515827209e+11,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 7.3033908785557658e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 2.5690112000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 3.5330000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 1.2965325515827209e+11,
      "predicted_flops_count": 2.5690112000000000e+07,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_32__13442301249643377801<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 3528,
      "real_time": 1.9863207116549494e+05,
      "cpu_time": 2.0507128656462423e+05,
      "time_unit": "ns",
      "items_per_second": 1.2933516651797728e+11,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 7.3051544952070380e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 2.5690112000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 3.5280000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 1.2933516651797728e+11,
      "predicted_flops_count": 2.5690112000000000e+07,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_32__258249073022879709<CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 83244,
      "real_time": 8.3665249600144325e+03,
      "cpu_time": 1.4244106049686055e+04,
      "time_unit": "ns",
      "items_per_second": 9.5955728792640228e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 7.3033908785557658e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 8.3244000000000000e+04,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 9.5955728792640228e+10,
      "predicted_flops_count": 8.0281600000000000e+05,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_32__258249073022879709<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 83124,
      "real_time": 8.4074209812358586e+03,
      "cpu_time": 1.4252676928440329e+04,
      "time_unit": "ns",
      "items_per_second": 9.5488973585570251e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 7.3051544952070380e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 8.3124000000000000e+04,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 9.5488973585570251e+10,
      "predicted_flops_count": 8.0281600000000000e+05,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_32__2520991670400452461<CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 6885,
      "real_time": 1.0168067687700862e+05,
      "cpu_time": 1.0789185737111467e+05,
      "time_unit": "ns",
      "items_per_second": 1.2632740452285916e+11,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 7.3033908785557658e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 6.8850000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.2632740452285916e+11,
      "predicted_flops_count": 1.2845056000000000e+07,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_32__2520991670400452461<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 6873,
      "real_time": 1.0183727463209891e+05,
      "cpu_time": 1.0804030467042627e+05,
      "time_unit": "ns",
      "items_per_second": 1.2613314767509758e+11,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 7.3051544952070380e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 6.8730000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.2613314767509758e+11,
      "predicted_flops_count": 1.2845056000000000e+07,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_32__8774762709134234122<CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 23647,
      "real_time": 2.9521662895666592e+04,
      "cpu_time": 3.5704367911346853e+04,
      "time_unit": "ns",
      "items_per_second": 1.0877652831918803e+11,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 7.3033908785557658e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 2.3647000000000000e+04,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 1.0877652831918803e+11,
      "predicted_flops_count": 3.2112640000000000e+06,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_32__8774762709134234122<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 23690,
      "real_time": 2.9565704083061068e+04,
      "cpu_time": 3.5757206711681465e+04,
      "time_unit": "ns",
      "items_per_second": 1.0861449438100186e+11,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 7.3051544952070380e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 2.3690000000000000e+04,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 1.0861449438100186e+11,
      "predicted_flops_count": 3.2112640000000000e+06,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_32__13031967372630854501<CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 39539,
      "real_time": 1.7691144216430606e+04,
      "cpu_time": 2.3869047573287291e+04,
      "time_unit": "ns",
      "items_per_second": 9.0759081513154663e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 7.3033908785557658e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 3.9539000000000000e+04,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 9.0759081513154663e+10,
      "predicted_flops_count": 1.6056320000000000e+06,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_32__13031967372630854501<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 39563,
      "real_time": 1.7688342112183407e+04,
      "cpu_time": 2.3858721633845966e+04,
      "time_unit": "ns",
      "items_per_second": 9.0773459141434738e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 7.3051544952070380e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 3.9563000000000000e+04,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 9.0773459141434738e+10,
      "predicted_flops_count": 1.6056320000000000e+06,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ADD_TENSOR_TENSORCOREHALF__BatchSize_32__8939760817463535564/input[0]:32/input[1]:128/input[2]:28/input[3]:28/bias[0]:1/bias[1]:128/bias[2]:1/bias[3]:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 16849,
      "real_time": 4.1546485406554719e+04,
      "cpu_time": 4.7726315567683610e+04,
      "time_unit": "ns",
      "items_per_second": 7.7293276881932465e+10,
      "a_desc_0": 1.0000000000000000e+00,
      "a_desc_1": 1.2800000000000000e+02,
      "a_desc_2": 1.0000000000000000e+00,
      "a_desc_3": 1.0000000000000000e+00,
      "alpha": 0.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_add_tensor.cpp": 1.5707289175264150e+19,
      "benchmark_func:void iLAYER_CUDNN_ADD_TENSOR_Impl(benchmark::State&) [with T = __half]": 1.3682207389025487e+19,
      "beta": 0.0000000000000000e+00,
      "bias[0]": 1.0000000000000000e+00,
      "bias[1]": 1.2800000000000000e+02,
      "bias[2]": 1.0000000000000000e+00,
      "bias[3]": 1.0000000000000000e+00,
      "c_desc_0": 3.2000000000000000e+01,
      "c_desc_1": 1.2800000000000000e+02,
      "c_desc_2": 2.8000000000000000e+01,
      "c_desc_3": 2.8000000000000000e+01,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ADD_TENSOR_Impl": 1.3211678748143176e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_tensor_layout": 0.0000000000000000e+00,
      "num_iterations": 1.6849000000000000e+04,
      "output_tensor_layout": 0.0000000000000000e+00,
      "predicted_flops": 7.7293276881932465e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ADD_TENSOR_TENSORCOREHALF__BatchSize_32__12001942720075412857/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/bias[0]:1/bias[1]:2048/bias[2]:1/bias[3]:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 16857,
      "real_time": 4.1543566508218173e+04,
      "cpu_time": 4.7707337960489902e+04,
      "time_unit": "ns",
      "items_per_second": 7.7298707595669373e+10,
      "a_desc_0": 1.0000000000000000e+00,
      "a_desc_1": 2.0480000000000000e+03,
      "a_desc_2": 1.0000000000000000e+00,
      "a_desc_3": 1.0000000000000000e+00,
      "alpha": 0.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_add_tensor.cpp": 1.5707289175264150e+19,
      "benchmark_func:void iLAYER_CUDNN_ADD_TENSOR_Impl(benchmark::State&) [with T = __half]": 1.3682207389025487e+19,
      "beta": 0.0000000000000000e+00,
      "bias[0]": 1.0000000000000000e+00,
      "bias[1]": 2.0480000000000000e+03,
      "bias[2]": 1.0000000000000000e+00,
      "bias[3]": 1.0000000000000000e+00,
      "c_desc_0": 3.2000000000000000e+01,
      "c_desc_1": 2.0480000000000000e+03,
      "c_desc_2": 7.0000000000000000e+00,
      "c_desc_3": 7.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ADD_TENSOR_Impl": 1.3211678748143176e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_tensor_layout": 0.0000000000000000e+00,
      "num_iterations": 1.6857000000000000e+04,
      "output_tensor_layout": 0.0000000000000000e+00,
      "predicted_flops": 7.7298707595669373e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ADD_TENSOR_TENSORCOREHALF__BatchSize_32__9332163173461072348/input[0]:32/input[1]:512/input[2]:7/input[3]:7/bias[0]:1/bias[1]:512/bias[2]:1/bias[3]:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 51952,
      "real_time": 1.3459062694344733e+04,
      "cpu_time": 1.9353221723896921e+04,
      "time_unit": "ns",
      "items_per_second": 5.9648730244590469e+10,
      "a_desc_0": 1.0000000000000000e+00,
      "a_desc_1": 5.1200000000000000e+02,
      "a_desc_2": 1.0000000000000000e+00,
      "a_desc_3": 1.0000000000000000e+00,
      "alpha": 0.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_add_tensor.cpp": 1.5707289175264150e+19,
      "benchmark_func:void iLAYER_CUDNN_ADD_TENSOR_Impl(benchmark::State&) [with T = __half]": 1.3682207389025487e+19,
      "beta": 0.0000000000000000e+00,
      "bias[0]": 1.0000000000000000e+00,
      "bias[1]": 5.1200000000000000e+02,
      "bias[2]": 1.0000000000000000e+00,
      "bias[3]": 1.0000000000000000e+00,
      "c_desc_0": 3.2000000000000000e+01,
      "c_desc_1": 5.1200000000000000e+02,
      "c_desc_2": 7.0000000000000000e+00,
      "c_desc_3": 7.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ADD_TENSOR_Impl": 1.3211678748143176e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_tensor_layout": 0.0000000000000000e+00,
      "num_iterations": 5.1952000000000000e+04,
      "output_tensor_layout": 0.0000000000000000e+00,
      "predicted_flops": 5.9648730244590469e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ADD_TENSOR_TENSORCOREHALF__BatchSize_32__1161881935698296473/input[0]:32/input[1]:256/input[2]:14/input[3]:14/bias[0]:1/bias[1]:256/bias[2]:1/bias[3]:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 34293,
      "real_time": 2.0414817550563897e+04,
      "cpu_time": 2.6291040474728012e+04,
      "time_unit": "ns",
      "items_per_second": 7.8650323277351517e+10,
      "a_desc_0": 1.0000000000000000e+00,
      "a_desc_1": 2.5600000000000000e+02,
      "a_desc_2": 1.0000000000000000e+00,
      "a_desc_3": 1.0000000000000000e+00,
      "alpha": 0.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_add_tensor.cpp": 1.5707289175264150e+19,
      "benchmark_func:void iLAYER_CUDNN_ADD_TENSOR_Impl(benchmark::State&) [with T = __half]": 1.3682207389025487e+19,
      "beta": 0.0000000000000000e+00,
      "bias[0]": 1.0000000000000000e+00,
      "bias[1]": 2.5600000000000000e+02,
      "bias[2]": 1.0000000000000000e+00,
      "bias[3]": 1.0000000000000000e+00,
      "c_desc_0": 3.2000000000000000e+01,
      "c_desc_1": 2.5600000000000000e+02,
      "c_desc_2": 1.4000000000000000e+01,
      "c_desc_3": 1.4000000000000000e+01,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ADD_TENSOR_Impl": 1.3211678748143176e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_tensor_layout": 0.0000000000000000e+00,
      "num_iterations": 3.4293000000000000e+04,
      "output_tensor_layout": 0.0000000000000000e+00,
      "predicted_flops": 7.8650323277351517e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ADD_TENSOR_TENSORCOREHALF__BatchSize_32__10497514973730459802/input[0]:32/input[1]:256/input[2]:14/input[3]:14/bias[0]:1/bias[1]:256/bias[2]:1/bias[3]:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 34289,
      "real_time": 2.0420913363224026e+04,
      "cpu_time": 2.6290242935066668e+04,
      "time_unit": "ns",
      "items_per_second": 7.8626845501023422e+10,
      "a_desc_0": 1.0000000000000000e+00,
      "a_desc_1": 2.5600000000000000e+02,
      "a_desc_2": 1.0000000000000000e+00,
      "a_desc_3": 1.0000000000000000e+00,
      "alpha": 0.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_add_tensor.cpp": 1.5707289175264150e+19,
      "benchmark_func:void iLAYER_CUDNN_ADD_TENSOR_Impl(benchmark::State&) [with T = __half]": 1.3682207389025487e+19,
      "beta": 0.0000000000000000e+00,
      "bias[0]": 1.0000000000000000e+00,
      "bias[1]": 2.5600000000000000e+02,
      "bias[2]": 1.0000000000000000e+00,
      "bias[3]": 1.0000000000000000e+00,
      "c_desc_0": 3.2000000000000000e+01,
      "c_desc_1": 2.5600000000000000e+02,
      "c_desc_2": 1.4000000000000000e+01,
      "c_desc_3": 1.4000000000000000e+01,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ADD_TENSOR_Impl": 1.3211678748143176e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_tensor_layout": 0.0000000000000000e+00,
      "num_iterations": 3.4289000000000000e+04,
      "output_tensor_layout": 0.0000000000000000e+00,
      "predicted_flops": 7.8626845501023422e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ADD_TENSOR_TENSORCOREHALF__BatchSize_32__1440331252729579534/input[0]:32/input[1]:64/input[2]:56/input[3]:56/bias[0]:1/bias[1]:64/bias[2]:1/bias[3]:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 9121,
      "real_time": 7.6631319755019504e+04,
      "cpu_time": 8.2792607170273041e+04,
      "time_unit": "ns",
      "items_per_second": 8.3810745013031189e+10,
      "a_desc_0": 1.0000000000000000e+00,
      "a_desc_1": 6.4000000000000000e+01,
      "a_desc_2": 1.0000000000000000e+00,
      "a_desc_3": 1.0000000000000000e+00,
      "alpha": 0.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_add_tensor.cpp": 1.5707289175264150e+19,
      "benchmark_func:void iLAYER_CUDNN_ADD_TENSOR_Impl(benchmark::State&) [with T = __half]": 1.3682207389025487e+19,
      "beta": 0.0000000000000000e+00,
      "bias[0]": 1.0000000000000000e+00,
      "bias[1]": 6.4000000000000000e+01,
      "bias[2]": 1.0000000000000000e+00,
      "bias[3]": 1.0000000000000000e+00,
      "c_desc_0": 3.2000000000000000e+01,
      "c_desc_1": 6.4000000000000000e+01,
      "c_desc_2": 5.6000000000000000e+01,
      "c_desc_3": 5.6000000000000000e+01,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ADD_TENSOR_Impl": 1.3211678748143176e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_tensor_layout": 0.0000000000000000e+00,
      "num_iterations": 9.1210000000000000e+03,
      "output_tensor_layout": 0.0000000000000000e+00,
      "predicted_flops": 8.3810745013031189e+10,
      "predicted_flops_count": 6.4225280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ADD_TENSOR_TENSORCOREHALF__BatchSize_32__7561747596892821011/input[0]:32/input[1]:128/input[2]:28/input[3]:28/bias[0]:1/bias[1]:128/bias[2]:1/bias[3]:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 16814,
      "real_time": 4.1598286943842679e+04,
      "cpu_time": 4.7768207089318348e+04,
      "time_unit": "ns",
      "items_per_second": 7.7197025068248077e+10,
      "a_desc_0": 1.0000000000000000e+00,
      "a_desc_1": 1.2800000000000000e+02,
      "a_desc_2": 1.0000000000000000e+00,
      "a_desc_3": 1.0000000000000000e+00,
      "alpha": 0.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_add_tensor.cpp": 1.5707289175264150e+19,
      "benchmark_func:void iLAYER_CUDNN_ADD_TENSOR_Impl(benchmark::State&) [with T = __half]": 1.3682207389025487e+19,
      "beta": 0.0000000000000000e+00,
      "bias[0]": 1.0000000000000000e+00,
      "bias[1]": 1.2800000000000000e+02,
      "bias[2]": 1.0000000000000000e+00,
      "bias[3]": 1.0000000000000000e+00,
      "c_desc_0": 3.2000000000000000e+01,
      "c_desc_1": 1.2800000000000000e+02,
      "c_desc_2": 2.8000000000000000e+01,
      "c_desc_3": 2.8000000000000000e+01,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ADD_TENSOR_Impl": 1.3211678748143176e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_tensor_layout": 0.0000000000000000e+00,
      "num_iterations": 1.6814000000000000e+04,
      "output_tensor_layout": 0.0000000000000000e+00,
      "predicted_flops": 7.7197025068248077e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ADD_TENSOR_TENSORCOREHALF__BatchSize_32__6631373113392793386/input[0]:32/input[1]:256/input[2]:56/input[3]:56/bias[0]:1/bias[1]:256/bias[2]:1/bias[3]:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2567,
      "real_time": 2.7283854475284787e+05,
      "cpu_time": 2.7960003077535168e+05,
      "time_unit": "ns",
      "items_per_second": 9.4158660841969788e+10,
      "a_desc_0": 1.0000000000000000e+00,
      "a_desc_1": 2.5600000000000000e+02,
      "a_desc_2": 1.0000000000000000e+00,
      "a_desc_3": 1.0000000000000000e+00,
      "alpha": 0.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_add_tensor.cpp": 1.5707289175264150e+19,
      "benchmark_func:void iLAYER_CUDNN_ADD_TENSOR_Impl(benchmark::State&) [with T = __half]": 1.3682207389025487e+19,
      "beta": 0.0000000000000000e+00,
      "bias[0]": 1.0000000000000000e+00,
      "bias[1]": 2.5600000000000000e+02,
      "bias[2]": 1.0000000000000000e+00,
      "bias[3]": 1.0000000000000000e+00,
      "c_desc_0": 3.2000000000000000e+01,
      "c_desc_1": 2.5600000000000000e+02,
      "c_desc_2": 5.6000000000000000e+01,
      "c_desc_3": 5.6000000000000000e+01,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ADD_TENSOR_Impl": 1.3211678748143176e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_tensor_layout": 0.0000000000000000e+00,
      "num_iterations": 2.5670000000000000e+03,
      "output_tensor_layout": 0.0000000000000000e+00,
      "predicted_flops": 9.4158660841969788e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ADD_TENSOR_TENSORCOREHALF__BatchSize_32__14006447847904214747/input[0]:32/input[1]:64/input[2]:56/input[3]:56/bias[0]:1/bias[1]:64/bias[2]:1/bias[3]:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 9125,
      "real_time": 7.6693541915730049e+04,
      "cpu_time": 8.2845493808215659e+04,
      "time_unit": "ns",
      "items_per_second": 8.3742748601401108e+10,
      "a_desc_0": 1.0000000000000000e+00,
      "a_desc_1": 6.4000000000000000e+01,
      "a_desc_2": 1.0000000000000000e+00,
      "a_desc_3": 1.0000000000000000e+00,
      "alpha": 0.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_add_tensor.cpp": 1.5707289175264150e+19,
      "benchmark_func:void iLAYER_CUDNN_ADD_TENSOR_Impl(benchmark::State&) [with T = __half]": 1.3682207389025487e+19,
      "beta": 0.0000000000000000e+00,
      "bias[0]": 1.0000000000000000e+00,
      "bias[1]": 6.4000000000000000e+01,
      "bias[2]": 1.0000000000000000e+00,
      "bias[3]": 1.0000000000000000e+00,
      "c_desc_0": 3.2000000000000000e+01,
      "c_desc_1": 6.4000000000000000e+01,
      "c_desc_2": 5.6000000000000000e+01,
      "c_desc_3": 5.6000000000000000e+01,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ADD_TENSOR_Impl": 1.3211678748143176e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_tensor_layout": 0.0000000000000000e+00,
      "num_iterations": 9.1250000000000000e+03,
      "output_tensor_layout": 0.0000000000000000e+00,
      "predicted_flops": 8.3742748601401108e+10,
      "predicted_flops_count": 6.4225280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ADD_TENSOR_TENSORCOREHALF__BatchSize_32__17385999163747969416/input[0]:32/input[1]:512/input[2]:28/input[3]:28/bias[0]:1/bias[1]:512/bias[2]:1/bias[3]:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4866,
      "real_time": 1.4388027198574317e+05,
      "cpu_time": 1.5015660686400713e+05,
      "time_unit": "ns",
      "items_per_second": 8.9276005825682587e+10,
      "a_desc_0": 1.0000000000000000e+00,
      "a_desc_1": 5.1200000000000000e+02,
      "a_desc_2": 1.0000000000000000e+00,
      "a_desc_3": 1.0000000000000000e+00,
      "alpha": 0.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_add_tensor.cpp": 1.5707289175264150e+19,
      "benchmark_func:void iLAYER_CUDNN_ADD_TENSOR_Impl(benchmark::State&) [with T = __half]": 1.3682207389025487e+19,
      "beta": 0.0000000000000000e+00,
      "bias[0]": 1.0000000000000000e+00,
      "bias[1]": 5.1200000000000000e+02,
      "bias[2]": 1.0000000000000000e+00,
      "bias[3]": 1.0000000000000000e+00,
      "c_desc_0": 3.2000000000000000e+01,
      "c_desc_1": 5.1200000000000000e+02,
      "c_desc_2": 2.8000000000000000e+01,
      "c_desc_3": 2.8000000000000000e+01,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ADD_TENSOR_Impl": 1.3211678748143176e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_tensor_layout": 0.0000000000000000e+00,
      "num_iterations": 4.8660000000000000e+03,
      "output_tensor_layout": 0.0000000000000000e+00,
      "predicted_flops": 8.9276005825682587e+10,
      "predicted_flops_count": 1.2845056000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ADD_TENSOR_TENSORCOREHALF__BatchSize_32__12108164587368163001/input[0]:32/input[1]:512/input[2]:7/input[3]:7/bias[0]:1/bias[1]:512/bias[2]:1/bias[3]:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 51922,
      "real_time": 1.3475453973377074e+04,
      "cpu_time": 1.9398649243109194e+04,
      "time_unit": "ns",
      "items_per_second": 5.9576174694083931e+10,
      "a_desc_0": 1.0000000000000000e+00,
      "a_desc_1": 5.1200000000000000e+02,
      "a_desc_2": 1.0000000000000000e+00,
      "a_desc_3": 1.0000000000000000e+00,
      "alpha": 0.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_add_tensor.cpp": 1.5707289175264150e+19,
      "benchmark_func:void iLAYER_CUDNN_ADD_TENSOR_Impl(benchmark::State&) [with T = __half]": 1.3682207389025487e+19,
      "beta": 0.0000000000000000e+00,
      "bias[0]": 1.0000000000000000e+00,
      "bias[1]": 5.1200000000000000e+02,
      "bias[2]": 1.0000000000000000e+00,
      "bias[3]": 1.0000000000000000e+00,
      "c_desc_0": 3.2000000000000000e+01,
      "c_desc_1": 5.1200000000000000e+02,
      "c_desc_2": 7.0000000000000000e+00,
      "c_desc_3": 7.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ADD_TENSOR_Impl": 1.3211678748143176e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_tensor_layout": 0.0000000000000000e+00,
      "num_iterations": 5.1922000000000000e+04,
      "output_tensor_layout": 0.0000000000000000e+00,
      "predicted_flops": 5.9576174694083931e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ADD_TENSOR_TENSORCOREHALF__BatchSize_32__9785213776875959313/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/bias[0]:1/bias[1]:1024/bias[2]:1/bias[3]:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 9138,
      "real_time": 7.6604263108448111e+04,
      "cpu_time": 8.2788210221060552e+04,
      "time_unit": "ns",
      "items_per_second": 8.3840346990971954e+10,
      "a_desc_0": 1.0000000000000000e+00,
      "a_desc_1": 1.0240000000000000e+03,
      "a_desc_2": 1.0000000000000000e+00,
      "a_desc_3": 1.0000000000000000e+00,
      "alpha": 0.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_add_tensor.cpp": 1.5707289175264150e+19,
      "benchmark_func:void iLAYER_CUDNN_ADD_TENSOR_Impl(benchmark::State&) [with T = __half]": 1.3682207389025487e+19,
      "beta": 0.0000000000000000e+00,
      "bias[0]": 1.0000000000000000e+00,
      "bias[1]": 1.0240000000000000e+03,
      "bias[2]": 1.0000000000000000e+00,
      "bias[3]": 1.0000000000000000e+00,
      "c_desc_0": 3.2000000000000000e+01,
      "c_desc_1": 1.0240000000000000e+03,
      "c_desc_2": 1.4000000000000000e+01,
      "c_desc_3": 1.4000000000000000e+01,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ADD_TENSOR_Impl": 1.3211678748143176e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_tensor_layout": 0.0000000000000000e+00,
      "num_iterations": 9.1380000000000000e+03,
      "output_tensor_layout": 0.0000000000000000e+00,
      "predicted_flops": 8.3840346990971954e+10,
      "predicted_flops_count": 6.4225280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_TENSORCOREHALF__BatchSize_32__8278812176109199559<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 1293,
      "real_time": 5.4151633713316615e+05,
      "cpu_time": 5.5110554833726760e+05,
      "time_unit": "ns",
      "items_per_second": 4.7441065464443146e+10,
      "batch_size": 3.2000000000000000e+01,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.2934699958013073e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.2930000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 4.7441065464443146e+10,
      "predicted_flops_count": 2.5690112000000000e+07,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_TENSORCOREHALF__BatchSize_32__4075642497639528124<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 1015,
      "real_time": 6.8948212804575567e+05,
      "cpu_time": 7.0109085024622909e+05,
      "time_unit": "ns",
      "items_per_second": 3.7260011470950188e+10,
      "batch_size": 3.2000000000000000e+01,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 1.7107992421717466e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.0150000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 3.7260011470950188e+10,
      "predicted_flops_count": 2.5690112000000000e+07,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_TENSORCOREHALF__BatchSize_32__14856908601492901007<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 5179,
      "real_time": 1.3514348545223568e+05,
      "cpu_time": 1.4142881965620592e+05,
      "time_unit": "ns",
      "items_per_second": 4.7523770594698334e+10,
      "batch_size": 3.2000000000000000e+01,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.2934699958013073e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 5.1790000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 4.7523770594698334e+10,
      "predicted_flops_count": 6.4225280000000000e+06,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_TENSORCOREHALF__BatchSize_32__9531304724067703540<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 4118,
      "real_time": 1.7000747447992975e+05,
      "cpu_time": 1.7630377853323694e+05,
      "time_unit": "ns",
      "items_per_second": 3.7777915468994354e+10,
      "batch_size": 3.2000000000000000e+01,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 1.7107992421717466e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.1180000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 3.7777915468994354e+10,
      "predicted_flops_count": 6.4225280000000000e+06,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_TENSORCOREHALF__BatchSize_32__1916338834342405283<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 55055,
      "real_time": 1.2656397965803761e+04,
      "cpu_time": 1.8702932104254211e+04,
      "time_unit": "ns",
      "items_per_second": 6.3431633721468254e+10,
      "batch_size": 3.2000000000000000e+01,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.2934699958013073e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 5.5055000000000000e+04,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.3431633721468254e+10,
      "predicted_flops_count": 8.0281600000000000e+05,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_TENSORCOREHALF__BatchSize_32__5833178058393334488<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 38119,
      "real_time": 1.8376819931330800e+04,
      "cpu_time": 2.4321322017862916e+04,
      "time_unit": "ns",
      "items_per_second": 4.3686339801984566e+10,
      "batch_size": 3.2000000000000000e+01,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 1.7107992421717466e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.8119000000000000e+04,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.3686339801984566e+10,
      "predicted_flops_count": 8.0281600000000000e+05,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_TENSORCOREHALF__BatchSize_32__11781959687368464375<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:32/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 1293,
      "real_time": 5.4149346958056418e+05,
      "cpu_time": 5.5117672853835439e+05,
      "time_unit": "ns",
      "items_per_second": 4.7443068925465195e+10,
      "batch_size": 3.2000000000000000e+01,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.2934699958013073e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 2.5690112000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.2930000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 4.7443068925465195e+10,
      "predicted_flops_count": 2.5690112000000000e+07,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_TENSORCOREHALF__BatchSize_32__16855360851789545868<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:32/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 1015,
      "real_time": 6.8939826542997884e+05,
      "cpu_time": 7.0110868078807823e+05,
      "time_unit": "ns",
      "items_per_second": 3.7264544006325623e+10,
      "batch_size": 3.2000000000000000e+01,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 1.7107992421717466e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 2.5690112000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.0150000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 3.7264544006325623e+10,
      "predicted_flops_count": 2.5690112000000000e+07,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_TENSORCOREHALF__BatchSize_32__15896664485656839884<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 19787,
      "real_time": 3.5373563126189460e+04,
      "cpu_time": 4.1533274119380272e+04,
      "time_unit": "ns",
      "items_per_second": 9.0781468311358276e+10,
      "batch_size": 3.2000000000000000e+01,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.2934699958013073e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.9787000000000000e+04,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 9.0781468311358276e+10,
      "predicted_flops_count": 3.2112640000000000e+06,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_TENSORCOREHALF__BatchSize_32__10878414858853028023<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 12311,
      "real_time": 5.6908339953131850e+04,
      "cpu_time": 6.3048753797353063e+04,
      "time_unit": "ns",
      "items_per_second": 5.6428706278283798e+10,
      "batch_size": 3.2000000000000000e+01,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 1.7107992421717466e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.2311000000000000e+04,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.6428706278283798e+10,
      "predicted_flops_count": 3.2112640000000000e+06,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_TENSORCOREHALF__BatchSize_32__6974791717183811956<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 19770,
      "real_time": 3.5376224464262676e+04,
      "cpu_time": 4.1533960343942032e+04,
      "time_unit": "ns",
      "items_per_second": 9.0774638860742264e+10,
      "batch_size": 3.2000000000000000e+01,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.2934699958013073e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.9770000000000000e+04,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 9.0774638860742264e+10,
      "predicted_flops_count": 3.2112640000000000e+06,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_TENSORCOREHALF__BatchSize_32__3071693065253234447<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 12323,
      "real_time": 5.6904627540715184e+04,
      "cpu_time": 6.3147799480636022e+04,
      "time_unit": "ns",
      "items_per_second": 5.6432387641977715e+10,
      "batch_size": 3.2000000000000000e+01,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 1.7107992421717466e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.2323000000000000e+04,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.6432387641977715e+10,
      "predicted_flops_count": 3.2112640000000000e+06,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_TENSORCOREHALF__BatchSize_32__542880171754594363<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 5178,
      "real_time": 1.3516713782443761e+05,
      "cpu_time": 1.4165465025103488e+05,
      "time_unit": "ns",
      "items_per_second": 4.7515454594754585e+10,
      "batch_size": 3.2000000000000000e+01,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.2934699958013073e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 5.1780000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.7515454594754585e+10,
      "predicted_flops_count": 6.4225280000000000e+06,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_TENSORCOREHALF__BatchSize_32__5612358347407357504<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 4117,
      "real_time": 1.6998753542478546e+05,
      "cpu_time": 1.7660371921310574e+05,
      "time_unit": "ns",
      "items_per_second": 3.7782346711190376e+10,
      "batch_size": 3.2000000000000000e+01,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 1.7107992421717466e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.1170000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 3.7782346711190376e+10,
      "predicted_flops_count": 6.4225280000000000e+06,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_TENSORCOREHALF__BatchSize_32__12526640776588634139<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 33274,
      "real_time": 2.0991650810293137e+04,
      "cpu_time": 2.7181691981715259e+04,
      "time_unit": "ns",
      "items_per_second": 7.6489077229347183e+10,
      "batch_size": 3.2000000000000000e+01,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.2934699958013073e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 3.3274000000000000e+04,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 7.6489077229347183e+10,
      "predicted_flops_count": 1.6056320000000000e+06,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_TENSORCOREHALF__BatchSize_32__16698285184648085088<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 22276,
      "real_time": 3.1405755110233127e+04,
      "cpu_time": 3.7594536092665061e+04,
      "time_unit": "ns",
      "items_per_second": 5.1125406613032753e+10,
      "batch_size": 3.2000000000000000e+01,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 1.7107992421717466e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.2276000000000000e+04,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.1125406613032753e+10,
      "predicted_flops_count": 1.6056320000000000e+06,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_TENSORCOREHALF__BatchSize_32__4319256319147746323<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 2554,
      "real_time": 2.7407481255882751e+05,
      "cpu_time": 2.8137721574015310e+05,
      "time_unit": "ns",
      "items_per_second": 4.6866969934506233e+10,
      "batch_size": 3.2000000000000000e+01,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.2934699958013073e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.5540000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.6866969934506233e+10,
      "predicted_flops_count": 1.2845056000000000e+07,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_TENSORCOREHALF__BatchSize_32__8186062192492769896<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 2004,
      "real_time": 3.4936209548633738e+05,
      "cpu_time": 3.5733676497001247e+05,
      "time_unit": "ns",
      "items_per_second": 3.6767171270022156e+10,
      "batch_size": 3.2000000000000000e+01,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 1.7107992421717466e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.0040000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 3.6767171270022156e+10,
      "predicted_flops_count": 1.2845056000000000e+07,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__18073761722069980106<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 692,
      "real_time": 1.0112254699352978e+06,
      "cpu_time": 1.0319527586706892e+06,
      "time_unit": "ns",
      "items_per_second": 3.0485915670194214e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.0311679840087891e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 4.8168960000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.9200000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "predicted_advised_flops": 3.7345246695987910e+12,
      "predicted_advised_flops_count": 3.7764464640000000e+09,
      "predicted_flops": 3.7345246695987910e+12,
      "predicted_flops_count": 3.7764464640000000e+09,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__18073761722069980106<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 692,
      "real_time": 1.0107317855285556e+06,
      "cpu_time": 1.0313808106936277e+06,
      "time_unit": "ns",
      "items_per_second": 3.0500806288464185e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.8800000000000000e+02,
      "advised_time": 1.0240000486373901e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 4.8168960000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.9200000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "predicted_advised_flops": 3.7363487703368623e+12,
      "predicted_advised_flops_count": 3.7764464640000000e+09,
      "predicted_flops": 3.7363487703368623e+12,
      "predicted_flops_count": 3.7764464640000000e+09,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 5.8800000000000000e+02,
      "workspace_megabytes": 5.6076049804687500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__18073761722069980106<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__18073761722069980106<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__18073761722069980106<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__18073761722069980106<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__18073761722069980106<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__18073761722069980106<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__5562003379773445646<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2744,
      "real_time": 2.5697739723215046e+05,
      "cpu_time": 2.6412096428570105e+05,
      "time_unit": "ns",
      "items_per_second": 1.2796200644173215e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.4985599517822266e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.7440000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.1990501610433037e+12,
      "predicted_advised_flops_count": 8.2208358400000000e+08,
      "predicted_flops": 3.1990501610433037e+12,
      "predicted_flops_count": 8.2208358400000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__5562003379773445646<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 8342,
      "real_time": 8.3665217673134161e+04,
      "cpu_time": 8.9936755813989963e+04,
      "time_unit": "ns",
      "items_per_second": 3.9303481511838836e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 8.8064000010490417e-02,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 8.3420000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 9.8258703779597090e+12,
      "predicted_advised_flops_count": 8.2208358400000000e+08,
      "predicted_flops": 9.8258703779597090e+12,
      "predicted_flops_count": 8.2208358400000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__5562003379773445646<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__5562003379773445646<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__5562003379773445646<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__5562003379773445646<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__5562003379773445646<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__5562003379773445646<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__16223873654537319576<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 896,
      "real_time": 7.8069971089332423e+05,
      "cpu_time": 7.9550699218750815e+05,
      "time_unit": "ns",
      "items_per_second": 1.6848139125028176e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 7.9360002279281616e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 8.9600000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.2120347812570439e+12,
      "predicted_advised_flops_count": 3.2883343360000000e+09,
      "predicted_flops": 4.2120347812570439e+12,
      "predicted_flops_count": 3.2883343360000000e+09,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__16223873654537319576<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2906,
      "real_time": 2.4029324493397868e+05,
      "cpu_time": 2.4725853062629161e+05,
      "time_unit": "ns",
      "items_per_second": 5.4738689585776406e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 2.5190401077270508e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.9060000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.3684672396444102e+13,
      "predicted_advised_flops_count": 3.2883343360000000e+09,
      "predicted_flops": 1.3684672396444102e+13,
      "predicted_flops_count": 3.2883343360000000e+09,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__16223873654537319576<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__16223873654537319576<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__16223873654537319576<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__16223873654537319576<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__16223873654537319576<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__16223873654537319576<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__1660753005502994940<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1211,
      "real_time": 5.7751640968153928e+05,
      "cpu_time": 5.8756395540875511e+05,
      "time_unit": "ns",
      "items_per_second": 2.8469618186375786e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.8777600526809692e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.2110000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.8469618186375786e+12,
      "predicted_advised_flops_count": 1.6441671680000000e+09,
      "predicted_flops": 2.8469618186375786e+12,
      "predicted_flops_count": 1.6441671680000000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__1660753005502994940<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 6664,
      "real_time": 1.0488768761902890e+05,
      "cpu_time": 1.1112771608630581e+05,
      "time_unit": "ns",
      "items_per_second": 1.5675502104421572e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.3001599907875061e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 6.6640000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.5675502104421572e+13,
      "predicted_advised_flops_count": 1.6441671680000000e+09,
      "predicted_flops": 1.5675502104421572e+13,
      "predicted_flops_count": 1.6441671680000000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__1660753005502994940<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__1660753005502994940<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__1660753005502994940<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__1660753005502994940<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__1660753005502994940<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_32__1660753005502994940<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__4185866925177589765<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2331,
      "real_time": 3.0028724203710072e+05,
      "cpu_time": 3.0760175589890720e+05,
      "time_unit": "ns",
      "items_per_second": 1.0950629516234072e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.0208000540733337e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.3310000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.7376573790585181e+12,
      "predicted_advised_flops_count": 8.2208358400000000e+08,
      "predicted_flops": 2.7376573790585181e+12,
      "predicted_flops_count": 8.2208358400000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__4185866925177589765<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 11087,
      "real_time": 6.2438127657374556e+04,
      "cpu_time": 6.8541327681097624e+04,
      "time_unit": "ns",
      "items_per_second": 5.2665485967877438e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 6.4511999487876892e-02,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.1087000000000000e+04,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.3166371491969359e+13,
      "predicted_advised_flops_count": 8.2208358400000000e+08,
      "predicted_flops": 1.3166371491969359e+13,
      "predicted_flops_count": 8.2208358400000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__4185866925177589765<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__4185866925177589765<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__4185866925177589765<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__4185866925177589765<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__4185866925177589765<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__4185866925177589765<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__3934074999474201260<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 555,
      "real_time": 1.2606548392927055e+06,
      "cpu_time": 1.2893878522526328e+06,
      "time_unit": "ns",
      "items_per_second": 3.2605418960721741e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.2974079847335815e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.5500000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 2.9344877064649565e+12,
      "predicted_advised_flops_count": 3.6993761280000000e+09,
      "predicted_flops": 2.9344877064649565e+12,
      "predicted_flops_count": 3.6993761280000000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__3934074999474201260<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 3642,
      "real_time": 1.9210785321655023e+05,
      "cpu_time": 1.9881168067003784e+05,
      "time_unit": "ns",
      "items_per_second": 2.1396407544914900e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 2.3552000522613525e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.6420000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 1.9256766790423410e+13,
      "predicted_advised_flops_count": 3.6993761280000000e+09,
      "predicted_flops": 1.9256766790423410e+13,
      "predicted_flops_count": 3.6993761280000000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__3934074999474201260<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__3934074999474201260<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__3934074999474201260<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__3934074999474201260<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__3934074999474201260<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__3934074999474201260<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__16619618211220476438<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2523,
      "real_time": 2.7741222162535356e+05,
      "cpu_time": 2.8468648156964203e+05,
      "time_unit": "ns",
      "items_per_second": 1.1853602976587350e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.7750399708747864e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.5230000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.9634007441468374e+12,
      "predicted_advised_flops_count": 8.2208358400000000e+08,
      "predicted_flops": 2.9634007441468374e+12,
      "predicted_flops_count": 8.2208358400000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__16619618211220476438<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 12414,
      "real_time": 5.5883577595936884e+04,
      "cpu_time": 6.2117916465248258e+04,
      "time_unit": "ns",
      "items_per_second": 5.8842588063636859e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 5.8368001133203506e-02,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.2414000000000000e+04,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.4710647015909215e+13,
      "predicted_advised_flops_count": 8.2208358400000000e+08,
      "predicted_flops": 1.4710647015909215e+13,
      "predicted_flops_count": 8.2208358400000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__16619618211220476438<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__16619618211220476438<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__16619618211220476438<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__16619618211220476438<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__16619618211220476438<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__16619618211220476438<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__5325725880560223457<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1190,
      "real_time": 5.8647419551990053e+05,
      "cpu_time": 5.9760444537806301e+05,
      "time_unit": "ns",
      "items_per_second": 2.8034774258779976e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.8572798967361450e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.1900000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.8034774258779976e+12,
      "predicted_advised_flops_count": 1.6441671680000000e+09,
      "predicted_flops": 2.8034774258779976e+12,
      "predicted_flops_count": 1.6441671680000000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__5325725880560223457<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 4015,
      "real_time": 1.7384518573471202e+05,
      "cpu_time": 1.8045750485707258e+05,
      "time_unit": "ns",
      "items_per_second": 9.4576514215872578e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 2.1196800470352173e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.0150000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 9.4576514215872578e+12,
      "predicted_advised_flops_count": 1.6441671680000000e+09,
      "predicted_flops": 9.4576514215872578e+12,
      "predicted_flops_count": 1.6441671680000000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__5325725880560223457<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__5325725880560223457<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__5325725880560223457<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__5325725880560223457<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__5325725880560223457<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__5325725880560223457<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__18284865084901057296<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 615,
      "real_time": 1.1391241976052402e+06,
      "cpu_time": 1.1616472731705748e+06,
      "time_unit": "ns",
      "items_per_second": 3.6084019009000562e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1499520540237427e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 6.1500000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 3.2475617108100508e+12,
      "predicted_advised_flops_count": 3.6993761280000000e+09,
      "predicted_flops": 3.2475617108100508e+12,
      "predicted_flops_count": 3.6993761280000000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__18284865084901057296<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 4197,
      "real_time": 1.6657075955683828e+05,
      "cpu_time": 1.7283054110081960e+05,
      "time_unit": "ns",
      "items_per_second": 2.4676707550207324e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 1.7612800002098083e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.1970000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 2.2209036795186590e+13,
      "predicted_advised_flops_count": 3.6993761280000000e+09,
      "predicted_flops": 2.2209036795186590e+13,
      "predicted_flops_count": 3.6993761280000000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__18284865084901057296<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__18284865084901057296<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__18284865084901057296<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__18284865084901057296<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__18284865084901057296<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__18284865084901057296<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__10238766467926789473<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 937,
      "real_time": 7.5482208084955160e+05,
      "cpu_time": 7.6741346531482763e+05,
      "time_unit": "ns",
      "items_per_second": 1.7425745321594104e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 8.1817597150802612e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 9.3700000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.3564363303985259e+12,
      "predicted_advised_flops_count": 3.2883343360000000e+09,
      "predicted_flops": 4.3564363303985259e+12,
      "predicted_flops_count": 3.2883343360000000e+09,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__10238766467926789473<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 4810,
      "real_time": 1.4454245744244024e+05,
      "cpu_time": 1.5104265051982307e+05,
      "time_unit": "ns",
      "items_per_second": 9.0999818162341188e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 1.7305600643157959e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 4.8100000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.2749954540585297e+13,
      "predicted_advised_flops_count": 3.2883343360000000e+09,
      "predicted_flops": 2.2749954540585297e+13,
      "predicted_flops_count": 3.2883343360000000e+09,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__10238766467926789473<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__10238766467926789473<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__10238766467926789473<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__10238766467926789473<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__10238766467926789473<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_32__10238766467926789473<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_32__838269448742565643<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 361,
      "real_time": 1.9403521704856418e+06,
      "cpu_time": 1.9998829972298448e+06,
      "time_unit": "ns",
      "items_per_second": 2.1183875703198880e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.9548159837722778e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.6100000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 1.9065488132878992e+12,
      "predicted_advised_flops_count": 3.6993761280000000e+09,
      "predicted_flops": 1.9065488132878992e+12,
      "predicted_flops_count": 3.6993761280000000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_32__838269448742565643<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 3883,
      "real_time": 1.7987813803886226e+05,
      "cpu_time": 1.8647922173582664e+05,
      "time_unit": "ns",
      "items_per_second": 2.2851125572091226e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 1.8943999707698822e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.8830000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 2.0566013014882102e+13,
      "predicted_advised_flops_count": 3.6993761280000000e+09,
      "predicted_flops": 2.0566013014882102e+13,
      "predicted_flops_count": 3.6993761280000000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_32__838269448742565643<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_32__838269448742565643<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_32__838269448742565643<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_32__838269448742565643<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_32__838269448742565643<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_32__838269448742565643<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_32__8837318308046846337<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1590,
      "real_time": 4.4046631048114254e+05,
      "cpu_time": 4.4884759496852668e+05,
      "time_unit": "ns",
      "items_per_second": 3.7327875682569165e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.4646400213241577e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.5900000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.7327875682569165e+12,
      "predicted_advised_flops_count": 1.6441671680000000e+09,
      "predicted_flops": 3.7327875682569165e+12,
      "predicted_flops_count": 1.6441671680000000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_32__8837318308046846337<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 8808,
      "real_time": 7.9536953953134012e+04,
      "cpu_time": 8.5731139986501730e+04,
      "time_unit": "ns",
      "items_per_second": 2.0671739188915902e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.0342399775981903e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 8.8080000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.0671739188915902e+13,
      "predicted_advised_flops_count": 1.6441671680000000e+09,
      "predicted_flops": 2.0671739188915902e+13,
      "predicted_flops_count": 1.6441671680000000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_32__8837318308046846337<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_32__8837318308046846337<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_32__8837318308046846337<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_32__8837318308046846337<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_32__8837318308046846337<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_32__8837318308046846337<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_32__8512738909926593344<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1325,
      "real_time": 5.2750519019955734e+05,
      "cpu_time": 5.3657075849058689e+05,
      "time_unit": "ns",
      "items_per_second": 3.1168739162130425e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.3763198852539062e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.3250000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.1168739162130425e+12,
      "predicted_advised_flops_count": 1.6441671680000000e+09,
      "predicted_flops": 3.1168739162130425e+12,
      "predicted_flops_count": 1.6441671680000000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_32__8512738909926593344<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 7917,
      "real_time": 8.8229214338204532e+04,
      "cpu_time": 9.4391556018780102e+04,
      "time_unit": "ns",
      "items_per_second": 1.8635178612126117e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 1.1264000087976456e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 7.9170000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.8635178612126117e+13,
      "predicted_advised_flops_count": 1.6441671680000000e+09,
      "predicted_flops": 1.8635178612126117e+13,
      "predicted_flops_count": 1.6441671680000000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_32__8512738909926593344<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_32__8512738909926593344<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_32__8512738909926593344<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_32__8512738909926593344<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_32__8512738909926593344<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_32__8512738909926593344<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__16578702347459478422<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 580,
      "real_time": 1.1993195060720858e+06,
      "cpu_time": 1.2242400896552594e+06,
      "time_unit": "ns",
      "items_per_second": 3.4272918093878979e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.2482559680938721e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 5.8000000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 3.0845626284491084e+12,
      "predicted_advised_flops_count": 3.6993761280000000e+09,
      "predicted_flops": 3.0845626284491084e+12,
      "predicted_flops_count": 3.6993761280000000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__16578702347459478422<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 4835,
      "real_time": 1.4525966228452063e+05,
      "cpu_time": 1.5172192533596564e+05,
      "time_unit": "ns",
      "items_per_second": 2.8297036185785078e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 1.8943999707698822e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 4.8350000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 2.5467332567206570e+13,
      "predicted_advised_flops_count": 3.6993761280000000e+09,
      "predicted_flops": 2.5467332567206570e+13,
      "predicted_flops_count": 3.6993761280000000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__16578702347459478422<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__16578702347459478422<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__16578702347459478422<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__16578702347459478422<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__16578702347459478422<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__16578702347459478422<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__11611879823513537095<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 781,
      "real_time": 8.9610621376945695e+05,
      "cpu_time": 9.1191276056273817e+05,
      "time_unit": "ns",
      "items_per_second": 1.8347904999830725e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 8.9699202775955200e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 7.8100000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.8347904999830725e+12,
      "predicted_advised_flops_count": 1.6441671680000000e+09,
      "predicted_flops": 1.8347904999830725e+12,
      "predicted_flops_count": 1.6441671680000000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__11611879823513537095<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 4639,
      "real_time": 1.5069870827190569e+05,
      "cpu_time": 1.5696719896523995e+05,
      "time_unit": "ns",
      "items_per_second": 1.0910293703602482e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 1.7407999932765961e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.6390000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.0910293703602482e+13,
      "predicted_advised_flops_count": 1.6441671680000000e+09,
      "predicted_flops": 1.0910293703602482e+13,
      "predicted_flops_count": 1.6441671680000000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__11611879823513537095<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__11611879823513537095<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__11611879823513537095<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__11611879823513537095<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__11611879823513537095<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__11611879823513537095<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__15649657084457129032<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1407,
      "real_time": 4.9817916808015114e+05,
      "cpu_time": 5.0699122956647084e+05,
      "time_unit": "ns",
      "items_per_second": 3.3003531125883467e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.1097601652145386e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.4070000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.3003531125883467e+12,
      "predicted_advised_flops_count": 1.6441671680000000e+09,
      "predicted_flops": 3.3003531125883467e+12,
      "predicted_flops_count": 1.6441671680000000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__15649657084457129032<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 6238,
      "real_time": 1.1181779306090213e+05,
      "cpu_time": 1.1804428470670685e+05,
      "time_unit": "ns",
      "items_per_second": 1.4703985143978795e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 1.3312000036239624e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 6.2380000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.4703985143978795e+13,
      "predicted_advised_flops_count": 1.6441671680000000e+09,
      "predicted_flops": 1.4703985143978795e+13,
      "predicted_flops_count": 1.6441671680000000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__15649657084457129032<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__15649657084457129032<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__15649657084457129032<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__15649657084457129032<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__15649657084457129032<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__15649657084457129032<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__13135651024655561312<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1537,
      "real_time": 4.5505197195059917e+05,
      "cpu_time": 4.6351440923887811e+05,
      "time_unit": "ns",
      "items_per_second": 3.6131415076660566e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.5772799849510193e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.5370000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.6131415076660566e+12,
      "predicted_advised_flops_count": 1.6441671680000000e+09,
      "predicted_flops": 3.6131415076660566e+12,
      "predicted_flops_count": 1.6441671680000000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__13135651024655561312<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5960,
      "real_time": 1.1721394695642393e+05,
      "cpu_time": 1.2341117046978472e+05,
      "time_unit": "ns",
      "items_per_second": 1.4027060863424762e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 1.4028799533843994e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.9600000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.4027060863424762e+13,
      "predicted_advised_flops_count": 1.6441671680000000e+09,
      "predicted_flops": 1.4027060863424762e+13,
      "predicted_flops_count": 1.6441671680000000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__13135651024655561312<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__13135651024655561312<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__13135651024655561312<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__13135651024655561312<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__13135651024655561312<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__13135651024655561312<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__6182785789005774789<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 848,
      "real_time": 8.2635599776623643e+05,
      "cpu_time": 8.4054341745269462e+05,
      "time_unit": "ns",
      "items_per_second": 1.5917277032605119e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 8.3664000034332275e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 8.4800000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.9793192581512798e+12,
      "predicted_advised_flops_count": 3.2883343360000000e+09,
      "predicted_flops": 3.9793192581512798e+12,
      "predicted_flops_count": 3.2883343360000000e+09,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__6182785789005774789<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 4650,
      "real_time": 1.4444397890099115e+05,
      "cpu_time": 1.5060390967745153e+05,
      "time_unit": "ns",
      "items_per_second": 9.1061859719441344e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.6896000504493713e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 4.6500000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.2765464929860336e+13,
      "predicted_advised_flops_count": 3.2883343360000000e+09,
      "predicted_flops": 2.2765464929860336e+13,
      "predicted_flops_count": 3.2883343360000000e+09,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__6182785789005774789<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__6182785789005774789<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__6182785789005774789<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__6182785789005774789<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__6182785789005774789<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_32__6182785789005774789<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_32__12046286916719842278<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2684,
      "real_time": 2.6050631823540412e+05,
      "cpu_time": 2.6725593666168867e+05,
      "time_unit": "ns",
      "items_per_second": 1.5778572849375801e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.7033600211143494e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.6840000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.5778572849375801e+12,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 1.5778572849375801e+12,
      "predicted_flops_count": 4.1104179200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_32__12046286916719842278<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 10111,
      "real_time": 6.8791110113509247e+04,
      "cpu_time": 7.4946791909803811e+04,
      "time_unit": "ns",
      "items_per_second": 5.9752167296291289e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 7.2704002261161804e-02,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.0111000000000000e+04,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.9752167296291289e+12,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 5.9752167296291289e+12,
      "predicted_flops_count": 4.1104179200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_32__12046286916719842278<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_32__12046286916719842278<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_32__12046286916719842278<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_32__12046286916719842278<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_32__12046286916719842278<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_32__12046286916719842278<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_32__10776729647895311461<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1657,
      "real_time": 4.2404064918600145e+05,
      "cpu_time": 4.3187557573949109e+05,
      "time_unit": "ns",
      "items_per_second": 3.8773810273995728e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.1164800524711609e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 1.6570000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.8773810273995728e+12,
      "predicted_advised_flops_count": 1.6441671680000000e+09,
      "predicted_flops": 3.8773810273995728e+12,
      "predicted_flops_count": 1.6441671680000000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_32__10776729647895311461<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 8019,
      "real_time": 8.6822276832706004e+04,
      "cpu_time": 9.3010569646937598e+04,
      "time_unit": "ns",
      "items_per_second": 1.8937157927429992e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 9.0112000703811646e-02,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 8.0190000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.8937157927429992e+13,
      "predicted_advised_flops_count": 1.6441671680000000e+09,
      "predicted_flops": 1.8937157927429992e+13,
      "predicted_flops_count": 1.6441671680000000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_32__10776729647895311461<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_32__10776729647895311461<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_32__10776729647895311461<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_32__10776729647895311461<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_32__10776729647895311461<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_32__10776729647895311461<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_TENSORCOREHALF__BatchSize_32__3627344119559258253/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 12960,
      "real_time": 5.1410432420647179e+04,
      "cpu_time": 5.7683995756191362e+04,
      "time_unit": "ns",
      "items_per_second": 6.2463275424820381e+10,
      "alpha": 5.9604644775390625e-08,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_op_tensor.cpp": 1.3194847084940028e+19,
      "benchmark_func:void iLAYER_CUDNN_OP_TENSOR_Impl(benchmark::State&) [with T = __half; cudnnOpTensorOp_t op_type = (cudnnOpTensorOp_t)0]": 1.5887120378050222e+19,
      "beta": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_OP_TENSOR_Impl": 3.0075642356307840e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_a_tensor_layout": 0.0000000000000000e+00,
      "input_b_tensor_layout": 0.0000000000000000e+00,
      "input_c": 2.0480000000000000e+03,
      "input_h": 7.0000000000000000e+00,
      "input_n": 3.2000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_w": 7.0000000000000000e+00,
      "num_iterations": 1.2960000000000000e+04,
      "op_type": 0.0000000000000000e+00,
      "output_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_TENSORCOREHALF__BatchSize_32__6130851535102693826/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 7139,
      "real_time": 9.8088692813437709e+04,
      "cpu_time": 1.0442125395713684e+05,
      "time_unit": "ns",
      "items_per_second": 6.5476741669047325e+10,
      "alpha": 5.9604644775390625e-08,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_op_tensor.cpp": 1.3194847084940028e+19,
      "benchmark_func:void iLAYER_CUDNN_OP_TENSOR_Impl(benchmark::State&) [with T = __half; cudnnOpTensorOp_t op_type = (cudnnOpTensorOp_t)0]": 1.5887120378050222e+19,
      "beta": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_OP_TENSOR_Impl": 3.0075642356307840e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_a_tensor_layout": 0.0000000000000000e+00,
      "input_b_tensor_layout": 0.0000000000000000e+00,
      "input_c": 1.0240000000000000e+03,
      "input_h": 1.4000000000000000e+01,
      "input_n": 3.2000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_w": 1.4000000000000000e+01,
      "num_iterations": 7.1390000000000000e+03,
      "op_type": 0.0000000000000000e+00,
      "output_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_TENSORCOREHALF__BatchSize_32__2340083525301539134/input[0]:32/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 1637,
      "real_time": 4.2794444508652593e+05,
      "cpu_time": 4.3676876114843535e+05,
      "time_unit": "ns",
      "items_per_second": 6.0031418318342064e+10,
      "alpha": 5.9604644775390625e-08,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_op_tensor.cpp": 1.3194847084940028e+19,
      "benchmark_func:void iLAYER_CUDNN_OP_TENSOR_Impl(benchmark::State&) [with T = __half; cudnnOpTensorOp_t op_type = (cudnnOpTensorOp_t)0]": 1.5887120378050222e+19,
      "beta": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_OP_TENSOR_Impl": 3.0075642356307840e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_a_tensor_layout": 0.0000000000000000e+00,
      "input_b_tensor_layout": 0.0000000000000000e+00,
      "input_c": 2.5600000000000000e+02,
      "input_h": 5.6000000000000000e+01,
      "input_n": 3.2000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_w": 5.6000000000000000e+01,
      "num_iterations": 1.6370000000000000e+03,
      "op_type": 0.0000000000000000e+00,
      "output_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_TENSORCOREHALF__BatchSize_32__7596603773415642602/input[0]:32/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:32/manual_time",
      "iterations": 3464,
      "real_time": 2.0219528541887313e+05,
      "cpu_time": 2.0897571449182034e+05,
      "time_unit": "ns",
      "items_per_second": 6.3527969870265968e+10,
      "alpha": 5.9604644775390625e-08,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_op_tensor.cpp": 1.3194847084940028e+19,
      "benchmark_func:void iLAYER_CUDNN_OP_TENSOR_Impl(benchmark::State&) [with T = __half; cudnnOpTensorOp_t op_type = (cudnnOpTensorOp_t)0]": 1.5887120378050222e+19,
      "beta": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_OP_TENSOR_Impl": 3.0075642356307840e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_a_tensor_layout": 0.0000000000000000e+00,
      "input_b_tensor_layout": 0.0000000000000000e+00,
      "input_c": 5.1200000000000000e+02,
      "input_h": 2.8000000000000000e+01,
      "input_n": 3.2000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_w": 2.8000000000000000e+01,
      "num_iterations": 3.4640000000000000e+03,
      "op_type": 0.0000000000000000e+00,
      "output_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_TENSORCOREHALF__BatchSize_32__4533259076117173143<CUDNN_POOLING_MAX>/input[0]:32/input[1]:64/input[2]:112/input[3]:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:32/manual_time",
      "iterations": 2933,
      "real_time": 2.3859363798684915e+05,
      "cpu_time": 2.4558773781103647e+05,
      "time_unit": "ns",
      "items_per_second": 1.0767308054297740e+11,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_pooling_fwd.cpp": 9.1239988607066061e+18,
      "benchmark_func:void iLAYER_CUDNN_POOLING_FWD_Impl(benchmark::State&) [with T = __half; cudnnPoolingMode_t pooling_mode = (cudnnPoolingMode_t)0]": 5.4796999114253292e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_POOLING_FWD_Impl": 1.4645785230092718e+19,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "horizontal_padding": 1.0000000000000000e+00,
      "horizontal_stride": 2.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 2.5690112000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 2.9330000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "pooling_mode": 0.0000000000000000e+00,
      "predicted_flops": 1.0767308054297740e+11,
      "predicted_flops_count": 2.5690112000000000e+07,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "vertical_padding": 1.0000000000000000e+00,
      "vertical_stride": 2.0000000000000000e+00,
      "window_height": 3.0000000000000000e+00,
      "window_width": 3.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_TENSORCOREHALF__BatchSize_32__4533259076117173143<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:32/input[1]:64/input[2]:112/input[3]:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:32/manual_time",
      "iterations": 2934,
      "real_time": 2.3857687393274161e+05,
      "cpu_time": 2.4555023994521212e+05,
      "time_unit": "ns",
      "items_per_second": 1.0768064639510040e+11,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_pooling_fwd.cpp": 9.1239988607066061e+18,
      "benchmark_func:void iLAYER_CUDNN_POOLING_FWD_Impl(benchmark::State&) [with T = __half; cudnnPoolingMode_t pooling_mode = (cudnnPoolingMode_t)3]": 5.4769555304018821e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_POOLING_FWD_Impl": 1.4645785230092718e+19,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "horizontal_padding": 1.0000000000000000e+00,
      "horizontal_stride": 2.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 2.5690112000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 2.9340000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "pooling_mode": 3.0000000000000000e+00,
      "predicted_flops": 1.0768064639510040e+11,
      "predicted_flops_count": 2.5690112000000000e+07,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "vertical_padding": 1.0000000000000000e+00,
      "vertical_stride": 2.0000000000000000e+00,
      "window_height": 3.0000000000000000e+00,
      "window_width": 3.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 678,
      "real_time": 1.0348134081753021e+06,
      "cpu_time": 1.0560939941002594e+06,
      "time_unit": "ns",
      "items_per_second": 2.9791007882628418e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.0280959606170654e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 4.8168960000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.7800000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 676,
      "real_time": 1.0330308343768781e+06,
      "cpu_time": 1.0544037071007208e+06,
      "time_unit": "ns",
      "items_per_second": 2.9842414547669781e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.0229760408401489e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 4.8168960000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.7600000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 677,
      "real_time": 1.0333622126885452e+06,
      "cpu_time": 1.0530355450518208e+06,
      "time_unit": "ns",
      "items_per_second": 2.9832844690336652e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.0311679840087891e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 4.8168960000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.7700000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 678,
      "real_time": 1.0333282970562357e+06,
      "cpu_time": 1.0529876047195271e+06,
      "time_unit": "ns",
      "items_per_second": 2.9833823856197247e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.0240000486373901e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 4.8168960000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.7800000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 677,
      "real_time": 1.0336532344851792e+06,
      "cpu_time": 1.0550440694240259e+06,
      "time_unit": "ns",
      "items_per_second": 2.9824445347335699e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.0240000486373901e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 4.8168960000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.7700000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 494,
      "real_time": 1.4176199178264181e+06,
      "cpu_time": 1.4493675202425371e+06,
      "time_unit": "ns",
      "items_per_second": 2.1746403258263748e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.5272000000000000e+04,
      "advised_time": 7.4649602174758911e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 4.8168960000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.9400000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.2857602300000000e+08,
      "workspace_megabytes": 1.2261965084075928e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 494,
      "real_time": 1.4176388254185559e+06,
      "cpu_time": 1.4494470566806046e+06,
      "time_unit": "ns",
      "items_per_second": 2.1746113218152048e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.5272000000000000e+04,
      "advised_time": 7.8847998380661011e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 4.8168960000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.9400000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.2857602300000000e+08,
      "workspace_megabytes": 1.2261965084075928e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 494,
      "real_time": 1.4178431986431454e+06,
      "cpu_time": 1.4519976194328791e+06,
      "time_unit": "ns",
      "items_per_second": 2.1742978652013190e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.5272000000000000e+04,
      "advised_time": 7.9462397098541260e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 4.8168960000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.9400000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.2857602300000000e+08,
      "workspace_megabytes": 1.2261965084075928e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 494,
      "real_time": 1.4176425148887553e+06,
      "cpu_time": 1.4518353765180821e+06,
      "time_unit": "ns",
      "items_per_second": 2.1746056623040213e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.5272000000000000e+04,
      "advised_time": 7.9462397098541260e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 4.8168960000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.9400000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.2857602300000000e+08,
      "workspace_megabytes": 1.2261965084075928e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 494,
      "real_time": 1.4176783397009498e+06,
      "cpu_time": 1.4518159493930899e+06,
      "time_unit": "ns",
      "items_per_second": 2.1745507098953772e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.5272000000000000e+04,
      "advised_time": 7.5062400102615356e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 4.8168960000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.9400000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.2857602300000000e+08,
      "workspace_megabytes": 1.2261965084075928e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 490,
      "real_time": 1.4271778030777159e+06,
      "cpu_time": 1.4621793734695346e+06,
      "time_unit": "ns",
      "items_per_second": 2.1600766445161197e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1801395200000000e+08,
      "advised_time": 1.4745600223541260e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 4.8168960000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.9000000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.1801395200000000e+08,
      "workspace_megabytes": 1.1254687500000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 490,
      "real_time": 1.4267412974138041e+06,
      "cpu_time": 1.4617055938777654e+06,
      "time_unit": "ns",
      "items_per_second": 2.1607375111297968e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1801395200000000e+08,
      "advised_time": 1.4776320457458496e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 4.8168960000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.9000000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.1801395200000000e+08,
      "workspace_megabytes": 1.1254687500000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 491,
      "real_time": 1.4260294316089931e+06,
      "cpu_time": 1.4608746924647298e+06,
      "time_unit": "ns",
      "items_per_second": 2.1618161390411508e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1801395200000000e+08,
      "advised_time": 1.4766080379486084e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 4.8168960000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.9100000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.1801395200000000e+08,
      "workspace_megabytes": 1.1254687500000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 171,
      "real_time": 4.0949817735985010e+06,
      "cpu_time": 4.2962134444451453e+06,
      "time_unit": "ns",
      "items_per_second": 7.5282714562388657e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.9546112000000000e+07,
      "advised_time": 4.2823681831359863e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 4.8168960000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.7100000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.9546112000000000e+07,
      "workspace_megabytes": 1.8640625000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 171,
      "real_time": 4.0936604801195059e+06,
      "cpu_time": 4.2918332456141952e+06,
      "time_unit": "ns",
      "items_per_second": 7.5307013245759048e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.9546112000000000e+07,
      "advised_time": 4.2762241363525391e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 4.8168960000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.7100000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.9546112000000000e+07,
      "workspace_megabytes": 1.8640625000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 171,
      "real_time": 4.0906814515198530e+06,
      "cpu_time": 4.2881599707602542e+06,
      "time_unit": "ns",
      "items_per_second": 7.5361855390979187e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.9546112000000000e+07,
      "advised_time": 4.2577919960021973e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 4.8168960000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.7100000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.9546112000000000e+07,
      "workspace_megabytes": 1.8640625000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__102854351462112874<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3501,
      "real_time": 1.9977752408711705e+05,
      "cpu_time": 2.0629161125397863e+05,
      "time_unit": "ns",
      "items_per_second": 1.6459981426970008e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.0272000133991241e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.5010000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3502,
      "real_time": 1.9990266368137079e+05,
      "cpu_time": 2.0630073957778845e+05,
      "time_unit": "ns",
      "items_per_second": 1.6449677435220914e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.0275199413299561e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.5020000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3506,
      "real_time": 1.9979641544242791e+05,
      "cpu_time": 2.0624347917843080e+05,
      "time_unit": "ns",
      "items_per_second": 1.6458425085947279e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.0070399343967438e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.5060000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3510,
      "real_time": 1.9967268623890585e+05,
      "cpu_time": 2.0643682307709559e+05,
      "time_unit": "ns",
      "items_per_second": 1.6468623715842385e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.0275199413299561e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.5100000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3508,
      "real_time": 1.9957984738021891e+05,
      "cpu_time": 2.0634556271335142e+05,
      "time_unit": "ns",
      "items_per_second": 1.6476284450380428e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.0479999482631683e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.5080000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2658,
      "real_time": 2.6320327218789107e+05,
      "cpu_time": 2.7032267118092359e+05,
      "time_unit": "ns",
      "items_per_second": 1.2493516165910660e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 2.2528000175952911e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.6580000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.4295543000000000e+07,
      "workspace_megabytes": 6.1317008018493652e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2658,
      "real_time": 2.6328274108386441e+05,
      "cpu_time": 2.7042575094038562e+05,
      "time_unit": "ns",
      "items_per_second": 1.2489745140387135e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 2.0684799551963806e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.6580000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.4295543000000000e+07,
      "workspace_megabytes": 6.1317008018493652e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2659,
      "real_time": 2.6348605988412007e+05,
      "cpu_time": 2.7055219969946827e+05,
      "time_unit": "ns",
      "items_per_second": 1.2480107438876250e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 2.0172800123691559e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.6590000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.4295543000000000e+07,
      "workspace_megabytes": 6.1317008018493652e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2659,
      "real_time": 2.6322891611503257e+05,
      "cpu_time": 2.7033848777735332e+05,
      "time_unit": "ns",
      "items_per_second": 1.2492299039680650e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 1.8329599499702454e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.6590000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.4295543000000000e+07,
      "workspace_megabytes": 6.1317008018493652e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2659,
      "real_time": 2.6328719917883736e+05,
      "cpu_time": 2.7039874087964435e+05,
      "time_unit": "ns",
      "items_per_second": 1.2489533658514117e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 1.8329599499702454e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.6590000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.4295543000000000e+07,
      "workspace_megabytes": 6.1317008018493652e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1909,
      "real_time": 3.6636538591785688e+05,
      "cpu_time": 3.7374301833440841e+05,
      "time_unit": "ns",
      "items_per_second": 8.9755595435461797e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2845056000000000e+07,
      "advised_time": 3.7990400195121765e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.9090000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.2845056000000000e+07,
      "workspace_megabytes": 1.2250000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1913,
      "real_time": 3.6670255365329213e+05,
      "cpu_time": 3.7418080292740586e+05,
      "time_unit": "ns",
      "items_per_second": 8.9673068901206387e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2845056000000000e+07,
      "advised_time": 3.7680000066757202e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.9130000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.2845056000000000e+07,
      "workspace_megabytes": 1.2250000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1916,
      "real_time": 3.6633229315147729e+05,
      "cpu_time": 3.7385209342404123e+05,
      "time_unit": "ns",
      "items_per_second": 8.9763703541153105e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2845056000000000e+07,
      "advised_time": 3.7990400195121765e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.9160000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.2845056000000000e+07,
      "workspace_megabytes": 1.2250000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 304,
      "real_time": 2.3035188174904571e+06,
      "cpu_time": 2.3798943289475790e+06,
      "time_unit": "ns",
      "items_per_second": 1.4275265784815422e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4961024000000000e+08,
      "advised_time": 2.3480319976806641e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.0400000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.4961024000000000e+08,
      "workspace_megabytes": 2.3804687500000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 304,
      "real_time": 2.3031133536469974e+06,
      "cpu_time": 2.3789551677633892e+06,
      "time_unit": "ns",
      "items_per_second": 1.4277778949928354e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4961024000000000e+08,
      "advised_time": 2.3439359664916992e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.0400000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.4961024000000000e+08,
      "workspace_megabytes": 2.3804687500000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 304,
      "real_time": 2.3032548334939699e+06,
      "cpu_time": 2.3833912730266340e+06,
      "time_unit": "ns",
      "items_per_second": 1.4276901922362161e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4961024000000000e+08,
      "advised_time": 2.3357439041137695e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.0400000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.4961024000000000e+08,
      "workspace_megabytes": 2.3804687500000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__13154939061043141550<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2591,
      "real_time": 2.7022650093568070e+05,
      "cpu_time": 2.7745612466243521e+05,
      "time_unit": "ns",
      "items_per_second": 1.2168807739484770e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.6828798651695251e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.5910000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2590,
      "real_time": 2.7014888034419704e+05,
      "cpu_time": 2.7739588262567122e+05,
      "time_unit": "ns",
      "items_per_second": 1.2172304145071150e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.7955201268196106e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.5900000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2590,
      "real_time": 2.7015829488273681e+05,
      "cpu_time": 2.7698526138980780e+05,
      "time_unit": "ns",
      "items_per_second": 1.2171879961810217e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.6931199431419373e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.5900000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2591,
      "real_time": 2.7019778617098066e+05,
      "cpu_time": 2.7707989309148310e+05,
      "time_unit": "ns",
      "items_per_second": 1.2170100956782629e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.6931199431419373e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.5910000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2590,
      "real_time": 2.7014477805254271e+05,
      "cpu_time": 2.7693384401519655e+05,
      "time_unit": "ns",
      "items_per_second": 1.2172488987961947e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.6931199431419373e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.5900000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4746,
      "real_time": 1.4745110936720044e+05,
      "cpu_time": 1.5370005225449966e+05,
      "time_unit": "ns",
      "items_per_second": 2.2301184101714660e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2375983000000000e+07,
      "advised_time": 1.5052799880504608e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.7460000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.2375983000000000e+07,
      "workspace_megabytes": 3.0876143455505371e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4749,
      "real_time": 1.4734341484595209e+05,
      "cpu_time": 1.5367696462414152e+05,
      "time_unit": "ns",
      "items_per_second": 2.2317484221727598e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2375983000000000e+07,
      "advised_time": 1.5257599949836731e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.7490000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.2375983000000000e+07,
      "workspace_megabytes": 3.0876143455505371e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4748,
      "real_time": 1.4736224886258179e+05,
      "cpu_time": 1.5362570008430645e+05,
      "time_unit": "ns",
      "items_per_second": 2.2314631877438547e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2375983000000000e+07,
      "advised_time": 1.7305600643157959e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.7480000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.2375983000000000e+07,
      "workspace_megabytes": 3.0876143455505371e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4750,
      "real_time": 1.4748654272836191e+05,
      "cpu_time": 1.5370443263160676e+05,
      "time_unit": "ns",
      "items_per_second": 2.2295826284682770e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2375983000000000e+07,
      "advised_time": 1.5052799880504608e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.7500000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.2375983000000000e+07,
      "workspace_megabytes": 3.0876143455505371e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4750,
      "real_time": 1.4715145783817495e+05,
      "cpu_time": 1.5364480189469090e+05,
      "time_unit": "ns",
      "items_per_second": 2.2346597066107488e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2375983000000000e+07,
      "advised_time": 1.5155200660228729e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.7500000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.2375983000000000e+07,
      "workspace_megabytes": 3.0876143455505371e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1599,
      "real_time": 4.3679444031458494e+05,
      "cpu_time": 4.4566015822376165e+05,
      "time_unit": "ns",
      "items_per_second": 7.5283337709877900e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 4.4646400213241577e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.5990000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1602,
      "real_time": 4.3795214092897275e+05,
      "cpu_time": 4.4616035205991764e+05,
      "time_unit": "ns",
      "items_per_second": 7.5084330653684443e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 4.4543999433517456e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.6020000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1598,
      "real_time": 4.3688340760427684e+05,
      "cpu_time": 4.4487870463049778e+05,
      "time_unit": "ns",
      "items_per_second": 7.5268006950232578e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 4.4646400213241577e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.5980000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 261,
      "real_time": 2.7013432022212679e+06,
      "cpu_time": 2.8118033984664907e+06,
      "time_unit": "ns",
      "items_per_second": 1.2172960226956943e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.7740467200000000e+08,
      "advised_time": 2.7002880573272705e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.6100000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.7740467200000000e+08,
      "workspace_megabytes": 6.4602343750000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 261,
      "real_time": 2.7014607754518134e+06,
      "cpu_time": 2.8119006590026198e+06,
      "time_unit": "ns",
      "items_per_second": 1.2172430434234358e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.7740467200000000e+08,
      "advised_time": 2.7013120651245117e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.6100000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.7740467200000000e+08,
      "workspace_megabytes": 6.4602343750000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 261,
      "real_time": 2.7012968608945380e+06,
      "cpu_time": 2.8118298582362086e+06,
      "time_unit": "ns",
      "items_per_second": 1.2173169056699172e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.7740467200000000e+08,
      "advised_time": 2.7023360729217529e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.6100000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.7740467200000000e+08,
      "workspace_megabytes": 6.4602343750000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__15920838676604651972<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1456,
      "real_time": 4.8043444133996917e+05,
      "cpu_time": 4.8921143200536474e+05,
      "time_unit": "ns",
      "items_per_second": 3.4222508349199312e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.0959998965263367e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 1.4560000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1460,
      "real_time": 4.8271160624994675e+05,
      "cpu_time": 4.9140470890414668e+05,
      "time_unit": "ns",
      "items_per_second": 3.4061065586822759e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.0448001027107239e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 1.4600000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1463,
      "real_time": 4.8303496976932400e+05,
      "cpu_time": 4.9184979630891257e+05,
      "time_unit": "ns",
      "items_per_second": 3.4038263705528008e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.3622401356697083e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 1.4630000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1451,
      "real_time": 4.7869441912366374e+05,
      "cpu_time": 4.8739059682919359e+05,
      "time_unit": "ns",
      "items_per_second": 3.4346904879525103e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.0755200386047363e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 1.4510000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1462,
      "real_time": 4.8299246044350450e+05,
      "cpu_time": 4.9165429274956882e+05,
      "time_unit": "ns",
      "items_per_second": 3.4041259494822236e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.0755200386047363e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 1.4620000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6550,
      "real_time": 1.0666697742177515e+05,
      "cpu_time": 1.1287899709901564e+05,
      "time_unit": "ns",
      "items_per_second": 1.5414022293879656e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.9426863000000000e+07,
      "advised_time": 1.0649599879980087e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 6.5500000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.9426863000000000e+07,
      "workspace_megabytes": 2.8063643455505371e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6561,
      "real_time": 1.0657973326022085e+05,
      "cpu_time": 1.1279310074668798e+05,
      "time_unit": "ns",
      "items_per_second": 1.5426639922110396e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.9426863000000000e+07,
      "advised_time": 1.1366400122642517e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 6.5610000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.9426863000000000e+07,
      "workspace_megabytes": 2.8063643455505371e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6568,
      "real_time": 1.0688487192530859e+05,
      "cpu_time": 1.1307347518275950e+05,
      "time_unit": "ns",
      "items_per_second": 1.5382599411719818e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.9426863000000000e+07,
      "advised_time": 1.1776000261306763e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 6.5680000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.9426863000000000e+07,
      "workspace_megabytes": 2.8063643455505371e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6549,
      "real_time": 1.0657480013430248e+05,
      "cpu_time": 1.1294464910651525e+05,
      "time_unit": "ns",
      "items_per_second": 1.5427353989198836e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.9426863000000000e+07,
      "advised_time": 1.1468800157308578e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 6.5490000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.9426863000000000e+07,
      "workspace_megabytes": 2.8063643455505371e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6583,
      "real_time": 1.0691707464602846e+05,
      "cpu_time": 1.1327246589687020e+05,
      "time_unit": "ns",
      "items_per_second": 1.5377966273800162e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.9426863000000000e+07,
      "advised_time": 1.0956799983978271e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 6.5830000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.9426863000000000e+07,
      "workspace_megabytes": 2.8063643455505371e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1088,
      "real_time": 6.3749290963160631e+05,
      "cpu_time": 6.4951021047869348e+05,
      "time_unit": "ns",
      "items_per_second": 2.5791144390141211e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2112640000000000e+06,
      "advised_time": 6.1030399799346924e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 1.0880000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.2112640000000000e+06,
      "workspace_megabytes": 3.0625000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1087,
      "real_time": 6.3759667353135673e+05,
      "cpu_time": 6.4958320147247240e+05,
      "time_unit": "ns",
      "items_per_second": 2.5786947081980669e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2112640000000000e+06,
      "advised_time": 6.1337602138519287e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 1.0870000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.2112640000000000e+06,
      "workspace_megabytes": 3.0625000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1088,
      "real_time": 6.3731576355006418e+05,
      "cpu_time": 6.4926655606625648e+05,
      "time_unit": "ns",
      "items_per_second": 2.5798313207277871e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2112640000000000e+06,
      "advised_time": 5.7651197910308838e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 1.0880000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.2112640000000000e+06,
      "workspace_megabytes": 3.0625000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 251,
      "real_time": 2.7825456851002467e+06,
      "cpu_time": 2.8934943784855050e+06,
      "time_unit": "ns",
      "items_per_second": 5.9088595626805164e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.2390272000000000e+08,
      "advised_time": 2.7811839580535889e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 2.5100000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.2390272000000000e+08,
      "workspace_megabytes": 5.9500000000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 252,
      "real_time": 2.7812574869982661e+06,
      "cpu_time": 2.8927911230167658e+06,
      "time_unit": "ns",
      "items_per_second": 5.9115963756901343e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.2390272000000000e+08,
      "advised_time": 2.7811839580535889e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 2.5200000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.2390272000000000e+08,
      "workspace_megabytes": 5.9500000000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 252,
      "real_time": 2.7791565581638780e+06,
      "cpu_time": 2.8920576944438647e+06,
      "time_unit": "ns",
      "items_per_second": 5.9160653010719983e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.2390272000000000e+08,
      "advised_time": 2.8159999847412109e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 2.5200000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.2390272000000000e+08,
      "workspace_megabytes": 5.9500000000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 493,
      "real_time": 1.4189047798888409e+06,
      "cpu_time": 1.4535789492900448e+06,
      "time_unit": "ns",
      "items_per_second": 1.1587579316836235e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1363984000000000e+08,
      "advised_time": 1.4325759410858154e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 4.9300000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.1363984000000000e+08,
      "workspace_megabytes": 1.0837539672851562e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 494,
      "real_time": 1.4161670661572865e+06,
      "cpu_time": 1.4505540323888310e+06,
      "time_unit": "ns",
      "items_per_second": 1.1609980257918176e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1363984000000000e+08,
      "advised_time": 1.4366719722747803e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 4.9400000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.1363984000000000e+08,
      "workspace_megabytes": 1.0837539672851562e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 494,
      "real_time": 1.4163411207316134e+06,
      "cpu_time": 1.4483592145738343e+06,
      "time_unit": "ns",
      "items_per_second": 1.1608553504050654e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1363984000000000e+08,
      "advised_time": 1.4387199878692627e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 4.9400000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.1363984000000000e+08,
      "workspace_megabytes": 1.0837539672851562e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_32__6010912523092587733<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 722,
      "real_time": 9.7077651129302848e+05,
      "cpu_time": 9.9035010387760098e+05,
      "time_unit": "ns",
      "items_per_second": 4.2341546918199713e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.6767997741699219e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 7.2200000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 721,
      "real_time": 9.6944794536732277e+05,
      "cpu_time": 9.8711808599168248e+05,
      "time_unit": "ns",
      "items_per_second": 4.2399573279229218e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.6153599023818970e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 7.2100000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 722,
      "real_time": 9.7151060357762093e+05,
      "cpu_time": 9.9101785734021582e+05,
      "time_unit": "ns",
      "items_per_second": 4.2309552822822992e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.8508799076080322e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 7.2200000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 720,
      "real_time": 9.7016480212914757e+05,
      "cpu_time": 9.8972713055604335e+05,
      "time_unit": "ns",
      "items_per_second": 4.2368244147583746e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.8406398296356201e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 7.2000000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 720,
      "real_time": 9.7290519810889650e+05,
      "cpu_time": 9.9244679027713626e+05,
      "time_unit": "ns",
      "items_per_second": 4.2248904908614996e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.8508799076080322e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 7.2000000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2999,
      "real_time": 2.3233281497219525e+05,
      "cpu_time": 2.3888043747935715e+05,
      "time_unit": "ns",
      "items_per_second": 1.7691938697905933e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.8627735000000000e+07,
      "advised_time": 2.3859199881553650e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.9990000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.8627735000000000e+07,
      "workspace_megabytes": 3.6838278770446777e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3004,
      "real_time": 2.3325937771238075e+05,
      "cpu_time": 2.4016970639133177e+05,
      "time_unit": "ns",
      "items_per_second": 1.7621662032676470e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.8627735000000000e+07,
      "advised_time": 2.3859199881553650e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.0040000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.8627735000000000e+07,
      "workspace_megabytes": 3.6838278770446777e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3002,
      "real_time": 2.3320867783030271e+05,
      "cpu_time": 2.4016102398412247e+05,
      "time_unit": "ns",
      "items_per_second": 1.7625493005843457e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.8627735000000000e+07,
      "advised_time": 2.4063999950885773e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.0020000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.8627735000000000e+07,
      "workspace_megabytes": 3.6838278770446777e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3002,
      "real_time": 2.3315963285406964e+05,
      "cpu_time": 2.4005587241856981e+05,
      "time_unit": "ns",
      "items_per_second": 1.7629200516766277e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.8627735000000000e+07,
      "advised_time": 2.3756800591945648e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.0020000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.8627735000000000e+07,
      "workspace_megabytes": 3.6838278770446777e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3008,
      "real_time": 2.3327020289314611e+05,
      "cpu_time": 2.4019142087767742e+05,
      "time_unit": "ns",
      "items_per_second": 1.7620844278524746e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.8627735000000000e+07,
      "advised_time": 2.3756800591945648e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.0080000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.8627735000000000e+07,
      "workspace_megabytes": 3.6838278770446777e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 518,
      "real_time": 1.3553012473936619e+06,
      "cpu_time": 1.3874202799233631e+06,
      "time_unit": "ns",
      "items_per_second": 3.0328444896694501e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1560550400000000e+08,
      "advised_time": 1.3711359500885010e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.1800000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.1560550400000000e+08,
      "workspace_megabytes": 1.1025000000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 518,
      "real_time": 1.3504368226083433e+06,
      "cpu_time": 1.3823843745166163e+06,
      "time_unit": "ns",
      "items_per_second": 3.0437691354274573e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1560550400000000e+08,
      "advised_time": 1.3701119422912598e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.1800000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.1560550400000000e+08,
      "workspace_megabytes": 1.1025000000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 516,
      "real_time": 1.3512694012904323e+06,
      "cpu_time": 1.3834251531016852e+06,
      "time_unit": "ns",
      "items_per_second": 3.0418937304986273e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1560550400000000e+08,
      "advised_time": 1.3690880537033081e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.1600000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.1560550400000000e+08,
      "workspace_megabytes": 1.1025000000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 720,
      "real_time": 9.7278128749975527e+05,
      "cpu_time": 9.9248197083253344e+05,
      "time_unit": "ns",
      "items_per_second": 4.2254286475479047e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.0776550400000000e+08,
      "advised_time": 1.1182080507278442e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 7.2000000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.0776550400000000e+08,
      "workspace_megabytes": 1.9814062500000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 720,
      "real_time": 9.7357897733066545e+05,
      "cpu_time": 9.9320172222133377e+05,
      "time_unit": "ns",
      "items_per_second": 4.2219665951188074e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.0776550400000000e+08,
      "advised_time": 1.1192320585250854e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 7.2000000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.0776550400000000e+08,
      "workspace_megabytes": 1.9814062500000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 720,
      "real_time": 9.7357662121390202e+05,
      "cpu_time": 9.9314554027785116e+05,
      "time_unit": "ns",
      "items_per_second": 4.2219768125439722e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.0776550400000000e+08,
      "advised_time": 1.0833920240402222e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 7.2000000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.0776550400000000e+08,
      "workspace_megabytes": 1.9814062500000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1351,
      "real_time": 5.1751122447171924e+05,
      "cpu_time": 5.2727349074730079e+05,
      "time_unit": "ns",
      "items_per_second": 7.9426642855832874e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.3526528000000000e+07,
      "advised_time": 5.8163201808929443e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.3510000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 5.3526528000000000e+07,
      "workspace_megabytes": 5.1046875000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1351,
      "real_time": 5.1758178503912280e+05,
      "cpu_time": 5.2728434196921112e+05,
      "time_unit": "ns",
      "items_per_second": 7.9415814829907568e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.3526528000000000e+07,
      "advised_time": 5.7958400249481201e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.3510000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 5.3526528000000000e+07,
      "workspace_megabytes": 5.1046875000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1351,
      "real_time": 5.1757382678948925e+05,
      "cpu_time": 5.2731459289436962e+05,
      "time_unit": "ns",
      "items_per_second": 7.9417035932765857e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.3526528000000000e+07,
      "advised_time": 5.6831997632980347e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.3510000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 5.3526528000000000e+07,
      "workspace_megabytes": 5.1046875000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 966,
      "real_time": 7.2404297139094549e+05,
      "cpu_time": 7.3755725155339786e+05,
      "time_unit": "ns",
      "items_per_second": 5.6770358699892529e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.3600000000000000e+05,
      "advised_time": 7.8131198883056641e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 6.7907396577335429e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 9.6600000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.3600000000000000e+05,
      "workspace_megabytes": 3.2043457031250000e-01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 967,
      "real_time": 7.2387253457243100e+05,
      "cpu_time": 7.3742262047544133e+05,
      "time_unit": "ns",
      "items_per_second": 5.6783725361646667e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.3600000000000000e+05,
      "advised_time": 7.8233599662780762e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 6.7907396577335429e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 9.6700000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.3600000000000000e+05,
      "workspace_megabytes": 3.2043457031250000e-01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 965,
      "real_time": 7.2382342388824478e+05,
      "cpu_time": 7.3739483108769788e+05,
      "time_unit": "ns",
      "items_per_second": 5.6787578079742151e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.3600000000000000e+05,
      "advised_time": 7.8028798103332520e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 6.7907396577335429e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 9.6500000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.3600000000000000e+05,
      "workspace_megabytes": 3.2043457031250000e-01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1426,
      "real_time": 4.8932622707361385e+05,
      "cpu_time": 4.9882267391275341e+05,
      "time_unit": "ns",
      "items_per_second": 8.4001586111214758e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1619532800000000e+08,
      "advised_time": 5.2531200647354126e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.6915749020158575e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.4260000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.1619532800000000e+08,
      "workspace_megabytes": 1.1081250000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1426,
      "real_time": 4.8896175025319646e+05,
      "cpu_time": 4.9842381556760694e+05,
      "time_unit": "ns",
      "items_per_second": 8.4064201706401868e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1619532800000000e+08,
      "advised_time": 5.2223998308181763e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.6915749020158575e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.4260000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.1619532800000000e+08,
      "workspace_megabytes": 1.1081250000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1432,
      "real_time": 4.8910518446023436e+05,
      "cpu_time": 4.9779148184337065e+05,
      "time_unit": "ns",
      "items_per_second": 8.4039549172560205e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1619532800000000e+08,
      "advised_time": 5.2121597528457642e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.6915749020158575e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.4320000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.1619532800000000e+08,
      "workspace_megabytes": 1.1081250000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__13758015389636537807<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 857,
      "real_time": 8.1605116991313174e+05,
      "cpu_time": 8.3028454492429283e+05,
      "time_unit": "ns",
      "items_per_second": 5.0369610038516974e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 8.1612801551818848e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 8.5700000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 858,
      "real_time": 8.1562642234655446e+05,
      "cpu_time": 8.3019818881072383e+05,
      "time_unit": "ns",
      "items_per_second": 5.0395840637118420e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 8.1612801551818848e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 8.5800000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 862,
      "real_time": 8.1660976076202583e+05,
      "cpu_time": 8.3056737703073688e+05,
      "time_unit": "ns",
      "items_per_second": 5.0335155388839960e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 8.1612801551818848e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 8.6200000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 855,
      "real_time": 8.1410168476773112e+05,
      "cpu_time": 8.2796711695958127e+05,
      "time_unit": "ns",
      "items_per_second": 5.0490227411490137e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 8.1612801551818848e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 8.5500000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 859,
      "real_time": 8.1834808468755789e+05,
      "cpu_time": 8.3403607101307192e+05,
      "time_unit": "ns",
      "items_per_second": 5.0228234133025946e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 8.1817597150802612e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 8.5900000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3951,
      "real_time": 1.7621355306200866e+05,
      "cpu_time": 1.8281248165014011e+05,
      "time_unit": "ns",
      "items_per_second": 2.3326343794643110e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.9567223000000000e+07,
      "advised_time": 1.8227200210094452e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.9510000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.9567223000000000e+07,
      "workspace_megabytes": 1.8660758018493652e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3953,
      "real_time": 1.7673833822016220e+05,
      "cpu_time": 1.8332701011890121e+05,
      "time_unit": "ns",
      "items_per_second": 2.3257081408560430e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.9567223000000000e+07,
      "advised_time": 1.8124799430370331e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.9530000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.9567223000000000e+07,
      "workspace_megabytes": 1.8660758018493652e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3953,
      "real_time": 1.7791604011819282e+05,
      "cpu_time": 1.8417826005561801e+05,
      "time_unit": "ns",
      "items_per_second": 2.3103132900605112e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.9567223000000000e+07,
      "advised_time": 2.1196800470352173e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.9530000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.9567223000000000e+07,
      "workspace_megabytes": 1.8660758018493652e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3926,
      "real_time": 1.7736669068062352e+05,
      "cpu_time": 1.8397213601650769e+05,
      "time_unit": "ns",
      "items_per_second": 2.3174689138229741e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.9567223000000000e+07,
      "advised_time": 1.8022400140762329e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.9260000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.9567223000000000e+07,
      "workspace_megabytes": 1.8660758018493652e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3908,
      "real_time": 1.7713745787189610e+05,
      "cpu_time": 1.8381017016368921e+05,
      "time_unit": "ns",
      "items_per_second": 2.3204679401985151e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.9567223000000000e+07,
      "advised_time": 1.8124799430370331e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.9080000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.9567223000000000e+07,
      "workspace_megabytes": 1.8660758018493652e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 767,
      "real_time": 9.2284837845443340e+05,
      "cpu_time": 9.4121722294643568e+05,
      "time_unit": "ns",
      "items_per_second": 4.4540555263087091e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.7802752000000000e+07,
      "advised_time": 9.0828800201416016e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 7.6700000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 5.7802752000000000e+07,
      "workspace_megabytes": 5.5125000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 759,
      "real_time": 9.2187771381631168e+05,
      "cpu_time": 9.4000146113330475e+05,
      "time_unit": "ns",
      "items_per_second": 4.4587452960371918e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.7802752000000000e+07,
      "advised_time": 9.0316802263259888e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 7.5900000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 5.7802752000000000e+07,
      "workspace_megabytes": 5.5125000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 766,
      "real_time": 9.2310659238137305e+05,
      "cpu_time": 9.3930689686686639e+05,
      "time_unit": "ns",
      "items_per_second": 4.4528096255885242e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.7802752000000000e+07,
      "advised_time": 9.0931200981140137e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 7.6600000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 5.7802752000000000e+07,
      "workspace_megabytes": 5.5125000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1008,
      "real_time": 6.8673233926390472e+05,
      "cpu_time": 6.9802581944450771e+05,
      "time_unit": "ns",
      "items_per_second": 5.9854730656865210e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.7884774400000000e+08,
      "advised_time": 7.1884799003601074e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.0080000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.7884774400000000e+08,
      "workspace_megabytes": 1.7056250000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1022,
      "real_time": 6.8486534320355672e+05,
      "cpu_time": 6.9628332583109254e+05,
      "time_unit": "ns",
      "items_per_second": 6.0017899296421179e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.7884774400000000e+08,
      "advised_time": 7.1679997444152832e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.0220000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.7884774400000000e+08,
      "workspace_megabytes": 1.7056250000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1020,
      "real_time": 6.8494434035885346e+05,
      "cpu_time": 6.9670051568597474e+05,
      "time_unit": "ns",
      "items_per_second": 6.0010977210885266e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.7884774400000000e+08,
      "advised_time": 7.2089600563049316e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.0200000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.7884774400000000e+08,
      "workspace_megabytes": 1.7056250000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1492,
      "real_time": 4.6902689590832294e+05,
      "cpu_time": 4.7815655630034232e+05,
      "time_unit": "ns",
      "items_per_second": 8.7637147375945605e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0697932800000000e+08,
      "advised_time": 5.0790399312973022e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.4920000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.0697932800000000e+08,
      "workspace_megabytes": 1.0202343750000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1489,
      "real_time": 4.6977328262517019e+05,
      "cpu_time": 4.7802586299555452e+05,
      "time_unit": "ns",
      "items_per_second": 8.7497907438037134e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0697932800000000e+08,
      "advised_time": 5.0483202934265137e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.4890000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.0697932800000000e+08,
      "workspace_megabytes": 1.0202343750000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1491,
      "real_time": 4.6934166145579686e+05,
      "cpu_time": 4.7771940241454006e+05,
      "time_unit": "ns",
      "items_per_second": 8.7578373231354919e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0697932800000000e+08,
      "advised_time": 5.0687998533248901e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.4910000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.0697932800000000e+08,
      "workspace_megabytes": 1.0202343750000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1138,
      "real_time": 6.1454729079669877e+05,
      "cpu_time": 6.2484387697724078e+05,
      "time_unit": "ns",
      "items_per_second": 6.6885298846102734e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.3437440000000000e+06,
      "advised_time": 6.5331202745437622e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 6.7907396577335429e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.1380000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.3437440000000000e+06,
      "workspace_megabytes": 1.2814941406250000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1137,
      "real_time": 6.1541659252311813e+05,
      "cpu_time": 6.2585076429207553e+05,
      "time_unit": "ns",
      "items_per_second": 6.6790820558605457e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.3437440000000000e+06,
      "advised_time": 6.5433597564697266e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 6.7907396577335429e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.1370000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.3437440000000000e+06,
      "workspace_megabytes": 1.2814941406250000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1135,
      "real_time": 6.1539131753138441e+05,
      "cpu_time": 6.2685484845801629e+05,
      "time_unit": "ns",
      "items_per_second": 6.6793563752065320e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.3437440000000000e+06,
      "advised_time": 6.6355198621749878e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 6.7907396577335429e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.1350000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.3437440000000000e+06,
      "workspace_megabytes": 1.2814941406250000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2113,
      "real_time": 3.2962707583541272e+05,
      "cpu_time": 3.3728435967819754e+05,
      "time_unit": "ns",
      "items_per_second": 1.2469903783184326e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.0162048000000000e+07,
      "advised_time": 3.4099200367927551e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.6915749020158575e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.1130000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.0162048000000000e+07,
      "workspace_megabytes": 5.7375000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2125,
      "real_time": 3.3013323038432968e+05,
      "cpu_time": 3.3712678682385402e+05,
      "time_unit": "ns",
      "items_per_second": 1.2450785142758254e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.0162048000000000e+07,
      "advised_time": 3.5123199224472046e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.6915749020158575e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.1250000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.0162048000000000e+07,
      "workspace_megabytes": 5.7375000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2122,
      "real_time": 3.3041174410189292e+05,
      "cpu_time": 3.3743527803939005e+05,
      "time_unit": "ns",
      "items_per_second": 1.2440290012005210e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.0162048000000000e+07,
      "advised_time": 3.4303998947143555e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.6915749020158575e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.1220000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.0162048000000000e+07,
      "workspace_megabytes": 5.7375000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10157862840842714847<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1486,
      "real_time": 4.7080682639645541e+05,
      "cpu_time": 4.7919905248933227e+05,
      "time_unit": "ns",
      "items_per_second": 3.4922330684633809e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.7414401173591614e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.4860000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1485,
      "real_time": 4.7018466282538715e+05,
      "cpu_time": 4.7866029764286132e+05,
      "time_unit": "ns",
      "items_per_second": 3.4968541043428198e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.5670399069786072e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.4850000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1472,
      "real_time": 4.7573500080983178e+05,
      "cpu_time": 4.8421633627733315e+05,
      "time_unit": "ns",
      "items_per_second": 3.4560567652183999e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.7308799624443054e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.4720000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1488,
      "real_time": 4.7011236597671831e+05,
      "cpu_time": 4.7847670026851591e+05,
      "time_unit": "ns",
      "items_per_second": 3.4973918726516230e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.6387198567390442e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.4880000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1462,
      "real_time": 4.7161170986889343e+05,
      "cpu_time": 4.8009241518459999e+05,
      "time_unit": "ns",
      "items_per_second": 3.4862729944875063e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.7615998983383179e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.4620000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3617,
      "real_time": 1.9342021309993495e+05,
      "cpu_time": 1.9978601852363755e+05,
      "time_unit": "ns",
      "items_per_second": 8.5004930025100508e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1565711100000000e+08,
      "advised_time": 1.9968000054359436e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.6170000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.1565711100000000e+08,
      "workspace_megabytes": 1.1029921627044678e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3617,
      "real_time": 1.9356260774641039e+05,
      "cpu_time": 1.9990941553773536e+05,
      "time_unit": "ns",
      "items_per_second": 8.4942396010393242e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1565711100000000e+08,
      "advised_time": 1.9968000054359436e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.6170000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.1565711100000000e+08,
      "workspace_megabytes": 1.1029921627044678e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3619,
      "real_time": 1.9348777903090909e+05,
      "cpu_time": 2.0017743658526646e+05,
      "time_unit": "ns",
      "items_per_second": 8.4975246304178682e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1565711100000000e+08,
      "advised_time": 1.9968000054359436e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.6190000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.1565711100000000e+08,
      "workspace_megabytes": 1.1029921627044678e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3617,
      "real_time": 1.9343112181021916e+05,
      "cpu_time": 2.0011887199295306e+05,
      "time_unit": "ns",
      "items_per_second": 8.5000136100804912e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1565711100000000e+08,
      "advised_time": 1.9968000054359436e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.6170000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.1565711100000000e+08,
      "workspace_megabytes": 1.1029921627044678e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3616,
      "real_time": 1.9355573919863801e+05,
      "cpu_time": 2.0024310038641072e+05,
      "time_unit": "ns",
      "items_per_second": 8.4945410288901904e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1565711100000000e+08,
      "advised_time": 1.9968000054359436e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.6160000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.1565711100000000e+08,
      "workspace_megabytes": 1.1029921627044678e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1324,
      "real_time": 5.2495079149852239e+05,
      "cpu_time": 5.3503623640481313e+05,
      "time_unit": "ns",
      "items_per_second": 3.1320405543280869e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2845056000000000e+07,
      "advised_time": 5.4579198360443115e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.3240000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.2845056000000000e+07,
      "workspace_megabytes": 1.2250000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1333,
      "real_time": 5.2388148238730110e+05,
      "cpu_time": 5.3397571492913063e+05,
      "time_unit": "ns",
      "items_per_second": 3.1384334496947939e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2845056000000000e+07,
      "advised_time": 5.4268801212310791e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.3330000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.2845056000000000e+07,
      "workspace_megabytes": 1.2250000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1335,
      "real_time": 5.3295184594791825e+05,
      "cpu_time": 5.4304771685458056e+05,
      "time_unit": "ns",
      "items_per_second": 3.0850201204869707e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2845056000000000e+07,
      "advised_time": 5.4988801479339600e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.3350000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.2845056000000000e+07,
      "workspace_megabytes": 1.2250000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 199,
      "real_time": 3.5153456949558691e+06,
      "cpu_time": 3.6975384221154372e+06,
      "time_unit": "ns",
      "items_per_second": 4.6771137483269354e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.2295244800000000e+08,
      "advised_time": 3.5614719390869141e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.9900000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.2295244800000000e+08,
      "workspace_megabytes": 5.9409375000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 199,
      "real_time": 3.5171362480158033e+06,
      "cpu_time": 3.6990379798987019e+06,
      "time_unit": "ns",
      "items_per_second": 4.6747326576488440e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.2295244800000000e+08,
      "advised_time": 3.5450880527496338e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.9900000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.2295244800000000e+08,
      "workspace_megabytes": 5.9409375000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 199,
      "real_time": 3.5164785388875846e+06,
      "cpu_time": 3.6926449597969856e+06,
      "time_unit": "ns",
      "items_per_second": 4.6756070023396808e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.2295244800000000e+08,
      "advised_time": 3.5471360683441162e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.9900000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.2295244800000000e+08,
      "workspace_megabytes": 5.9409375000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 636,
      "real_time": 1.1016471538789358e+06,
      "cpu_time": 1.1227617452821394e+06,
      "time_unit": "ns",
      "items_per_second": 1.4924625931368616e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.5820473600000000e+08,
      "advised_time": 1.1366399526596069e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 6.3600000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.5820473600000000e+08,
      "workspace_megabytes": 1.5087579345703125e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 635,
      "real_time": 1.1016546871410464e+06,
      "cpu_time": 1.1224308377936222e+06,
      "time_unit": "ns",
      "items_per_second": 1.4924523874780149e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.5820473600000000e+08,
      "advised_time": 1.1499520540237427e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 6.3500000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.5820473600000000e+08,
      "workspace_megabytes": 1.5087579345703125e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 635,
      "real_time": 1.1018271834816872e+06,
      "cpu_time": 1.1227005118098352e+06,
      "time_unit": "ns",
      "items_per_second": 1.4922187368844551e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.5820473600000000e+08,
      "advised_time": 1.1499520540237427e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 6.3500000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.5820473600000000e+08,
      "workspace_megabytes": 1.5087579345703125e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__5824868746478056138<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1218,
      "real_time": 5.7447562524658896e+05,
      "cpu_time": 5.8533472003237426e+05,
      "time_unit": "ns",
      "items_per_second": 2.8620312085377944e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.7446402311325073e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.2180000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1218,
      "real_time": 5.7447793539299991e+05,
      "cpu_time": 5.8534039737173915e+05,
      "time_unit": "ns",
      "items_per_second": 2.8620196994602178e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.7651197910308838e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.2180000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1218,
      "real_time": 5.7449238938745880e+05,
      "cpu_time": 5.8532781691303116e+05,
      "time_unit": "ns",
      "items_per_second": 2.8619476922106157e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.8367997407913208e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.2180000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1218,
      "real_time": 5.7449977062543179e+05,
      "cpu_time": 5.8533095730709098e+05,
      "time_unit": "ns",
      "items_per_second": 2.8619109215832588e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.8470398187637329e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.2180000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1218,
      "real_time": 5.7449582899188122e+05,
      "cpu_time": 5.8533433661796048e+05,
      "time_unit": "ns",
      "items_per_second": 2.8619305572421055e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.8675199747085571e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.2180000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5247,
      "real_time": 1.3111354426299073e+05,
      "cpu_time": 1.3739046083487020e+05,
      "time_unit": "ns",
      "items_per_second": 1.2540025344003283e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1731259000000000e+07,
      "advised_time": 1.3519999384880066e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.2470000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.1731259000000000e+07,
      "workspace_megabytes": 1.1187800407409668e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5199,
      "real_time": 1.3135985587600397e+05,
      "cpu_time": 1.3768205077927996e+05,
      "time_unit": "ns",
      "items_per_second": 1.2516511662071232e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1731259000000000e+07,
      "advised_time": 1.5667200088500977e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.1990000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.1731259000000000e+07,
      "workspace_megabytes": 1.1187800407409668e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5189,
      "real_time": 1.3171246469570592e+05,
      "cpu_time": 1.3792606918502395e+05,
      "time_unit": "ns",
      "items_per_second": 1.2483003577516404e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1731259000000000e+07,
      "advised_time": 1.3823999464511871e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.1890000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.1731259000000000e+07,
      "workspace_megabytes": 1.1187800407409668e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5190,
      "real_time": 1.3164650330428564e+05,
      "cpu_time": 1.3787829171417144e+05,
      "time_unit": "ns",
      "items_per_second": 1.2489258178014025e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1731259000000000e+07,
      "advised_time": 1.3312000036239624e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.1900000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.1731259000000000e+07,
      "workspace_megabytes": 1.1187800407409668e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5196,
      "real_time": 1.3174799130752299e+05,
      "cpu_time": 1.3796194380328656e+05,
      "time_unit": "ns",
      "items_per_second": 1.2479637463027613e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1731259000000000e+07,
      "advised_time": 1.3721600174903870e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.1960000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.1731259000000000e+07,
      "workspace_megabytes": 1.1187800407409668e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 925,
      "real_time": 7.4924392367687984e+05,
      "cpu_time": 7.6340302378375281e+05,
      "time_unit": "ns",
      "items_per_second": 2.1944351045669158e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 7.5775998830795288e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 9.2500000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 926,
      "real_time": 7.4954827496637125e+05,
      "cpu_time": 7.6233352159841917e+05,
      "time_unit": "ns",
      "items_per_second": 2.1935440623537773e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 7.5775998830795288e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 9.2600000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 925,
      "real_time": 7.4823729253399209e+05,
      "cpu_time": 7.6109547243098903e+05,
      "time_unit": "ns",
      "items_per_second": 2.1973873588041003e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 7.5571197271347046e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 9.2500000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 83,
      "real_time": 8.2974742806280954e+06,
      "cpu_time": 9.1638375662636291e+06,
      "time_unit": "ns",
      "items_per_second": 1.9815272845600690e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5711083520000000e+09,
      "advised_time": 8.2984962463378906e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 8.3000000000000000e+01,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.5711083520000000e+09,
      "workspace_megabytes": 2.4520000000000000e+03,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 82,
      "real_time": 8.3054375902908603e+06,
      "cpu_time": 9.1853125365848504e+06,
      "time_unit": "ns",
      "items_per_second": 1.9796273828149017e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5711083520000000e+09,
      "advised_time": 8.3056640625000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 8.2000000000000000e+01,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.5711083520000000e+09,
      "workspace_megabytes": 2.4520000000000000e+03,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 82,
      "real_time": 8.3033412399633629e+06,
      "cpu_time": 9.1839048170758877e+06,
      "time_unit": "ns",
      "items_per_second": 1.9801271807146091e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5711083520000000e+09,
      "advised_time": 8.3169279098510742e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 8.2000000000000000e+01,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.5711083520000000e+09,
      "workspace_megabytes": 2.4520000000000000e+03,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 229,
      "real_time": 3.0416911508578919e+06,
      "cpu_time": 3.1745308733626907e+06,
      "time_unit": "ns",
      "items_per_second": 5.4054375886791522e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.2059459200000000e+08,
      "advised_time": 3.0729920864105225e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.2900000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.2059459200000000e+08,
      "workspace_megabytes": 2.1037539672851562e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 230,
      "real_time": 3.0378999968018867e+06,
      "cpu_time": 3.1704252217381331e+06,
      "time_unit": "ns",
      "items_per_second": 5.4121833165373364e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.2059459200000000e+08,
      "advised_time": 3.1150081157684326e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.3000000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.2059459200000000e+08,
      "workspace_megabytes": 2.1037539672851562e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 230,
      "real_time": 3.0427756871137284e+06,
      "cpu_time": 3.1741534434756786e+06,
      "time_unit": "ns",
      "items_per_second": 5.4035109290609595e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.2059459200000000e+08,
      "advised_time": 3.0648319721221924e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.3000000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.2059459200000000e+08,
      "workspace_megabytes": 2.1037539672851562e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__14977812475437988261<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 893,
      "real_time": 7.8982704429608781e+05,
      "cpu_time": 8.0504000447983341e+05,
      "time_unit": "ns",
      "items_per_second": 1.6653440065125348e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 7.9360002279281616e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 8.9300000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 900,
      "real_time": 7.8393343680848682e+05,
      "cpu_time": 7.9726983555531211e+05,
      "time_unit": "ns",
      "items_per_second": 1.6778640540642396e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 7.1884799003601074e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 9.0000000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 897,
      "real_time": 7.8723656327423186e+05,
      "cpu_time": 8.0082564214023994e+05,
      "time_unit": "ns",
      "items_per_second": 1.6708239883184982e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 7.0451200008392334e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 8.9700000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 891,
      "real_time": 7.8432973044141533e+05,
      "cpu_time": 7.9919344893350638e+05,
      "time_unit": "ns",
      "items_per_second": 1.6770162896410150e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 7.2294402122497559e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 8.9100000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 898,
      "real_time": 7.8675559750926122e+05,
      "cpu_time": 8.0009524387498421e+05,
      "time_unit": "ns",
      "items_per_second": 1.6718454098885730e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 7.2188800573348999e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 8.9800000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2818,
      "real_time": 2.4495376548090338e+05,
      "cpu_time": 2.5152271681972119e+05,
      "time_unit": "ns",
      "items_per_second": 5.3697224527970914e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.2429999000000000e+07,
      "advised_time": 2.7647998929023743e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 2.8180000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 5.2429999000000000e+07,
      "workspace_megabytes": 5.0001143455505371e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2851,
      "real_time": 2.4463728322955067e+05,
      "cpu_time": 2.5165651174959994e+05,
      "time_unit": "ns",
      "items_per_second": 5.3766691529425711e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.2429999000000000e+07,
      "advised_time": 2.4883200228214264e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 2.8510000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 5.2429999000000000e+07,
      "workspace_megabytes": 5.0001143455505371e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2813,
      "real_time": 2.4397662237538683e+05,
      "cpu_time": 2.5100062068983039e+05,
      "time_unit": "ns",
      "items_per_second": 5.3912285594978188e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.2429999000000000e+07,
      "advised_time": 2.4886399507522583e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 2.8130000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 5.2429999000000000e+07,
      "workspace_megabytes": 5.0001143455505371e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2850,
      "real_time": 2.4391325186067994e+05,
      "cpu_time": 2.5092653438603343e+05,
      "time_unit": "ns",
      "items_per_second": 5.3926292416096414e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.2429999000000000e+07,
      "advised_time": 2.5187200307846069e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 2.8500000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 5.2429999000000000e+07,
      "workspace_megabytes": 5.0001143455505371e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2847,
      "real_time": 2.4523015061476306e+05,
      "cpu_time": 2.5227123428135592e+05,
      "time_unit": "ns",
      "items_per_second": 5.3636705401134953e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.2429999000000000e+07,
      "advised_time": 2.6624000072479248e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 2.8470000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 5.2429999000000000e+07,
      "workspace_megabytes": 5.0001143455505371e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 718,
      "real_time": 9.6795948716477177e+05,
      "cpu_time": 9.8763743175335682e+05,
      "time_unit": "ns",
      "items_per_second": 1.3588727130023945e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 9.1238397359848022e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 7.1800000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 717,
      "real_time": 9.6843090551974182e+05,
      "cpu_time": 9.8814253556441877e+05,
      "time_unit": "ns",
      "items_per_second": 1.3582112331432473e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 9.1648000478744507e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 7.1700000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 723,
      "real_time": 9.6874060218749288e+05,
      "cpu_time": 9.8832524204846041e+05,
      "time_unit": "ns",
      "items_per_second": 1.3577770266156621e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 9.9020802974700928e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 7.2300000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 71,
      "real_time": 9.7827632504869513e+06,
      "cpu_time": 1.1216133042251572e+07,
      "time_unit": "ns",
      "items_per_second": 1.3445421306035667e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4956354560000000e+09,
      "advised_time": 9.7996797561645508e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 7.1000000000000000e+01,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.4956354560000000e+09,
      "workspace_megabytes": 2.3800234375000000e+03,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 71,
      "real_time": 9.8392838533495516e+06,
      "cpu_time": 1.1259254140846955e+07,
      "time_unit": "ns",
      "items_per_second": 1.3368185672905715e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4956354560000000e+09,
      "advised_time": 9.8119678497314453e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 7.1000000000000000e+01,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.4956354560000000e+09,
      "workspace_megabytes": 2.3800234375000000e+03,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 71,
      "real_time": 9.7829494494157769e+06,
      "cpu_time": 1.1196907887326015e+07,
      "time_unit": "ns",
      "items_per_second": 1.3445165399260544e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4956354560000000e+09,
      "advised_time": 9.7853441238403320e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 7.1000000000000000e+01,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.4956354560000000e+09,
      "workspace_megabytes": 2.3800234375000000e+03,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_32__10892439351607294794<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1580,
      "real_time": 4.4416522386533947e+05,
      "cpu_time": 4.5315023101237975e+05,
      "time_unit": "ns",
      "items_per_second": 3.7017017084130679e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.4953599572181702e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.5800000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1578,
      "real_time": 4.4524842374208552e+05,
      "cpu_time": 4.5419233016497886e+05,
      "time_unit": "ns",
      "items_per_second": 3.6926962125584072e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.4236800074577332e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.5780000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1577,
      "real_time": 4.4391209544355882e+05,
      "cpu_time": 4.5289267786964303e+05,
      "time_unit": "ns",
      "items_per_second": 3.7038124999886328e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.4953599572181702e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.5770000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1577,
      "real_time": 4.4412542098425044e+05,
      "cpu_time": 4.5308191312587872e+05,
      "time_unit": "ns",
      "items_per_second": 3.7020334579278799e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.4953599572181702e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.5770000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1577,
      "real_time": 4.4310759084468108e+05,
      "cpu_time": 4.5205263094607904e+05,
      "time_unit": "ns",
      "items_per_second": 3.7105371290656055e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.3929600715637207e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.5770000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4000,
      "real_time": 1.7463574484645505e+05,
      "cpu_time": 1.8124630375022831e+05,
      "time_unit": "ns",
      "items_per_second": 9.4148375491260430e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.7121943000000000e+07,
      "advised_time": 1.8227200210094452e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.0000000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 7.7121943000000000e+07,
      "workspace_megabytes": 7.3549216270446777e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4008,
      "real_time": 1.7483234453588276e+05,
      "cpu_time": 1.8143327145647170e+05,
      "time_unit": "ns",
      "items_per_second": 9.4042505256374316e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.7121943000000000e+07,
      "advised_time": 1.8227200210094452e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.0080000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 7.7121943000000000e+07,
      "workspace_megabytes": 7.3549216270446777e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4008,
      "real_time": 1.7488151829302969e+05,
      "cpu_time": 1.8120180039865983e+05,
      "time_unit": "ns",
      "items_per_second": 9.4016062077243086e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.7121943000000000e+07,
      "advised_time": 1.8329599499702454e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.0080000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 7.7121943000000000e+07,
      "workspace_megabytes": 7.3549216270446777e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3998,
      "real_time": 1.7459270530780978e+05,
      "cpu_time": 1.8095108654300144e+05,
      "time_unit": "ns",
      "items_per_second": 9.4171584379846035e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.7121943000000000e+07,
      "advised_time": 2.3142400383949280e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.9980000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 7.7121943000000000e+07,
      "workspace_megabytes": 7.3549216270446777e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4009,
      "real_time": 1.7494792831418390e+05,
      "cpu_time": 1.8123179770487506e+05,
      "time_unit": "ns",
      "items_per_second": 9.3980373694239355e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.7121943000000000e+07,
      "advised_time": 1.8227200210094452e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.0090000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 7.7121943000000000e+07,
      "workspace_megabytes": 7.3549216270446777e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 986,
      "real_time": 7.1004812569550145e+05,
      "cpu_time": 7.2179543711976637e+05,
      "time_unit": "ns",
      "items_per_second": 2.3155714500189922e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.1380224000000000e+07,
      "advised_time": 7.6697599887847900e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 9.8600000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 5.1380224000000000e+07,
      "workspace_megabytes": 4.9000000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 987,
      "real_time": 7.0993494223086163e+05,
      "cpu_time": 7.2200204559212422e+05,
      "time_unit": "ns",
      "items_per_second": 2.3159406168027979e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.1380224000000000e+07,
      "advised_time": 7.6083201169967651e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 9.8700000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 5.1380224000000000e+07,
      "workspace_megabytes": 4.9000000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 985,
      "real_time": 7.1011862379550794e+05,
      "cpu_time": 7.2199351269055717e+05,
      "time_unit": "ns",
      "items_per_second": 2.3153415681623770e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.1380224000000000e+07,
      "advised_time": 7.6185601949691772e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 9.8500000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 5.1380224000000000e+07,
      "workspace_megabytes": 4.9000000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 159,
      "real_time": 4.4722980731781926e+06,
      "cpu_time": 4.7594210628890665e+06,
      "time_unit": "ns",
      "items_per_second": 3.6763362841591406e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.3057049600000000e+08,
      "advised_time": 4.4523520469665527e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.5900000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 8.3057049600000000e+08,
      "workspace_megabytes": 7.9209375000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 159,
      "real_time": 4.4611890554287527e+06,
      "cpu_time": 4.7457530628933413e+06,
      "time_unit": "ns",
      "items_per_second": 3.6854909029224805e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.3057049600000000e+08,
      "advised_time": 4.4431362152099609e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.5900000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 8.3057049600000000e+08,
      "workspace_megabytes": 7.9209375000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 159,
      "real_time": 4.4685045415359847e+06,
      "cpu_time": 4.7467478113189712e+06,
      "time_unit": "ns",
      "items_per_second": 3.6794573054967535e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.3057049600000000e+08,
      "advised_time": 4.4083199501037598e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.5900000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 8.3057049600000000e+08,
      "workspace_megabytes": 7.9209375000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 587,
      "real_time": 1.1934312344076561e+06,
      "cpu_time": 1.2171456882468462e+06,
      "time_unit": "ns",
      "items_per_second": 1.3776806912683669e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.5820473600000000e+08,
      "advised_time": 1.2400640249252319e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.8700000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.5820473600000000e+08,
      "workspace_megabytes": 1.5087579345703125e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 587,
      "real_time": 1.1935339944303872e+06,
      "cpu_time": 1.2173757836457076e+06,
      "time_unit": "ns",
      "items_per_second": 1.3775620767171167e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.5820473600000000e+08,
      "advised_time": 1.2431360483169556e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.8700000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.5820473600000000e+08,
      "workspace_megabytes": 1.5087579345703125e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 587,
      "real_time": 1.1934545148938284e+06,
      "cpu_time": 1.2174042350944141e+06,
      "time_unit": "ns",
      "items_per_second": 1.3776538171178376e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.5820473600000000e+08,
      "advised_time": 1.2462079524993896e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.8700000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.5820473600000000e+08,
      "workspace_megabytes": 1.5087579345703125e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__14279887323636876103<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1777,
      "real_time": 3.9392626757477236e+05,
      "cpu_time": 4.0232468204731069e+05,
      "time_unit": "ns",
      "items_per_second": 4.1737941928127842e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.1164800524711609e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.7770000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1776,
      "real_time": 3.9417066721209988e+05,
      "cpu_time": 4.0259451013472263e+05,
      "time_unit": "ns",
      "items_per_second": 4.1712062940373179e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.8809600472450256e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.7760000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1779,
      "real_time": 3.9394710824077297e+05,
      "cpu_time": 4.0233836649820395e+05,
      "time_unit": "ns",
      "items_per_second": 4.1735733899463384e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.9116799831390381e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.7790000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1779,
      "real_time": 3.9293749873437925e+05,
      "cpu_time": 4.0133532265368104e+05,
      "time_unit": "ns",
      "items_per_second": 4.1842969258361270e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.8912001252174377e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.7790000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1779,
      "real_time": 3.9335840937321325e+05,
      "cpu_time": 4.0111471781864972e+05,
      "time_unit": "ns",
      "items_per_second": 4.1798195457924888e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.8912001252174377e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.7790000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5374,
      "real_time": 1.2928088367721246e+05,
      "cpu_time": 1.3548408578372278e+05,
      "time_unit": "ns",
      "items_per_second": 1.2717790296863566e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.7938551000000000e+07,
      "advised_time": 1.3619199395179749e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.3740000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 5.7938551000000000e+07,
      "workspace_megabytes": 5.5254508018493652e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5410,
      "real_time": 1.2989688162808522e+05,
      "cpu_time": 1.3615038336410458e+05,
      "time_unit": "ns",
      "items_per_second": 1.2657479897843152e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.7938551000000000e+07,
      "advised_time": 1.3926400244235992e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.4100000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 5.7938551000000000e+07,
      "workspace_megabytes": 5.5254508018493652e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5417,
      "real_time": 1.3070919583503016e+05,
      "cpu_time": 1.3691424736897630e+05,
      "time_unit": "ns",
      "items_per_second": 1.2578817867375801e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.7938551000000000e+07,
      "advised_time": 1.3414399325847626e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.4170000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 5.7938551000000000e+07,
      "workspace_megabytes": 5.5254508018493652e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5408,
      "real_time": 1.2931064732438460e+05,
      "cpu_time": 1.3551483450465073e+05,
      "time_unit": "ns",
      "items_per_second": 1.2714863021878580e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.7938551000000000e+07,
      "advised_time": 1.3414399325847626e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.4080000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 5.7938551000000000e+07,
      "workspace_megabytes": 5.5254508018493652e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5443,
      "real_time": 1.2979587696826497e+05,
      "cpu_time": 1.3600295259973430e+05,
      "time_unit": "ns",
      "items_per_second": 1.2667329705719375e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.7938551000000000e+07,
      "advised_time": 1.3414399325847626e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.4430000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 5.7938551000000000e+07,
      "workspace_megabytes": 5.5254508018493652e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1457,
      "real_time": 4.8037664211731002e+05,
      "cpu_time": 4.8881559025484941e+05,
      "time_unit": "ns",
      "items_per_second": 3.4226626023138057e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 4.8329600691795349e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.4570000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1454,
      "real_time": 4.8035803006208042e+05,
      "cpu_time": 4.8897651375477458e+05,
      "time_unit": "ns",
      "items_per_second": 3.4227952175328711e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 4.8742398619651794e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.4540000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1456,
      "real_time": 4.8106918614763883e+05,
      "cpu_time": 4.8976757074322004e+05,
      "time_unit": "ns",
      "items_per_second": 3.4177353597854624e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 4.8640000820159912e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.4560000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 286,
      "real_time": 2.4462708693740149e+06,
      "cpu_time": 2.5375916328676362e+06,
      "time_unit": "ns",
      "items_per_second": 6.7211165721019763e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.0633907200000000e+08,
      "advised_time": 2.4401919841766357e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.8600000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.0633907200000000e+08,
      "workspace_megabytes": 5.7825000000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 285,
      "real_time": 2.4502050270440807e+06,
      "cpu_time": 2.5374764421050651e+06,
      "time_unit": "ns",
      "items_per_second": 6.7103248497678491e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.0633907200000000e+08,
      "advised_time": 2.4514560699462891e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.8500000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.0633907200000000e+08,
      "workspace_megabytes": 5.7825000000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 286,
      "real_time": 2.4497377762727281e+06,
      "cpu_time": 2.5371006678314018e+06,
      "time_unit": "ns",
      "items_per_second": 6.7116047436783105e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.0633907200000000e+08,
      "advised_time": 2.4524800777435303e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.8600000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.0633907200000000e+08,
      "workspace_megabytes": 5.7825000000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 831,
      "real_time": 8.4038600867735187e+05,
      "cpu_time": 8.5503979422190506e+05,
      "time_unit": "ns",
      "items_per_second": 1.9564428144010696e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.6901152000000000e+07,
      "advised_time": 8.6937600374221802e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 8.3100000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 8.6901152000000000e+07,
      "workspace_megabytes": 8.2875396728515625e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 833,
      "real_time": 8.4101397113422875e+05,
      "cpu_time": 8.5540826410581486e+05,
      "time_unit": "ns",
      "items_per_second": 1.9549819913010522e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.6901152000000000e+07,
      "advised_time": 8.6323201656341553e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 8.3300000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 8.6901152000000000e+07,
      "workspace_megabytes": 8.2875396728515625e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 833,
      "real_time": 8.4007557314940216e+05,
      "cpu_time": 8.5459097238918149e+05,
      "time_unit": "ns",
      "items_per_second": 1.9571657843068782e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.6901152000000000e+07,
      "advised_time": 8.6220800876617432e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 8.3300000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 8.6901152000000000e+07,
      "workspace_megabytes": 8.2875396728515625e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__15078829952593902432<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 864,
      "real_time": 8.1117674529162259e+05,
      "cpu_time": 8.2671154166692996e+05,
      "time_unit": "ns",
      "items_per_second": 1.6215131191009799e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 8.2124799489974976e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 8.6400000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 864,
      "real_time": 8.1123307703550102e+05,
      "cpu_time": 8.2549231944508117e+05,
      "time_unit": "ns",
      "items_per_second": 1.6214005217916410e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 8.3865600824356079e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 8.6400000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 862,
      "real_time": 8.0810873480211163e+05,
      "cpu_time": 8.2362634802833828e+05,
      "time_unit": "ns",
      "items_per_second": 1.6276692451815863e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 8.3148801326751709e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 8.6200000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 861,
      "real_time": 8.1149134743021976e+05,
      "cpu_time": 8.2559961904812616e+05,
      "time_unit": "ns",
      "items_per_second": 1.6208844845546621e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 8.2841598987579346e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 8.6100000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 861,
      "real_time": 8.1150424810024758e+05,
      "cpu_time": 8.2704988966326043e+05,
      "time_unit": "ns",
      "items_per_second": 1.6208587169805094e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 8.2124799489974976e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 8.6100000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3328,
      "real_time": 2.0863589569531681e+05,
      "cpu_time": 2.1544402614119655e+05,
      "time_unit": "ns",
      "items_per_second": 6.3044459823963305e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.9884731000000000e+07,
      "advised_time": 2.1503999829292297e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 3.3280000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.9884731000000000e+07,
      "workspace_megabytes": 2.8500300407409668e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3327,
      "real_time": 2.0929746835702917e+05,
      "cpu_time": 2.1611435707863129e+05,
      "time_unit": "ns",
      "items_per_second": 6.2845181297474828e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.9884731000000000e+07,
      "advised_time": 2.2627200186252594e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 3.3270000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.9884731000000000e+07,
      "workspace_megabytes": 2.8500300407409668e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3330,
      "real_time": 2.0972679063430271e+05,
      "cpu_time": 2.1649238768788480e+05,
      "time_unit": "ns",
      "items_per_second": 6.2716533754313078e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.9884731000000000e+07,
      "advised_time": 1.9353599846363068e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 3.3300000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.9884731000000000e+07,
      "workspace_megabytes": 2.8500300407409668e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3329,
      "real_time": 2.0839421941239087e+05,
      "cpu_time": 2.1519461309707526e+05,
      "time_unit": "ns",
      "items_per_second": 6.3117572939827516e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.9884731000000000e+07,
      "advised_time": 2.1401600539684296e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 3.3290000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.9884731000000000e+07,
      "workspace_megabytes": 2.8500300407409668e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3326,
      "real_time": 2.0888480216331789e+05,
      "cpu_time": 2.1531545009044078e+05,
      "time_unit": "ns",
      "items_per_second": 6.2969336245515750e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.9884731000000000e+07,
      "advised_time": 1.9148799777030945e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 3.3260000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.9884731000000000e+07,
      "workspace_megabytes": 2.8500300407409668e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 711,
      "real_time": 9.7918802973488148e+05,
      "cpu_time": 9.9905261181558052e+05,
      "time_unit": "ns",
      "items_per_second": 1.3432902511646625e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2112640000000000e+06,
      "advised_time": 9.8710399866104126e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 7.1100000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.2112640000000000e+06,
      "workspace_megabytes": 3.0625000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 711,
      "real_time": 9.7854258299382124e+05,
      "cpu_time": 9.9651589029510459e+05,
      "time_unit": "ns",
      "items_per_second": 1.3441762854875221e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2112640000000000e+06,
      "advised_time": 9.8816001415252686e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 7.1100000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.2112640000000000e+06,
      "workspace_megabytes": 3.0625000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 711,
      "real_time": 9.7850567647144618e+05,
      "cpu_time": 9.9667019127958873e+05,
      "time_unit": "ns",
      "items_per_second": 1.3442269840918832e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2112640000000000e+06,
      "advised_time": 9.8713600635528564e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 7.1100000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.2112640000000000e+06,
      "workspace_megabytes": 3.0625000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 18,
      "real_time": 3.8259429443213671e+07,
      "cpu_time": 5.9363732111115217e+07,
      "time_unit": "ns",
      "items_per_second": 3.4379334808227502e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 9.5546490880000000e+09,
      "advised_time": -1.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.8000000000000000e+01,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 9.5546490880000000e+09,
      "workspace_megabytes": 9.1120234375000000e+03,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 18,
      "real_time": 3.8164936833911471e+07,
      "cpu_time": 5.9240229277773120e+07,
      "time_unit": "ns",
      "items_per_second": 3.4464454641288953e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 9.5546490880000000e+09,
      "advised_time": -1.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.8000000000000000e+01,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 9.5546490880000000e+09,
      "workspace_megabytes": 9.1120234375000000e+03,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 18,
      "real_time": 3.8148209866550237e+07,
      "cpu_time": 5.9212709555551000e+07,
      "time_unit": "ns",
      "items_per_second": 3.4479566380736871e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 9.5546490880000000e+09,
      "advised_time": -1.0000000000000000e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.8000000000000000e+01,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 9.5546490880000000e+09,
      "workspace_megabytes": 9.1120234375000000e+03,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_32__3658150069958588101<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1587,
      "real_time": 4.3943619433169562e+05,
      "cpu_time": 4.4845380592312402e+05,
      "time_unit": "ns",
      "items_per_second": 3.7415378824233770e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.4339200854301453e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.5870000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1592,
      "real_time": 4.4075760261469224e+05,
      "cpu_time": 4.4978306218620122e+05,
      "time_unit": "ns",
      "items_per_second": 3.7303206076227832e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.4134399294853210e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.5920000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1590,
      "real_time": 4.3965516022169299e+05,
      "cpu_time": 4.4785460880506202e+05,
      "time_unit": "ns",
      "items_per_second": 3.7396744466070649e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.5670399069786072e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.5900000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1584,
      "real_time": 4.3944215830186184e+05,
      "cpu_time": 4.4763025063056085e+05,
      "time_unit": "ns",
      "items_per_second": 3.7414871034530732e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.4441598653793335e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.5840000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1594,
      "real_time": 4.4075934194616153e+05,
      "cpu_time": 4.4979556399031484e+05,
      "time_unit": "ns",
      "items_per_second": 3.7303058869727461e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.4134399294853210e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.5940000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6852,
      "real_time": 1.0198233343718565e+05,
      "cpu_time": 1.0822468826626737e+05,
      "time_unit": "ns",
      "items_per_second": 1.6122078330485525e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6548155000000000e+07,
      "advised_time": 1.3107199966907501e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 6.8520000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.6548155000000000e+07,
      "workspace_megabytes": 1.5781550407409668e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6870,
      "real_time": 1.0198010204264487e+05,
      "cpu_time": 1.0833814454130323e+05,
      "time_unit": "ns",
      "items_per_second": 1.6122431092611195e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6548155000000000e+07,
      "advised_time": 1.4336000382900238e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 6.8700000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.6548155000000000e+07,
      "workspace_megabytes": 1.5781550407409668e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6862,
      "real_time": 1.0206609897247846e+05,
      "cpu_time": 1.0844037088300692e+05,
      "time_unit": "ns",
      "items_per_second": 1.6108846958512057e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6548155000000000e+07,
      "advised_time": 1.4336000382900238e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 6.8620000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.6548155000000000e+07,
      "workspace_megabytes": 1.5781550407409668e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6855,
      "real_time": 1.0191116407062733e+05,
      "cpu_time": 1.0825512005834040e+05,
      "time_unit": "ns",
      "items_per_second": 1.6133337137239896e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6548155000000000e+07,
      "advised_time": 9.9327996373176575e-02,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 6.8550000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.6548155000000000e+07,
      "workspace_megabytes": 1.5781550407409668e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6864,
      "real_time": 1.0194992624653821e+05,
      "cpu_time": 1.0833083551830015e+05,
      "time_unit": "ns",
      "items_per_second": 1.6127203113654328e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6548155000000000e+07,
      "advised_time": 9.9327996373176575e-02,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 6.8640000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.6548155000000000e+07,
      "workspace_megabytes": 1.5781550407409668e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1170,
      "real_time": 5.8987090860604926e+05,
      "cpu_time": 6.0118745982839190e+05,
      "time_unit": "ns",
      "items_per_second": 2.7873338793489683e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6056320000000000e+06,
      "advised_time": 6.8505597114562988e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.1700000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.6056320000000000e+06,
      "workspace_megabytes": 1.5312500000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1175,
      "real_time": 5.8999486663874157e+05,
      "cpu_time": 6.0010484680773551e+05,
      "time_unit": "ns",
      "items_per_second": 2.7867482599755166e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6056320000000000e+06,
      "advised_time": 6.7993599176406860e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.1750000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.6056320000000000e+06,
      "workspace_megabytes": 1.5312500000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1171,
      "real_time": 5.9137803622275707e+05,
      "cpu_time": 6.0158158838573366e+05,
      "time_unit": "ns",
      "items_per_second": 2.7802303556987095e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6056320000000000e+06,
      "advised_time": 6.8198400735855103e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.1710000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.6056320000000000e+06,
      "workspace_megabytes": 1.5312500000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 85,
      "real_time": 8.1739161930540027e+06,
      "cpu_time": 9.0898870941192824e+06,
      "time_unit": "ns",
      "items_per_second": 2.0114803347227533e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4578621440000000e+09,
      "advised_time": 8.2012157440185547e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 8.5000000000000000e+01,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.4578621440000000e+09,
      "workspace_megabytes": 2.3440000000000000e+03,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 85,
      "real_time": 8.1619549761800207e+06,
      "cpu_time": 9.0986505764710587e+06,
      "time_unit": "ns",
      "items_per_second": 2.0144281275728226e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4578621440000000e+09,
      "advised_time": 8.2001924514770508e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 8.5000000000000000e+01,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.4578621440000000e+09,
      "workspace_megabytes": 2.3440000000000000e+03,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 84,
      "real_time": 8.1728354229458738e+06,
      "cpu_time": 9.1216923333349973e+06,
      "time_unit": "ns",
      "items_per_second": 2.0117463314920941e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4578621440000000e+09,
      "advised_time": 8.1776638031005859e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 8.4000000000000000e+01,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.4578621440000000e+09,
      "workspace_megabytes": 2.3440000000000000e+03,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 250,
      "real_time": 2.7942339032888412e+06,
      "cpu_time": 2.9050818719981639e+06,
      "time_unit": "ns",
      "items_per_second": 5.8841429347228186e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.2059459200000000e+08,
      "advised_time": 2.8446719646453857e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.5000000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.2059459200000000e+08,
      "workspace_megabytes": 2.1037539672851562e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 250,
      "real_time": 2.7942015165463090e+06,
      "cpu_time": 2.9064541240004473e+06,
      "time_unit": "ns",
      "items_per_second": 5.8842111360394104e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.2059459200000000e+08,
      "advised_time": 2.8487679958343506e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.5000000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.2059459200000000e+08,
      "workspace_megabytes": 2.1037539672851562e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 250,
      "real_time": 2.7926978906616569e+06,
      "cpu_time": 2.9045062760021663e+06,
      "time_unit": "ns",
      "items_per_second": 5.8873792739910632e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.2059459200000000e+08,
      "advised_time": 2.8272960186004639e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.5000000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.2059459200000000e+08,
      "workspace_megabytes": 2.1037539672851562e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__3644933935944624745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1366,
      "real_time": 5.1210037913953402e+05,
      "cpu_time": 5.2202198096598854e+05,
      "time_unit": "ns",
      "items_per_second": 3.2106345454433013e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.2428799867630005e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.3660000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1367,
      "real_time": 5.1223680139577191e+05,
      "cpu_time": 5.2216438844235003e+05,
      "time_unit": "ns",
      "items_per_second": 3.2097794682457026e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.2220797538757324e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.3670000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1366,
      "real_time": 5.1213596319564310e+05,
      "cpu_time": 5.2207466105379700e+05,
      "time_unit": "ns",
      "items_per_second": 3.2104114652301914e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.2223998308181763e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.3660000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1367,
      "real_time": 5.1212149018853705e+05,
      "cpu_time": 5.2204802706501080e+05,
      "time_unit": "ns",
      "items_per_second": 3.2105021943029600e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.2223998308181763e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.3670000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1367,
      "real_time": 5.1221557033242111e+05,
      "cpu_time": 5.2130893269834411e+05,
      "time_unit": "ns",
      "items_per_second": 3.2099125118999355e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.2223998308181763e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.3670000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5104,
      "real_time": 1.3703616907983233e+05,
      "cpu_time": 1.4327069592438720e+05,
      "time_unit": "ns",
      "items_per_second": 1.1998052623918344e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.9793071000000000e+07,
      "advised_time": 1.5257599949836731e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 5.1040000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.9793071000000000e+07,
      "workspace_megabytes": 1.8876143455505371e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5102,
      "real_time": 1.3695919103599642e+05,
      "cpu_time": 1.4324164758934954e+05,
      "time_unit": "ns",
      "items_per_second": 1.2004796140829059e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.9793071000000000e+07,
      "advised_time": 1.4131200313568115e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 5.1020000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.9793071000000000e+07,
      "workspace_megabytes": 1.8876143455505371e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5110,
      "real_time": 1.3707223182695382e+05,
      "cpu_time": 1.4330170078275545e+05,
      "time_unit": "ns",
      "items_per_second": 1.1994896020046355e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.9793071000000000e+07,
      "advised_time": 1.4233599603176117e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 5.1100000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.9793071000000000e+07,
      "workspace_megabytes": 1.8876143455505371e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5108,
      "real_time": 1.3730151899404731e+05,
      "cpu_time": 1.4353824784706792e+05,
      "time_unit": "ns",
      "items_per_second": 1.1974865100154375e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.9793071000000000e+07,
      "advised_time": 1.4233599603176117e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 5.1080000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.9793071000000000e+07,
      "workspace_megabytes": 1.8876143455505371e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5096,
      "real_time": 1.3706645535524358e+05,
      "cpu_time": 1.4334813206412943e+05,
      "time_unit": "ns",
      "items_per_second": 1.1995401527957447e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.9793071000000000e+07,
      "advised_time": 1.4028799533843994e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 5.0960000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.9793071000000000e+07,
      "workspace_megabytes": 1.8876143455505371e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1044,
      "real_time": 6.7178724310004024e+05,
      "cpu_time": 6.8420564367916621e+05,
      "time_unit": "ns",
      "items_per_second": 2.4474522028920938e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2845056000000000e+07,
      "advised_time": 6.8403202295303345e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.0440000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.2845056000000000e+07,
      "workspace_megabytes": 1.2250000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1044,
      "real_time": 6.7169121261400625e+05,
      "cpu_time": 6.8296237260577048e+05,
      "time_unit": "ns",
      "items_per_second": 2.4478021107369116e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2845056000000000e+07,
      "advised_time": 6.8095999956130981e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.0440000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.2845056000000000e+07,
      "workspace_megabytes": 1.2250000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1044,
      "real_time": 6.7180554244008951e+05,
      "cpu_time": 6.8300226532562077e+05,
      "time_unit": "ns",
      "items_per_second": 2.4473855366363315e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2845056000000000e+07,
      "advised_time": 6.7993599176406860e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.0440000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.2845056000000000e+07,
      "workspace_megabytes": 1.2250000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 246,
      "real_time": 2.8275225540562496e+06,
      "cpu_time": 2.9430607926821182e+06,
      "time_unit": "ns",
      "items_per_second": 5.8148684460229834e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.8052582400000000e+08,
      "advised_time": 2.8334081172943115e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.4600000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.8052582400000000e+08,
      "workspace_megabytes": 6.4900000000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 248,
      "real_time": 2.8277098956037192e+06,
      "cpu_time": 2.9420425362891289e+06,
      "time_unit": "ns",
      "items_per_second": 5.8144831991294800e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.8052582400000000e+08,
      "advised_time": 2.8293120861053467e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.4800000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.8052582400000000e+08,
      "workspace_megabytes": 6.4900000000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 248,
      "real_time": 2.8278826737791421e+06,
      "cpu_time": 2.9483641088697440e+06,
      "time_unit": "ns",
      "items_per_second": 5.8141279454241235e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.8052582400000000e+08,
      "advised_time": 2.8344318866729736e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.4800000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.8052582400000000e+08,
      "workspace_megabytes": 6.4900000000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 448,
      "real_time": 1.5647377778285383e+06,
      "cpu_time": 1.6053607098213923e+06,
      "time_unit": "ns",
      "items_per_second": 1.0507621093431321e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1363984000000000e+08,
      "advised_time": 1.6138240098953247e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.4800000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.1363984000000000e+08,
      "workspace_megabytes": 1.0837539672851562e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 448,
      "real_time": 1.5635405590208913e+06,
      "cpu_time": 1.6004822098208496e+06,
      "time_unit": "ns",
      "items_per_second": 1.0515666885095697e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1363984000000000e+08,
      "advised_time": 1.6148480176925659e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.4800000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.1363984000000000e+08,
      "workspace_megabytes": 1.0837539672851562e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 447,
      "real_time": 1.5632078620361402e+06,
      "cpu_time": 1.6040213445191698e+06,
      "time_unit": "ns",
      "items_per_second": 1.0517904930815836e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1363984000000000e+08,
      "advised_time": 1.6158720254898071e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.4700000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.1363984000000000e+08,
      "workspace_megabytes": 1.0837539672851562e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__4472721870803484840<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4927,
      "real_time": 1.4146483681709165e+05,
      "cpu_time": 1.4801139090673422e+05,
      "time_unit": "ns",
      "items_per_second": 2.9056110426328804e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.3516800105571747e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.9270000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4949,
      "real_time": 1.4133878288064475e+05,
      "cpu_time": 1.4784976581174720e+05,
      "time_unit": "ns",
      "items_per_second": 2.9082024312258950e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.3516800105571747e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.9490000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4946,
      "real_time": 1.4133273042725067e+05,
      "cpu_time": 1.4785288091340478e+05,
      "time_unit": "ns",
      "items_per_second": 2.9083269725095898e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.3619199395179749e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.9460000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4945,
      "real_time": 1.4149697931366620e+05,
      "cpu_time": 1.4804062952503646e+05,
      "time_unit": "ns",
      "items_per_second": 2.9049510031504990e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.3721600174903870e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.9450000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4946,
      "real_time": 1.4153466117634220e+05,
      "cpu_time": 1.4806046482014711e+05,
      "time_unit": "ns",
      "items_per_second": 2.9041775956765176e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.3619199395179749e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.9460000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 7397,
      "real_time": 9.4797694487062210e+04,
      "cpu_time": 1.0111269136150417e+05,
      "time_unit": "ns",
      "items_per_second": 4.3359893320622700e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.8562199000000000e+07,
      "advised_time": 1.0137599706649780e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 7.3970000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.8562199000000000e+07,
      "workspace_megabytes": 3.6775778770446777e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 7377,
      "real_time": 9.4704394851445046e+04,
      "cpu_time": 1.0099586213893195e+05,
      "time_unit": "ns",
      "items_per_second": 4.3402610052550068e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.8562199000000000e+07,
      "advised_time": 1.0134399682283401e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 7.3770000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.8562199000000000e+07,
      "workspace_megabytes": 3.6775778770446777e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 7343,
      "real_time": 9.4702954169426012e+04,
      "cpu_time": 1.0104819842042799e+05,
      "time_unit": "ns",
      "items_per_second": 4.3403270320864092e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.8562199000000000e+07,
      "advised_time": 9.9327996373176575e-02,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 7.3430000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.8562199000000000e+07,
      "workspace_megabytes": 3.6775778770446777e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 7385,
      "real_time": 9.4922852615383497e+04,
      "cpu_time": 1.0110519390712822e+05,
      "time_unit": "ns",
      "items_per_second": 4.3302722229123701e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.8562199000000000e+07,
      "advised_time": 1.0035199671983719e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 7.3850000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.8562199000000000e+07,
      "workspace_megabytes": 3.6775778770446777e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 7351,
      "real_time": 9.4778687142411130e+04,
      "cpu_time": 1.0098192041908462e+05,
      "time_unit": "ns",
      "items_per_second": 4.3368588908852793e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.8562199000000000e+07,
      "advised_time": 1.0035199671983719e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 7.3510000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.8562199000000000e+07,
      "workspace_megabytes": 3.6775778770446777e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3361,
      "real_time": 2.0826560706657360e+05,
      "cpu_time": 2.1474098066033004e+05,
      "time_unit": "ns",
      "items_per_second": 1.9736422052086956e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2845056000000000e+07,
      "advised_time": 2.2118400037288666e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.3610000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.2845056000000000e+07,
      "workspace_megabytes": 1.2250000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3362,
      "real_time": 2.0831764959114543e+05,
      "cpu_time": 2.1478408090476718e+05,
      "time_unit": "ns",
      "items_per_second": 1.9731491441398799e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2845056000000000e+07,
      "advised_time": 2.2323200106620789e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.3620000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.2845056000000000e+07,
      "workspace_megabytes": 1.2250000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3359,
      "real_time": 2.0824967473422334e+05,
      "cpu_time": 2.1474611193839781e+05,
      "time_unit": "ns",
      "items_per_second": 1.9737932005156221e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2845056000000000e+07,
      "advised_time": 2.2425599396228790e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.3590000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.2845056000000000e+07,
      "workspace_megabytes": 1.2250000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 721,
      "real_time": 9.6991542772287899e+05,
      "cpu_time": 9.8739218724090268e+05,
      "time_unit": "ns",
      "items_per_second": 4.2379137422839453e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.0771635200000000e+08,
      "advised_time": 1.0106879472732544e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 7.2100000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.0771635200000000e+08,
      "workspace_megabytes": 1.9809375000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 720,
      "real_time": 9.6996862258593971e+05,
      "cpu_time": 9.8944219027864549e+05,
      "time_unit": "ns",
      "items_per_second": 4.2376813273006830e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.0771635200000000e+08,
      "advised_time": 9.8508799076080322e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 7.2000000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.0771635200000000e+08,
      "workspace_megabytes": 1.9809375000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 720,
      "real_time": 9.6956484461164405e+05,
      "cpu_time": 9.8910958749808883e+05,
      "time_unit": "ns",
      "items_per_second": 4.2394461214674237e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.0771635200000000e+08,
      "advised_time": 9.9430400133132935e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 7.2000000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.0771635200000000e+08,
      "workspace_megabytes": 1.9809375000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1735,
      "real_time": 4.0351763786680950e+05,
      "cpu_time": 4.1126427953908843e+05,
      "time_unit": "ns",
      "items_per_second": 1.0186464070640551e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.2948160000000000e+07,
      "advised_time": 4.3212801218032837e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.7350000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.2948160000000000e+07,
      "workspace_megabytes": 6.0032043457031250e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1734,
      "real_time": 4.0351675069451035e+05,
      "cpu_time": 4.1193205997750151e+05,
      "time_unit": "ns",
      "items_per_second": 1.0186486466609824e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.2948160000000000e+07,
      "advised_time": 4.3110400438308716e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.7340000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.2948160000000000e+07,
      "workspace_megabytes": 6.0032043457031250e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1734,
      "real_time": 4.0344865446171217e+05,
      "cpu_time": 4.1183096828102565e+05,
      "time_unit": "ns",
      "items_per_second": 1.0188205796557153e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.2948160000000000e+07,
      "advised_time": 4.3417599797248840e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.7340000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.2948160000000000e+07,
      "workspace_megabytes": 6.0032043457031250e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__13825374536048850819<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 631,
      "real_time": 1.1097175691264982e+06,
      "cpu_time": 1.1333948985731741e+06,
      "time_unit": "ns",
      "items_per_second": 3.7040216667340588e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1192320585250854e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 6.3100000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 631,
      "real_time": 1.1097371447964229e+06,
      "cpu_time": 1.1333918288423507e+06,
      "time_unit": "ns",
      "items_per_second": 3.7039563281033014e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1366399526596069e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 6.3100000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 631,
      "real_time": 1.1096444405635993e+06,
      "cpu_time": 1.1333094690983077e+06,
      "time_unit": "ns",
      "items_per_second": 3.7042657717568329e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1202559471130371e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 6.3100000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 631,
      "real_time": 1.1096992120353384e+06,
      "cpu_time": 1.1333096767035357e+06,
      "time_unit": "ns",
      "items_per_second": 3.7040829401518073e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1427839994430542e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 6.3100000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 631,
      "real_time": 1.1096667548532342e+06,
      "cpu_time": 1.1333166925525113e+06,
      "time_unit": "ns",
      "items_per_second": 3.7041912826735522e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1089919805526733e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 6.3100000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3637,
      "real_time": 1.9236699391398678e+05,
      "cpu_time": 1.9907277151473431e+05,
      "time_unit": "ns",
      "items_per_second": 2.1367584097290073e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0814639000000000e+07,
      "advised_time": 1.9660800695419312e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.6370000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.0814639000000000e+07,
      "workspace_megabytes": 1.0313643455505371e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3638,
      "real_time": 1.9246633257864093e+05,
      "cpu_time": 1.9916105799895807e+05,
      "time_unit": "ns",
      "items_per_second": 2.1356555533267100e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0814639000000000e+07,
      "advised_time": 2.1913599967956543e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.6380000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.0814639000000000e+07,
      "workspace_megabytes": 1.0313643455505371e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3643,
      "real_time": 1.9223816089533811e+05,
      "cpu_time": 1.9892642986529559e+05,
      "time_unit": "ns",
      "items_per_second": 2.1381904096751482e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0814639000000000e+07,
      "advised_time": 2.0070399343967438e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.6430000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.0814639000000000e+07,
      "workspace_megabytes": 1.0313643455505371e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3636,
      "real_time": 1.9242818192865726e+05,
      "cpu_time": 1.9877707068246516e+05,
      "time_unit": "ns",
      "items_per_second": 2.1360789666058044e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0814639000000000e+07,
      "advised_time": 2.0272000133991241e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.6360000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.0814639000000000e+07,
      "workspace_megabytes": 1.0313643455505371e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3634,
      "real_time": 1.9248292464377865e+05,
      "cpu_time": 1.9923682113401141e+05,
      "time_unit": "ns",
      "items_per_second": 2.1354714594071165e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0814639000000000e+07,
      "advised_time": 2.2630399465560913e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.6340000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.0814639000000000e+07,
      "workspace_megabytes": 1.0313643455505371e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 599,
      "real_time": 1.1691687543501763e+06,
      "cpu_time": 1.1945646427374487e+06,
      "time_unit": "ns",
      "items_per_second": 3.5156754785878357e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.8901376000000000e+07,
      "advised_time": 1.1724799871444702e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 5.9900000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.8901376000000000e+07,
      "workspace_megabytes": 2.7562500000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 599,
      "real_time": 1.1692252744747968e+06,
      "cpu_time": 1.1946820751262095e+06,
      "time_unit": "ns",
      "items_per_second": 3.5155055315121838e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.8901376000000000e+07,
      "advised_time": 1.1776000261306763e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 5.9900000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.8901376000000000e+07,
      "workspace_megabytes": 2.7562500000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 599,
      "real_time": 1.1692368664478695e+06,
      "cpu_time": 1.1946536594325968e+06,
      "time_unit": "ns",
      "items_per_second": 3.5154706783129504e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.8901376000000000e+07,
      "advised_time": 1.1786240339279175e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 5.9900000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.8901376000000000e+07,
      "workspace_megabytes": 2.7562500000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 895,
      "real_time": 7.7192757172020955e+05,
      "cpu_time": 7.8669584469354711e+05,
      "time_unit": "ns",
      "items_per_second": 5.3248751185815259e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.7222860800000000e+08,
      "advised_time": 7.8233599662780762e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 8.9500000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.7222860800000000e+08,
      "workspace_megabytes": 1.6425000000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 906,
      "real_time": 7.7636873358027975e+05,
      "cpu_time": 7.8944344702132116e+05,
      "time_unit": "ns",
      "items_per_second": 5.2944145509885681e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.7222860800000000e+08,
      "advised_time": 7.8131198883056641e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 9.0600000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.7222860800000000e+08,
      "workspace_megabytes": 1.6425000000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 908,
      "real_time": 7.7657697792575252e+05,
      "cpu_time": 7.8969648127668316e+05,
      "time_unit": "ns",
      "items_per_second": 5.2929948180784100e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.7222860800000000e+08,
      "advised_time": 7.8233599662780762e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 9.0800000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.7222860800000000e+08,
      "workspace_megabytes": 1.6425000000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 496,
      "real_time": 1.4319755296568356e+06,
      "cpu_time": 1.4645669637078776e+06,
      "time_unit": "ns",
      "items_per_second": 2.8704526263692767e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.5654041600000000e+08,
      "advised_time": 1.5093760490417480e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.9600000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.5654041600000000e+08,
      "workspace_megabytes": 3.4002343750000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 489,
      "real_time": 1.4131722956560629e+06,
      "cpu_time": 1.4455212474444106e+06,
      "time_unit": "ns",
      "items_per_second": 2.9086459822591876e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.5654041600000000e+08,
      "advised_time": 1.5226880311965942e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.8900000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.5654041600000000e+08,
      "workspace_megabytes": 3.4002343750000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 495,
      "real_time": 1.4324560627397716e+06,
      "cpu_time": 1.4648012343431301e+06,
      "time_unit": "ns",
      "items_per_second": 2.8694897015816693e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.5654041600000000e+08,
      "advised_time": 1.5175679922103882e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.9500000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.5654041600000000e+08,
      "workspace_megabytes": 3.4002343750000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1197,
      "real_time": 5.8421900711016869e+05,
      "cpu_time": 5.9409774185429397e+05,
      "time_unit": "ns",
      "items_per_second": 7.0357483580209509e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.3744640000000000e+06,
      "advised_time": 6.4307200908660889e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 6.7907396577335429e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.1970000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 5.3744640000000000e+06,
      "workspace_megabytes": 5.1254882812500000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1199,
      "real_time": 5.8416979992490343e+05,
      "cpu_time": 5.9517688407012285e+05,
      "time_unit": "ns",
      "items_per_second": 7.0363410099741626e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.3744640000000000e+06,
      "advised_time": 6.2976002693176270e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 6.7907396577335429e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.1990000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 5.3744640000000000e+06,
      "workspace_megabytes": 5.1254882812500000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1198,
      "real_time": 5.8427841501902847e+05,
      "cpu_time": 5.9526784056819160e+05,
      "time_unit": "ns",
      "items_per_second": 7.0350329814359717e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.3744640000000000e+06,
      "advised_time": 6.3795202970504761e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 6.7907396577335429e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.1980000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 5.3744640000000000e+06,
      "workspace_megabytes": 5.1254882812500000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2048,
      "real_time": 3.4198222206782701e+05,
      "cpu_time": 3.4981473535122821e+05,
      "time_unit": "ns",
      "items_per_second": 1.2019390643016409e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7185920000000000e+07,
      "advised_time": 3.4815999865531921e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.6915749020158575e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.0480000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 4.7185920000000000e+07,
      "workspace_megabytes": 4.5000000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2047,
      "real_time": 3.4189896154923539e+05,
      "cpu_time": 3.4972532144606835e+05,
      "time_unit": "ns",
      "items_per_second": 1.2022317650146116e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7185920000000000e+07,
      "advised_time": 3.5328000783920288e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.6915749020158575e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.0470000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 4.7185920000000000e+07,
      "workspace_megabytes": 4.5000000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2047,
      "real_time": 3.4196455515664053e+05,
      "cpu_time": 3.4976035075780208e+05,
      "time_unit": "ns",
      "items_per_second": 1.2020011600667732e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7185920000000000e+07,
      "advised_time": 3.5228800773620605e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.6915749020158575e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.0470000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 4.7185920000000000e+07,
      "workspace_megabytes": 4.5000000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_32__1838390466059574295<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 933,
      "real_time": 7.4952159800376080e+05,
      "cpu_time": 7.6228184030059108e+05,
      "time_unit": "ns",
      "items_per_second": 1.7548977079555754e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 7.2806400060653687e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 9.3300000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 934,
      "real_time": 7.4944788373446360e+05,
      "cpu_time": 7.6230176873721241e+05,
      "time_unit": "ns",
      "items_per_second": 1.7550703163584289e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 7.3625600337982178e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 9.3400000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 934,
      "real_time": 7.4954251144270808e+05,
      "cpu_time": 7.6214672483970865e+05,
      "time_unit": "ns",
      "items_per_second": 1.7548487434932350e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 7.3830401897430420e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 9.3400000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 934,
      "real_time": 7.4937857268178719e+05,
      "cpu_time": 7.6353226552425500e+05,
      "time_unit": "ns",
      "items_per_second": 1.7552326452207457e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 7.2703999280929565e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 9.3400000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 934,
      "real_time": 7.4957204647102987e+05,
      "cpu_time": 7.6373188650992070e+05,
      "time_unit": "ns",
      "items_per_second": 1.7547795980287219e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 7.2809600830078125e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 9.3400000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1651,
      "real_time": 4.2400331250736001e+05,
      "cpu_time": 4.3269477649885061e+05,
      "time_unit": "ns",
      "items_per_second": 3.1021779679543613e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0302731900000000e+08,
      "advised_time": 4.3110400438308716e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.6510000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.0302731900000000e+08,
      "workspace_megabytes": 9.8254508018493652e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1651,
      "real_time": 4.2405923011460016e+05,
      "cpu_time": 4.3271079527575191e+05,
      "time_unit": "ns",
      "items_per_second": 3.1017689063023977e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0302731900000000e+08,
      "advised_time": 4.3007999658584595e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.6510000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.0302731900000000e+08,
      "workspace_megabytes": 9.8254508018493652e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1651,
      "real_time": 4.2398319395130972e+05,
      "cpu_time": 4.3182873955148837e+05,
      "time_unit": "ns",
      "items_per_second": 3.1023251703487402e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0302731900000000e+08,
      "advised_time": 4.4339200854301453e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.6510000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.0302731900000000e+08,
      "workspace_megabytes": 9.8254508018493652e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1651,
      "real_time": 4.2403944097301370e+05,
      "cpu_time": 4.3194651059973490e+05,
      "time_unit": "ns",
      "items_per_second": 3.1019136601581105e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0302731900000000e+08,
      "advised_time": 4.3622401356697083e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.6510000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.0302731900000000e+08,
      "workspace_megabytes": 9.8254508018493652e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1651,
      "real_time": 4.2400711142982071e+05,
      "cpu_time": 4.3187752453060716e+05,
      "time_unit": "ns",
      "items_per_second": 3.1021501737659105e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0302731900000000e+08,
      "advised_time": 4.3212801218032837e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.6510000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.0302731900000000e+08,
      "workspace_megabytes": 9.8254508018493652e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 752,
      "real_time": 9.3105178398508672e+05,
      "cpu_time": 9.4950025797757565e+05,
      "time_unit": "ns",
      "items_per_second": 1.4127396102181449e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2845056000000000e+07,
      "advised_time": 9.3388801813125610e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 7.5200000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.2845056000000000e+07,
      "workspace_megabytes": 1.2250000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 752,
      "real_time": 9.3080561062843702e+05,
      "cpu_time": 9.4919745877539099e+05,
      "time_unit": "ns",
      "items_per_second": 1.4131132423148453e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2845056000000000e+07,
      "advised_time": 9.3593597412109375e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 7.5200000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.2845056000000000e+07,
      "workspace_megabytes": 1.2250000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 752,
      "real_time": 9.3098361282906635e+05,
      "cpu_time": 9.4932375531933748e+05,
      "time_unit": "ns",
      "items_per_second": 1.4128430578954803e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2845056000000000e+07,
      "advised_time": 9.3491202592849731e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 7.5200000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.2845056000000000e+07,
      "workspace_megabytes": 1.2250000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 98,
      "real_time": 7.1838716548696468e+06,
      "cpu_time": 7.9168926734652994e+06,
      "time_unit": "ns",
      "items_per_second": 1.8309538332417036e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.8438400000000000e+08,
      "advised_time": 7.2110080718994141e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 9.8000000000000000e+01,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 7.8438400000000000e+08,
      "workspace_megabytes": 7.4804687500000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 98,
      "real_time": 7.1743631222266322e+06,
      "cpu_time": 7.9058560612246981e+06,
      "time_unit": "ns",
      "items_per_second": 1.8333804854747490e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.8438400000000000e+08,
      "advised_time": 7.1987199783325195e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 9.8000000000000000e+01,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 7.8438400000000000e+08,
      "workspace_megabytes": 7.4804687500000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 98,
      "real_time": 7.1825035277525987e+06,
      "cpu_time": 7.9160035102101658e+06,
      "time_unit": "ns",
      "items_per_second": 1.8313025943080422e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.8438400000000000e+08,
      "advised_time": 7.2478718757629395e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 9.8000000000000000e+01,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 7.8438400000000000e+08,
      "workspace_megabytes": 7.4804687500000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__13376775725398321751<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2314,
      "real_time": 3.0254014086671727e+05,
      "cpu_time": 3.0956793085581652e+05,
      "time_unit": "ns",
      "items_per_second": 1.0869084434811117e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.0310401320457458e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.3140000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2314,
      "real_time": 3.0256128570510843e+05,
      "cpu_time": 3.0948789801303385e+05,
      "time_unit": "ns",
      "items_per_second": 1.0868324836525771e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.0412799119949341e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.3140000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2304,
      "real_time": 3.0267102804120642e+05,
      "cpu_time": 3.0975423741323262e+05,
      "time_unit": "ns",
      "items_per_second": 1.0864384203803998e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.1334400177001953e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.3040000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2315,
      "real_time": 3.0257989027382521e+05,
      "cpu_time": 3.0950314427663106e+05,
      "time_unit": "ns",
      "items_per_second": 1.0867656581619359e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.0310401320457458e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.3150000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2314,
      "real_time": 3.0259779352990969e+05,
      "cpu_time": 3.0951298617052747e+05,
      "time_unit": "ns",
      "items_per_second": 1.0867013594647943e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.0412799119949341e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.3140000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6065,
      "real_time": 1.1153640410277812e+05,
      "cpu_time": 1.1775506924927571e+05,
      "time_unit": "ns",
      "items_per_second": 2.9482162012053742e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.7105211000000000e+07,
      "advised_time": 1.5155200660228729e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 6.0650000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.7105211000000000e+07,
      "workspace_megabytes": 1.6312800407409668e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6038,
      "real_time": 1.1133987178328865e+05,
      "cpu_time": 1.1771716263653820e+05,
      "time_unit": "ns",
      "items_per_second": 2.9534202647551066e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.7105211000000000e+07,
      "advised_time": 1.1571200191974640e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 6.0380000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.7105211000000000e+07,
      "workspace_megabytes": 1.6312800407409668e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6071,
      "real_time": 1.1175404664342175e+05,
      "cpu_time": 1.1797944457227914e+05,
      "time_unit": "ns",
      "items_per_second": 2.9424745096633719e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.7105211000000000e+07,
      "advised_time": 1.3516800105571747e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 6.0710000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.7105211000000000e+07,
      "workspace_megabytes": 1.6312800407409668e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6035,
      "real_time": 1.1137587032006944e+05,
      "cpu_time": 1.1758793786252881e+05,
      "time_unit": "ns",
      "items_per_second": 2.9524656701223160e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.7105211000000000e+07,
      "advised_time": 1.1568000167608261e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 6.0350000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.7105211000000000e+07,
      "workspace_megabytes": 1.6312800407409668e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6035,
      "real_time": 1.1148472327920134e+05,
      "cpu_time": 1.1765892709191841e+05,
      "time_unit": "ns",
      "items_per_second": 2.9495829018337562e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.7105211000000000e+07,
      "advised_time": 1.1571200191974640e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 6.0350000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.7105211000000000e+07,
      "workspace_megabytes": 1.6312800407409668e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1462,
      "real_time": 4.7553665710249392e+05,
      "cpu_time": 4.8496122776776232e+05,
      "time_unit": "ns",
      "items_per_second": 6.9149965347282471e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2112640000000000e+06,
      "advised_time": 4.8435199260711670e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.4620000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.2112640000000000e+06,
      "workspace_megabytes": 3.0625000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1466,
      "real_time": 4.7644114635260915e+05,
      "cpu_time": 4.8589937039526587e+05,
      "time_unit": "ns",
      "items_per_second": 6.9018689111421494e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2112640000000000e+06,
      "advised_time": 4.8640000820159912e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.4660000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.2112640000000000e+06,
      "workspace_megabytes": 3.0625000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1468,
      "real_time": 4.7640281297442218e+05,
      "cpu_time": 4.8584462738356914e+05,
      "time_unit": "ns",
      "items_per_second": 6.9024242646034688e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2112640000000000e+06,
      "advised_time": 4.8332801461219788e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.4680000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.2112640000000000e+06,
      "workspace_megabytes": 3.0625000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 73,
      "real_time": 9.4868831515108068e+06,
      "cpu_time": 1.0814257890412953e+07,
      "time_unit": "ns",
      "items_per_second": 3.4661904057249042e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4956354560000000e+09,
      "advised_time": 9.4658555984497070e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 7.3000000000000000e+01,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.4956354560000000e+09,
      "workspace_megabytes": 2.3800234375000000e+03,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 74,
      "real_time": 9.5122672013334334e+06,
      "cpu_time": 1.0832167945940873e+07,
      "time_unit": "ns",
      "items_per_second": 3.4569406708203491e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4956354560000000e+09,
      "advised_time": 9.4668798446655273e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 7.4000000000000000e+01,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.4956354560000000e+09,
      "workspace_megabytes": 2.3800234375000000e+03,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 73,
      "real_time": 9.4697266332294848e+06,
      "cpu_time": 1.0796713150680199e+07,
      "time_unit": "ns",
      "items_per_second": 3.4724701814106866e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4956354560000000e+09,
      "advised_time": 9.5006399154663086e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 7.3000000000000000e+01,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.4956354560000000e+09,
      "workspace_megabytes": 2.3800234375000000e+03,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__11780059200872913080<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 563,
      "real_time": 1.2431327289972806e+06,
      "cpu_time": 1.2687134120756492e+06,
      "time_unit": "ns",
      "items_per_second": 3.3064996392746344e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.2625919580459595e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.6300000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 564,
      "real_time": 1.2431015844245488e+06,
      "cpu_time": 1.2687868156036425e+06,
      "time_unit": "ns",
      "items_per_second": 3.3065824800655988e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.2769279479980469e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.6400000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 564,
      "real_time": 1.2413112292683797e+06,
      "cpu_time": 1.2669764024849832e+06,
      "time_unit": "ns",
      "items_per_second": 3.3113515958625885e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.2441279888153076e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.6400000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 563,
      "real_time": 1.2412788305054444e+06,
      "cpu_time": 1.2669390603877481e+06,
      "time_unit": "ns",
      "items_per_second": 3.3114380258352203e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.2625919580459595e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.6300000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 563,
      "real_time": 1.2413424883884764e+06,
      "cpu_time": 1.2670758259321912e+06,
      "time_unit": "ns",
      "items_per_second": 3.3112682103842163e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.2625919580459595e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.6300000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2980,
      "real_time": 2.3425066298762202e+05,
      "cpu_time": 2.4078902650891550e+05,
      "time_unit": "ns",
      "items_per_second": 1.7547091938080010e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 9.5358030000000000e+06,
      "advised_time": 2.6624000072479248e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.9800000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 9.5358030000000000e+06,
      "workspace_megabytes": 9.0940504074096680e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2979,
      "real_time": 2.3408338469201489e+05,
      "cpu_time": 2.4051127290971307e+05,
      "time_unit": "ns",
      "items_per_second": 1.7559631263056560e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 9.5358030000000000e+06,
      "advised_time": 2.4268800020217896e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.9790000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 9.5358030000000000e+06,
      "workspace_megabytes": 9.0940504074096680e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2981,
      "real_time": 2.3400734893635387e+05,
      "cpu_time": 2.4091142804558622e+05,
      "time_unit": "ns",
      "items_per_second": 1.7565336895115913e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 9.5358030000000000e+06,
      "advised_time": 2.4371199309825897e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.9810000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 9.5358030000000000e+06,
      "workspace_megabytes": 9.0940504074096680e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2985,
      "real_time": 2.3424822247335204e+05,
      "cpu_time": 2.4116211356664382e+05,
      "time_unit": "ns",
      "items_per_second": 1.7547274752394756e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 9.5358030000000000e+06,
      "advised_time": 2.4473600089550018e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.9850000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 9.5358030000000000e+06,
      "workspace_megabytes": 9.0940504074096680e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2982,
      "real_time": 2.3430813097511811e+05,
      "cpu_time": 2.4118576324708422e+05,
      "time_unit": "ns",
      "items_per_second": 1.7542788220339216e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 9.5358030000000000e+06,
      "advised_time": 2.4473600089550018e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.9820000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 9.5358030000000000e+06,
      "workspace_megabytes": 9.0940504074096680e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 526,
      "real_time": 1.3295704903463505e+06,
      "cpu_time": 1.3579697566538726e+06,
      "time_unit": "ns",
      "items_per_second": 3.0915381695401831e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.4450688000000000e+07,
      "advised_time": 1.3373440504074097e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.2600000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.4450688000000000e+07,
      "workspace_megabytes": 1.3781250000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 526,
      "real_time": 1.3292282775483544e+06,
      "cpu_time": 1.3578114733803985e+06,
      "time_unit": "ns",
      "items_per_second": 3.0923340929680695e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.4450688000000000e+07,
      "advised_time": 1.3393599987030029e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.2600000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.4450688000000000e+07,
      "workspace_megabytes": 1.3781250000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 526,
      "real_time": 1.3292375294679331e+06,
      "cpu_time": 1.3576183384050364e+06,
      "time_unit": "ns",
      "items_per_second": 3.0923125693308685e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.4450688000000000e+07,
      "advised_time": 1.3475840091705322e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.2600000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.4450688000000000e+07,
      "workspace_megabytes": 1.3781250000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 249,
      "real_time": 2.7921731568813086e+06,
      "cpu_time": 2.9113142409630152e+06,
      "time_unit": "ns",
      "items_per_second": 1.4721214226524164e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.5116569600000000e+08,
      "advised_time": 2.8241920471191406e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.4900000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.5116569600000000e+08,
      "workspace_megabytes": 6.2100000000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 250,
      "real_time": 2.7928739069029689e+06,
      "cpu_time": 2.9067292079980690e+06,
      "time_unit": "ns",
      "items_per_second": 1.4717520579216058e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.5116569600000000e+08,
      "advised_time": 2.8211519718170166e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.5000000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.5116569600000000e+08,
      "workspace_megabytes": 6.2100000000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 250,
      "real_time": 2.7925869300961494e+06,
      "cpu_time": 2.9050571560005667e+06,
      "time_unit": "ns",
      "items_per_second": 1.4719033007357367e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.5116569600000000e+08,
      "advised_time": 2.8252160549163818e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.5000000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 6.5116569600000000e+08,
      "workspace_megabytes": 6.2100000000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 137,
      "real_time": 4.9564884125805683e+06,
      "cpu_time": 5.3236264233598448e+06,
      "time_unit": "ns",
      "items_per_second": 8.2930041954036026e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2834816000000000e+09,
      "advised_time": 5.1947841644287109e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.3700000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.2834816000000000e+09,
      "workspace_megabytes": 1.2240234375000000e+03,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 136,
      "real_time": 4.9413272816523472e+06,
      "cpu_time": 5.3219815220603216e+06,
      "time_unit": "ns",
      "items_per_second": 8.3184490435644714e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2834816000000000e+09,
      "advised_time": 5.1783680915832520e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.3600000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.2834816000000000e+09,
      "workspace_megabytes": 1.2240234375000000e+03,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 140,
      "real_time": 4.9156094169510258e+06,
      "cpu_time": 5.2842863500026325e+06,
      "time_unit": "ns",
      "items_per_second": 8.3619701472326141e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2834816000000000e+09,
      "advised_time": 5.1599359512329102e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.4000000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 1.2834816000000000e+09,
      "workspace_megabytes": 1.2240234375000000e+03,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 472,
      "real_time": 1.4315084051104041e+06,
      "cpu_time": 1.4688760953370323e+06,
      "time_unit": "ns",
      "items_per_second": 2.8713893018902582e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.1496832000000000e+07,
      "advised_time": 1.5042560100555420e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 6.7907396577335429e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 4.7200000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.1496832000000000e+07,
      "workspace_megabytes": 2.0500976562500000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 485,
      "real_time": 1.4312566101992715e+06,
      "cpu_time": 1.4652060824777642e+06,
      "time_unit": "ns",
      "items_per_second": 2.8718944532439319e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.1496832000000000e+07,
      "advised_time": 1.5226880311965942e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 6.7907396577335429e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 4.8500000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.1496832000000000e+07,
      "workspace_megabytes": 2.0500976562500000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 487,
      "real_time": 1.4301052989220168e+06,
      "cpu_time": 1.4665618747416527e+06,
      "time_unit": "ns",
      "items_per_second": 2.8742064819271326e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.1496832000000000e+07,
      "advised_time": 1.5073280334472656e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 6.7907396577335429e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 4.8700000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.1496832000000000e+07,
      "workspace_megabytes": 2.0500976562500000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1895,
      "real_time": 3.6700894866608043e+05,
      "cpu_time": 3.7504988601575186e+05,
      "time_unit": "ns",
      "items_per_second": 1.1199775740999231e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.6623104000000000e+07,
      "advised_time": 3.8297599554061890e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.6915749020158575e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.8950000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 5.6623104000000000e+07,
      "workspace_megabytes": 5.4000000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1900,
      "real_time": 3.6734430689217616e+05,
      "cpu_time": 3.7538226368305431e+05,
      "time_unit": "ns",
      "items_per_second": 1.1189551172781616e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.6623104000000000e+07,
      "advised_time": 3.8604798913002014e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.6915749020158575e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.9000000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 5.6623104000000000e+07,
      "workspace_megabytes": 5.4000000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1904,
      "real_time": 3.6690328063535265e+05,
      "cpu_time": 3.7423816018872935e+05,
      "time_unit": "ns",
      "items_per_second": 1.1203001272929868e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.6623104000000000e+07,
      "advised_time": 3.8195198774337769e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.6915749020158575e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.9040000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 5.6623104000000000e+07,
      "workspace_megabytes": 5.4000000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__12678942444603697681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1824,
      "real_time": 3.8257849164916767e+05,
      "cpu_time": 3.9081346381570667e+05,
      "time_unit": "ns",
      "items_per_second": 4.2975943600816304e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.8195198774337769e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.8240000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1828,
      "real_time": 3.8302365071265050e+05,
      "cpu_time": 3.9136917177262862e+05,
      "time_unit": "ns",
      "items_per_second": 4.2925995951969980e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.8092800974845886e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.8280000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1829,
      "real_time": 3.8269904072708596e+05,
      "cpu_time": 3.9099445489317458e+05,
      "time_unit": "ns",
      "items_per_second": 4.2962406304344629e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.8396799564361572e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.8290000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1828,
      "real_time": 3.8286303780123155e+05,
      "cpu_time": 3.9037021115706721e+05,
      "time_unit": "ns",
      "items_per_second": 4.2944003616603789e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.9219200611114502e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.8280000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1831,
      "real_time": 3.8286269861001347e+05,
      "cpu_time": 3.9062905406798876e+05,
      "time_unit": "ns",
      "items_per_second": 4.2944041662171948e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.9116799831390381e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.8310000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6661,
      "real_time": 1.0450233880196372e+05,
      "cpu_time": 1.1065871100474375e+05,
      "time_unit": "ns",
      "items_per_second": 1.5733304984836420e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.8670967000000000e+07,
      "advised_time": 1.0956799983978271e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 6.6610000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.8670967000000000e+07,
      "workspace_megabytes": 3.6879508018493652e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6709,
      "real_time": 1.0508158906123630e+05,
      "cpu_time": 1.1124309092245626e+05,
      "time_unit": "ns",
      "items_per_second": 1.5646576937867408e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.8670967000000000e+07,
      "advised_time": 1.0956799983978271e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 6.7090000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.8670967000000000e+07,
      "workspace_megabytes": 3.6879508018493652e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6708,
      "real_time": 1.0495649336755110e+05,
      "cpu_time": 1.1114744752595249e+05,
      "time_unit": "ns",
      "items_per_second": 1.5665225802106680e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.8670967000000000e+07,
      "advised_time": 1.4336000382900238e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 6.7080000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.8670967000000000e+07,
      "workspace_megabytes": 3.6879508018493652e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6665,
      "real_time": 1.0438104223905184e+05,
      "cpu_time": 1.1053642985803475e+05,
      "time_unit": "ns",
      "items_per_second": 1.5751587958228602e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.8670967000000000e+07,
      "advised_time": 1.4745600521564484e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 6.6650000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.8670967000000000e+07,
      "workspace_megabytes": 3.6879508018493652e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6685,
      "real_time": 1.0495790302800990e+05,
      "cpu_time": 1.1111024173442341e+05,
      "time_unit": "ns",
      "items_per_second": 1.5665015406807666e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.8670967000000000e+07,
      "advised_time": 1.3516800105571747e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 6.6850000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 3.8670967000000000e+07,
      "workspace_megabytes": 3.6879508018493652e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1175,
      "real_time": 5.9521443165957613e+05,
      "cpu_time": 6.0513846978626540e+05,
      "time_unit": "ns",
      "items_per_second": 2.7623106573806270e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5690112000000000e+07,
      "advised_time": 6.0416001081466675e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.1750000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.5690112000000000e+07,
      "workspace_megabytes": 2.4500000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1175,
      "real_time": 5.9538930154187570e+05,
      "cpu_time": 6.0532907829944650e+05,
      "time_unit": "ns",
      "items_per_second": 2.7614993479763770e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5690112000000000e+07,
      "advised_time": 5.6524801254272461e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.1750000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.5690112000000000e+07,
      "workspace_megabytes": 2.4500000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1176,
      "real_time": 5.9518043264045008e+05,
      "cpu_time": 6.0523668027191760e+05,
      "time_unit": "ns",
      "items_per_second": 2.7624684512994487e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5690112000000000e+07,
      "advised_time": 6.0518401861190796e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 7.0488587744553958e+17,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.1760000000000000e+03,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 2.5690112000000000e+07,
      "workspace_megabytes": 2.4500000000000000e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 278,
      "real_time": 2.5241271853982974e+06,
      "cpu_time": 2.6208420035968041e+06,
      "time_unit": "ns",
      "items_per_second": 6.5138047619441052e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.1329382400000000e+08,
      "advised_time": 2.5425920486450195e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.7800000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 7.1329382400000000e+08,
      "workspace_megabytes": 6.8025000000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 277,
      "real_time": 2.5120576505720722e+06,
      "cpu_time": 2.6085262021655953e+06,
      "time_unit": "ns",
      "items_per_second": 6.5451012544460229e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.1329382400000000e+08,
      "advised_time": 2.5507841110229492e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.7700000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 7.1329382400000000e+08,
      "workspace_megabytes": 6.8025000000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 277,
      "real_time": 2.5242211092061731e+06,
      "cpu_time": 2.6212701335752555e+06,
      "time_unit": "ns",
      "items_per_second": 6.5135623896159558e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.1329382400000000e+08,
      "advised_time": 2.5405440330505371e+00,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 5.3915503001725706e+18,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.7700000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 7.1329382400000000e+08,
      "workspace_megabytes": 6.8025000000000000e+02,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 734,
      "real_time": 9.5216998064697639e+05,
      "cpu_time": 9.7104076430807810e+05,
      "time_unit": "ns",
      "items_per_second": 1.7267580383943928e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.6901152000000000e+07,
      "advised_time": 9.8713600635528564e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 7.3400000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 8.6901152000000000e+07,
      "workspace_megabytes": 8.2875396728515625e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 733,
      "real_time": 9.5258621153666917e+05,
      "cpu_time": 9.7147503819763043e+05,
      "time_unit": "ns",
      "items_per_second": 1.7260035344703379e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.6901152000000000e+07,
      "advised_time": 9.8099201917648315e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 7.3300000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 8.6901152000000000e+07,
      "workspace_megabytes": 8.2875396728515625e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 734,
      "real_time": 9.5219836179839505e+05,
      "cpu_time": 9.7107286239768483e+05,
      "time_unit": "ns",
      "items_per_second": 1.7267065707765967e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.6901152000000000e+07,
      "advised_time": 9.8816001415252686e-01,
      "batch_size": 3.2000000000000000e+01,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3111256115020788e+19,
      "bias_tensor_layout": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 3.2000000000000000e+01,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 3.2000000000000000e+01,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 7.3400000000000000e+02,
      "output_batch_size": 3.2000000000000000e+01,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 0.0000000000000000e+00,
      "workspace_bytes": 8.6901152000000000e+07,
      "workspace_megabytes": 8.2875396728515625e+01,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_32__3717872339074717591<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:32/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:32/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    }
  ]
}
