{
  "context": {
    "date": "2019-09-25 20:21:03",
    "executable": "./scope",
    "num_cpus": 8,
    "mhz_per_cpu": 3601,
    "cpu_scaling_enabled": true,
    "caches": [
      {
        "type": "Data",
        "level": 1,
        "size": 32000000,
        "num_sharing": 1
      },
      {
        "type": "Instruction",
        "level": 1,
        "size": 32000000,
        "num_sharing": 1
      },
      {
        "type": "Unified",
        "level": 2,
        "size": 1024000000,
        "num_sharing": 1
      },
      {
        "type": "Unified",
        "level": 3,
        "size": 11264000000,
        "num_sharing": 8
      }
    ],
    "library_build_type": "release"
  },
  "benchmarks": [
    {
      "name": "LAYER_CUBLAS_GEMM_FWD_FLOAT32__BatchSize_8__14833586761715734451/input[0]:8/input[1]:1000/input[2]:2048/input[3]:0/input[4]:1/input[5]:1/input[6]:1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 15560,
      "real_time": 4.4987613450395242e+04,
      "cpu_time": 5.1217859511568320e+04,
      "time_unit": "ns",
      "items_per_second": 3.6418913437285388e+11,
      "K": 2.0480000000000000e+03,
      "M": 8.0000000000000000e+00,
      "N": 1.0000000000000000e+03,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemm_fwd.cpp": 7.2770906096155412e+18,
      "benchmark_func:void iLAYER_CUBLAS_GEMM_FWD_Impl(benchmark::State&) [with T = float]": 7.4787548781531884e+18,
      "beta": 1.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMM_FWD_Impl": 1.7610984762236383e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0000000000000000e+03,
      "input[2]": 2.0480000000000000e+03,
      "input[3]": 0.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": 1.0000000000000000e+00,
      "input[6]": 1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "lda": 8.0000000000000000e+00,
      "ldb": 1.0000000000000000e+03,
      "num_iterations": 1.5560000000000000e+04,
      "predicted_flops": 7.2837826874570776e+11,
      "predicted_flops_count": 3.2768000000000000e+07,
      "transA": 0.0000000000000000e+00,
      "transB": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_8__2508734707905405705<CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 44223,
      "real_time": 1.5847051045150180e+04,
      "cpu_time": 2.2044657327635359e+04,
      "time_unit": "ns",
      "items_per_second": 5.0660277278888000e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 4.4223000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.0660277278888000e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_8__2508734707905405705<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 43968,
      "real_time": 1.5916618145932889e+04,
      "cpu_time": 2.2087646674855390e+04,
      "time_unit": "ns",
      "items_per_second": 5.0438855329650566e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 4.3968000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.0438855329650566e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_8__6120376001579986082<CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 24770,
      "real_time": 2.8245516858450505e+04,
      "cpu_time": 3.4443692692770950e+04,
      "time_unit": "ns",
      "items_per_second": 5.6845552094035278e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 2.4770000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 5.6845552094035278e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_8__6120376001579986082<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 24750,
      "real_time": 2.8274621281507098e+04,
      "cpu_time": 3.4459197535355132e+04,
      "time_unit": "ns",
      "items_per_second": 5.6787038242317932e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 2.4750000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 5.6787038242317932e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_8__6449059682728522274<CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 7351,
      "real_time": 9.5164015180524555e+04,
      "cpu_time": 1.0148983811725184e+05,
      "time_unit": "ns",
      "items_per_second": 6.7489039715448860e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 7.3510000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 6.7489039715448860e+10,
      "predicted_flops_count": 6.4225280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_8__6449059682728522274<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 7348,
      "real_time": 9.5198922657544259e+04,
      "cpu_time": 1.0151291303756266e+05,
      "time_unit": "ns",
      "items_per_second": 6.7464292879695015e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 7.3480000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 6.7464292879695015e+10,
      "predicted_flops_count": 6.4225280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_8__12392619029784752570<CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 7356,
      "real_time": 9.5160903166338292e+04,
      "cpu_time": 1.0146989817835038e+05,
      "time_unit": "ns",
      "items_per_second": 6.7491246786231331e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 7.3560000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 6.7491246786231331e+10,
      "predicted_flops_count": 6.4225280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_8__12392619029784752570<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 7349,
      "real_time": 9.5205959430005169e+04,
      "cpu_time": 1.0151304721730246e+05,
      "time_unit": "ns",
      "items_per_second": 6.7459306522947266e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 7.3490000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 6.7459306522947266e+10,
      "predicted_flops_count": 6.4225280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_8__1480150849994883458<CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 90732,
      "real_time": 7.7072238653251488e+03,
      "cpu_time": 1.3616634120267259e+04,
      "time_unit": "ns",
      "items_per_second": 5.2082047571751122e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 9.0732000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.2082047571751122e+10,
      "predicted_flops_count": 4.0140800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_8__1480150849994883458<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 90425,
      "real_time": 7.7408804531018686e+03,
      "cpu_time": 1.3638816212328598e+04,
      "time_unit": "ns",
      "items_per_second": 5.1855599945242760e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 9.0425000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.1855599945242760e+10,
      "predicted_flops_count": 4.0140800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_8__877134272634754350<CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 24784,
      "real_time": 2.8246670619816305e+04,
      "cpu_time": 3.4470047127176258e+04,
      "time_unit": "ns",
      "items_per_second": 5.6843230184925835e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 2.4784000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.6843230184925835e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_8__877134272634754350<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 24747,
      "real_time": 2.8276645924271175e+04,
      "cpu_time": 3.4464917121258528e+04,
      "time_unit": "ns",
      "items_per_second": 5.6782972220259346e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 2.4747000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.6782972220259346e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_8__16916288736664379921<CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 44204,
      "real_time": 1.5840703157663240e+04,
      "cpu_time": 2.2029636458241224e+04,
      "time_unit": "ns",
      "items_per_second": 5.0680578507755356e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 4.4204000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.0680578507755356e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_8__16916288736664379921<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 44022,
      "real_time": 1.5907433433444585e+04,
      "cpu_time": 2.2098298373518133e+04,
      "time_unit": "ns",
      "items_per_second": 5.0467977965076347e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 4.4022000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.0467977965076347e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_8__11722348554578645518<CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 99528,
      "real_time": 7.1197448263769229e+03,
      "cpu_time": 1.2975633942209635e+04,
      "time_unit": "ns",
      "items_per_second": 2.8189774338040947e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 9.9528000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.8189774338040947e+10,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_8__11722348554578645518<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 95641,
      "real_time": 7.3060844867090918e+03,
      "cpu_time": 1.2918174559025567e+04,
      "time_unit": "ns",
      "items_per_second": 2.7470801954879101e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 9.5641000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.7470801954879101e+10,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_8__13952687925410928534<CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 13155,
      "real_time": 5.0567968624550354e+04,
      "cpu_time": 5.6815808741933310e+04,
      "time_unit": "ns",
      "items_per_second": 6.3503915370667198e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.3155000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 6.3503915370667198e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_8__13952687925410928534<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 13829,
      "real_time": 5.0577278013693824e+04,
      "cpu_time": 5.6804594475369697e+04,
      "time_unit": "ns",
      "items_per_second": 6.3492226670058220e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.3829000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 6.3492226670058220e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_8__3955180099896498992<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:8/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 3424,
      "real_time": 2.0446354466283458e+05,
      "cpu_time": 2.1129461682242798e+05,
      "time_unit": "ns",
      "items_per_second": 3.1411604501872974e+10,
      "batch_size": 8.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.1200000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 3.4240000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 3.1411604501872974e+10,
      "predicted_flops_count": 6.4225280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_8__13080952564339887047<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:8/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 2396,
      "real_time": 2.9220338854942634e+05,
      "cpu_time": 2.9970747871451447e+05,
      "time_unit": "ns",
      "items_per_second": 2.1979649284298519e+10,
      "batch_size": 8.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.1200000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.3960000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 2.1979649284298519e+10,
      "predicted_flops_count": 6.4225280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_8__5570079899784366619<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 27079,
      "real_time": 2.5843330899109227e+04,
      "cpu_time": 3.2038997414962021e+04,
      "time_unit": "ns",
      "items_per_second": 3.1064726258938690e+10,
      "batch_size": 8.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.7079000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 3.1064726258938690e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_8__14855009558560004844<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 17842,
      "real_time": 3.9438964853318103e+04,
      "cpu_time": 4.5706263815705002e+04,
      "time_unit": "ns",
      "items_per_second": 2.0355909517043449e+10,
      "batch_size": 8.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.7842000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 2.0355909517043449e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_8__12555421662009753220<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 6672,
      "real_time": 1.0492734749303760e+05,
      "cpu_time": 1.1132038788969879e+05,
      "time_unit": "ns",
      "items_per_second": 3.0604642895533802e+10,
      "batch_size": 8.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 6.6720000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 3.0604642895533802e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_8__3266991199011303027<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 4565,
      "real_time": 1.5403918242900603e+05,
      "cpu_time": 1.6063772179629063e+05,
      "time_unit": "ns",
      "items_per_second": 2.0847059490724155e+10,
      "batch_size": 8.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.5650000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 2.0847059490724155e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_8__4283986814073947568<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 12780,
      "real_time": 5.4730765205790769e+04,
      "cpu_time": 6.0978229968699481e+04,
      "time_unit": "ns",
      "items_per_second": 2.9336918531336681e+10,
      "batch_size": 8.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.2780000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 2.9336918531336681e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_8__13265556224132601159<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 8751,
      "real_time": 7.9681712925138665e+04,
      "cpu_time": 8.6020381213565866e+04,
      "time_unit": "ns",
      "items_per_second": 2.0150570828070656e+10,
      "batch_size": 8.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 8.7510000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 2.0150570828070656e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_8__14152381087296592040<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 3423,
      "real_time": 2.0446445606336033e+05,
      "cpu_time": 2.1126406777688066e+05,
      "time_unit": "ns",
      "items_per_second": 3.1411464484613205e+10,
      "batch_size": 8.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 3.4230000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 3.1411464484613205e+10,
      "predicted_flops_count": 6.4225280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_8__5119508419727165535<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 2396,
      "real_time": 2.9223695086563652e+05,
      "cpu_time": 2.9969436018365476e+05,
      "time_unit": "ns",
      "items_per_second": 2.1977125004130375e+10,
      "batch_size": 8.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.3960000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 2.1977125004130375e+10,
      "predicted_flops_count": 6.4225280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_8__14785901570099559196<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 91953,
      "real_time": 7.5968549047908500e+03,
      "cpu_time": 1.3575691733829730e+04,
      "time_unit": "ns",
      "items_per_second": 2.6419354129487041e+10,
      "batch_size": 8.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 9.1953000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.6419354129487041e+10,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_8__5645663965042977771<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 55675,
      "real_time": 1.2581113776564445e+04,
      "cpu_time": 1.8498331872465456e+04,
      "time_unit": "ns",
      "items_per_second": 1.5952800647416662e+10,
      "batch_size": 8.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.5675000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 1.5952800647416662e+10,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_8__9610272853904034563<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 27076,
      "real_time": 2.5933160185094221e+04,
      "cpu_time": 3.2028215282927835e+04,
      "time_unit": "ns",
      "items_per_second": 3.0957121857498882e+10,
      "batch_size": 8.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.7076000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.0957121857498882e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_8__447530279498095604<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 17646,
      "real_time": 3.9220555162549870e+04,
      "cpu_time": 4.5490585911849448e+04,
      "time_unit": "ns",
      "items_per_second": 2.0469266604532326e+10,
      "batch_size": 8.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.7646000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.0469266604532326e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_8__7183243870126406716<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 12760,
      "real_time": 5.4749585842870816e+04,
      "cpu_time": 6.0975476645796465e+04,
      "time_unit": "ns",
      "items_per_second": 2.9326833715383736e+10,
      "batch_size": 8.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.2760000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.9326833715383736e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_8__16202680872826203339<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 8741,
      "real_time": 7.9674151486577277e+04,
      "cpu_time": 8.6004271250402962e+04,
      "time_unit": "ns",
      "items_per_second": 2.0152483208691608e+10,
      "batch_size": 8.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 8.7410000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.0152483208691608e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_8__8869482810187311248<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 58557,
      "real_time": 1.1934932828620866e+04,
      "cpu_time": 1.8068110524796921e+04,
      "time_unit": "ns",
      "items_per_second": 3.3633033864873829e+10,
      "batch_size": 8.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 5.8557000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 3.3633033864873829e+10,
      "predicted_flops_count": 4.0140800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_8__17905685168469145703<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 34784,
      "real_time": 2.0141142396054922e+04,
      "cpu_time": 2.6369045020660989e+04,
      "time_unit": "ns",
      "items_per_second": 1.9929753343019135e+10,
      "batch_size": 8.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.4784000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.9929753343019135e+10,
      "predicted_flops_count": 4.0140800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_8__1093605584666137853<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2943,
      "real_time": 2.3853325497753336e+05,
      "cpu_time": 2.4559885015288065e+05,
      "time_unit": "ns",
      "items_per_second": 1.3785643164554631e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.4063999950885773e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.9430000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.4464107911386577e+12,
      "predicted_advised_flops_count": 8.2208358400000000e+08,
      "predicted_flops": 3.4464107911386577e+12,
      "predicted_flops_count": 8.2208358400000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_8__1093605584666137853<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 3456,
      "real_time": 2.0225046150951835e+05,
      "cpu_time": 2.0908811429396863e+05,
      "time_unit": "ns",
      "items_per_second": 1.6258723522592523e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 2.0889599621295929e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.4560000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.0646808806481309e+12,
      "predicted_advised_flops_count": 8.2208358400000000e+08,
      "predicted_flops": 4.0646808806481309e+12,
      "predicted_flops_count": 8.2208358400000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_8__1093605584666137853<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1821,
      "real_time": 3.8498036866357579e+05,
      "cpu_time": 3.9335443986812560e+05,
      "time_unit": "ns",
      "items_per_second": 8.5415636839227734e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 3.8912001252174377e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.8210000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.1353909209806934e+12,
      "predicted_advised_flops_count": 8.2208358400000000e+08,
      "predicted_flops": 2.1353909209806934e+12,
      "predicted_flops_count": 8.2208358400000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_8__1093605584666137853<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_8__1093605584666137853<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_8__1093605584666137853<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 112,
      "real_time": 6.2392140056804884e+06,
      "cpu_time": 6.8040752410714692e+06,
      "time_unit": "ns",
      "items_per_second": 5.2704304308301300e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.2395187200000000e+08,
      "advised_time": 6.2238721847534180e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.1200000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.3176076077075325e+11,
      "predicted_advised_flops_count": 8.2208358400000000e+08,
      "predicted_flops": 1.3280924286132930e+12,
      "predicted_flops_count": 8.2862528814422722e+09,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 6.2395187200000000e+08,
      "workspace_megabytes": 5.9504687500000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_8__1093605584666137853<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_8__1093605584666137853<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_8__14503317905622524929<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 7760,
      "real_time": 8.8373134518012201e+04,
      "cpu_time": 9.4718393041170668e+04,
      "time_unit": "ns",
      "items_per_second": 9.3024151342333906e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.2160001397132874e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 7.7600000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.3256037835583477e+12,
      "predicted_advised_flops_count": 2.0552089600000000e+08,
      "predicted_flops": 2.3256037835583477e+12,
      "predicted_flops_count": 2.0552089600000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_8__14503317905622524929<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 7930,
      "real_time": 8.7165960422241391e+04,
      "cpu_time": 9.3081137704937384e+04,
      "time_unit": "ns",
      "items_per_second": 9.4312456378354316e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 9.0112000703811646e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 7.9300000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.3578114094588579e+12,
      "predicted_advised_flops_count": 2.0552089600000000e+08,
      "predicted_flops": 2.3578114094588579e+12,
      "predicted_flops_count": 2.0552089600000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_8__14503317905622524929<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2978,
      "real_time": 2.3428701314886895e+05,
      "cpu_time": 2.4132144795161422e+05,
      "time_unit": "ns",
      "items_per_second": 3.5088738933968896e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2112640000000000e+06,
      "advised_time": 2.3859199881553650e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.9780000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 8.7721847334922241e+11,
      "predicted_advised_flops_count": 2.0552089600000000e+08,
      "predicted_flops": 8.7721847334922241e+11,
      "predicted_flops_count": 2.0552089600000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.2112640000000000e+06,
      "workspace_megabytes": 3.0625000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_8__14503317905622524929<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_8__14503317905622524929<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_8__14503317905622524929<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 290,
      "real_time": 2.4229288189511360e+06,
      "cpu_time": 2.5151828724136357e+06,
      "time_unit": "ns",
      "items_per_second": 3.3929332862360870e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.9718860800000000e+08,
      "advised_time": 2.3941121101379395e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.9000000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 8.4823332155902176e+10,
      "predicted_advised_flops_count": 2.0552089600000000e+08,
      "predicted_flops": 7.6618368556290918e+11,
      "predicted_flops_count": 1.8564085323605680e+09,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 5.9718860800000000e+08,
      "workspace_megabytes": 5.6952343750000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_8__14503317905622524929<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_8__14503317905622524929<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_8__1835841509207708859<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1498,
      "real_time": 4.6611421926348691e+05,
      "cpu_time": 4.7625807610137318e+05,
      "time_unit": "ns",
      "items_per_second": 2.2046194634948724e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.6793600916862488e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.4980000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -2.1453968977391696e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 1.9841575171453853e+12,
      "predicted_flops_count": 9.2484403200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_8__1835841509207708859<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1181,
      "real_time": 5.8010984087957477e+05,
      "cpu_time": 5.9218553090583254e+05,
      "time_unit": "ns",
      "items_per_second": 1.7713963935552695e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 5.8367997407913208e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.1810000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -1.7238114741921613e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 1.5942567541997424e+12,
      "predicted_flops_count": 9.2484403200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_8__1835841509207708859<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1599,
      "real_time": 4.3576931827855977e+05,
      "cpu_time": 4.4480412695431075e+05,
      "time_unit": "ns",
      "items_per_second": 2.3581386685492105e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.2253440000000000e+06,
      "advised_time": 4.3827199935913086e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.5990000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -2.2947921252242986e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 2.1223248016942893e+12,
      "predicted_flops_count": 9.2484403200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.2253440000000000e+06,
      "workspace_megabytes": 6.8906250000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_8__1835841509207708859<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_8__1835841509207708859<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 252,
      "real_time": 2.7552183961407058e+06,
      "cpu_time": 2.8761964563494124e+06,
      "time_unit": "ns",
      "items_per_second": 3.7296661543759575e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.2285414400000000e+08,
      "advised_time": 2.7545599937438965e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.5200000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -3.6294763471408351e+02,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 6.4290910683753868e+10,
      "predicted_flops_count": 1.7713549982051772e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.2285414400000000e+08,
      "workspace_megabytes": 5.9400000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_8__1835841509207708859<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 145,
      "real_time": 4.7941352272855826e+06,
      "cpu_time": 5.1407469862067895e+06,
      "time_unit": "ns",
      "items_per_second": 2.1434616073227142e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1765268480000000e+09,
      "advised_time": 4.9817600250244141e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.4500000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -2.0858819215372768e+02,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 3.6948373673808746e+10,
      "predicted_flops_count": 1.7713549982051772e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1765268480000000e+09,
      "workspace_megabytes": 1.1220234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_8__1835841509207708859<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2290,
      "real_time": 3.0657949227805139e+05,
      "cpu_time": 3.1462387292572303e+05,
      "time_unit": "ns",
      "items_per_second": 3.3518369815421869e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.6216448000000000e+07,
      "advised_time": 3.4201601147651672e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnMathType_t math_type = (cudnnMathType_t)0]": 5.7500739770702787e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.2900000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -3.2617967776300343e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": -3.2617967776300343e+03,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.6216448000000000e+07,
      "workspace_megabytes": 2.5001953125000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_8__1835841509207708859<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1996,
      "real_time": 3.4871603647643095e+05,
      "cpu_time": 3.5720340230475995e+05,
      "time_unit": "ns",
      "items_per_second": 2.9468231240046625e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7185920000000000e+07,
      "advised_time": 3.7683200836181641e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.2538945752816425e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.9960000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -2.8676627840359961e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": -2.8676627840359961e+03,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7185920000000000e+07,
      "workspace_megabytes": 4.5000000000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__15590784223998854129<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2650,
      "real_time": 2.6450300857178721e+05,
      "cpu_time": 2.7171442075483111e+05,
      "time_unit": "ns",
      "items_per_second": 3.8850389095710559e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.5190401077270508e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.6500000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -3.7806753329559792e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 3.4965350186139502e+12,
      "predicted_flops_count": 9.2484403200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__15590784223998854129<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 3314,
      "real_time": 2.1106358826206517e+05,
      "cpu_time": 2.1716760289665993e+05,
      "time_unit": "ns",
      "items_per_second": 4.8686961520055475e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 2.1299199759960175e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.3140000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -4.7379086475037038e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 4.3818265368049927e+12,
      "predicted_flops_count": 9.2484403200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__15590784223998854129<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1668,
      "real_time": 4.1830756828762317e+05,
      "cpu_time": 4.2709819484426262e+05,
      "time_unit": "ns",
      "items_per_second": 2.4565763517179105e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.7802752000000000e+07,
      "advised_time": 4.2905598878860474e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.6680000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -2.3905854825758547e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 2.2109187165461191e+12,
      "predicted_flops_count": 9.2484403200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.7802752000000000e+07,
      "workspace_megabytes": 5.5125000000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__15590784223998854129<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__15590784223998854129<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1976,
      "real_time": 3.5714814634128805e+05,
      "cpu_time": 3.6518380921034707e+05,
      "time_unit": "ns",
      "items_per_second": 2.8772499326316785e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.5586099200000000e+08,
      "advised_time": 3.9628800749778748e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.9760000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -2.7999585332984134e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 8.0988785445874573e+11,
      "predicted_flops_count": 2.8924994596426392e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.5586099200000000e+08,
      "workspace_megabytes": 1.4864062500000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__15590784223998854129<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2151,
      "real_time": 3.2622552647738991e+05,
      "cpu_time": 3.3379618828433973e+05,
      "time_unit": "ns",
      "items_per_second": 3.1499818272842035e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.6787840000000000e+07,
      "advised_time": 3.6556801199913025e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.1510000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -3.0653640467626255e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 8.8665638488688684e+11,
      "predicted_flops_count": 2.8924994596426392e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.6787840000000000e+07,
      "workspace_megabytes": 2.5546875000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__15590784223998854129<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5771,
      "real_time": 1.2094660013085585e+05,
      "cpu_time": 1.2739058499404961e+05,
      "time_unit": "ns",
      "items_per_second": 8.4963486273132361e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.0985600000000000e+05,
      "advised_time": 1.4336000382900238e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnMathType_t math_type = (cudnnMathType_t)0]": 5.7500739770702787e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.7710000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -8.2681117031654412e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": -8.2681117031654412e+03,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.0985600000000000e+05,
      "workspace_megabytes": 3.9086914062500000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__15590784223998854129<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2712,
      "real_time": 2.5672812851360149e+05,
      "cpu_time": 2.6385690892334096e+05,
      "time_unit": "ns",
      "items_per_second": 4.0026953257891931e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.8392576000000000e+07,
      "advised_time": 2.8876799345016479e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.2538945752816425e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.7120000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -3.8951711516372457e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": -3.8951711516372457e+03,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.8392576000000000e+07,
      "workspace_megabytes": 5.5687500000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__11951679115028441018<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 4848,
      "real_time": 1.4464000684978353e+05,
      "cpu_time": 1.5119373102302261e+05,
      "time_unit": "ns",
      "items_per_second": 2.8418264140908755e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.5769599378108978e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.8480000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.8418264140908755e+12,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 2.8418264140908755e+12,
      "predicted_flops_count": 4.1104179200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__11951679115028441018<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 4860,
      "real_time": 1.4399856862474573e+05,
      "cpu_time": 1.5026825020576280e+05,
      "time_unit": "ns",
      "items_per_second": 2.8544852627747832e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 1.4643199741840363e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.8600000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.8544852627747832e+12,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 2.8544852627747832e+12,
      "predicted_flops_count": 4.1104179200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__11951679115028441018<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2461,
      "real_time": 2.8317270140863321e+05,
      "cpu_time": 2.9060252986585617e+05,
      "time_unit": "ns",
      "items_per_second": 1.4515586776383677e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 2.8569599986076355e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.4610000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.4515586776383677e+12,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 1.4515586776383677e+12,
      "predicted_flops_count": 4.1104179200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__11951679115028441018<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__11951679115028441018<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 258,
      "real_time": 2.6985979259967110e+06,
      "cpu_time": 2.8101681434111823e+06,
      "time_unit": "ns",
      "items_per_second": 1.5231679682262564e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.2390272000000000e+08,
      "advised_time": 2.7002880573272705e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.5800000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.5231679682262564e+11,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 3.0296114469487433e+11,
      "predicted_flops_count": 8.1757031673117745e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.2390272000000000e+08,
      "workspace_megabytes": 5.9500000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__11951679115028441018<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1134,
      "real_time": 6.1270267643302190e+05,
      "cpu_time": 6.2423204585575766e+05,
      "time_unit": "ns",
      "items_per_second": 6.7086665002504419e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.5148960000000000e+07,
      "advised_time": 6.6150397062301636e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.1340000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 6.7086665002504419e+11,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 1.3343671378927800e+12,
      "predicted_flops_count": 8.1757031673117745e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.5148960000000000e+07,
      "workspace_megabytes": 5.2594146728515625e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__11951679115028441018<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__11951679115028441018<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__6456733360940543154<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2249,
      "real_time": 3.0925061755903519e+05,
      "cpu_time": 3.1682629968891462e+05,
      "time_unit": "ns",
      "items_per_second": 1.0633234500727439e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.1027200818061829e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.2490000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.6583086251818599e+12,
      "predicted_advised_flops_count": 8.2208358400000000e+08,
      "predicted_flops": 2.6583086251818599e+12,
      "predicted_flops_count": 8.2208358400000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__6456733360940543154<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2894,
      "real_time": 2.4074421984747113e+05,
      "cpu_time": 2.4789669073940901e+05,
      "time_unit": "ns",
      "items_per_second": 1.3659037538194676e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 2.4678400158882141e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.8940000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.4147593845486689e+12,
      "predicted_advised_flops_count": 8.2208358400000000e+08,
      "predicted_flops": 3.4147593845486689e+12,
      "predicted_flops_count": 8.2208358400000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__6456733360940543154<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1808,
      "real_time": 3.8552775071672187e+05,
      "cpu_time": 3.9405398838504043e+05,
      "time_unit": "ns",
      "items_per_second": 8.5294361557287803e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6056320000000000e+06,
      "advised_time": 3.8502401113510132e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.8080000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.1323590389321951e+12,
      "predicted_advised_flops_count": 8.2208358400000000e+08,
      "predicted_flops": 2.1323590389321951e+12,
      "predicted_flops_count": 8.2208358400000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.6056320000000000e+06,
      "workspace_megabytes": 1.5312500000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__6456733360940543154<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__6456733360940543154<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__6456733360940543154<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 19,
      "real_time": 3.7230541243364938e+07,
      "cpu_time": 5.6797914315789685e+07,
      "time_unit": "ns",
      "items_per_second": 8.8323570546695511e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 9.2337848320000000e+09,
      "advised_time": -1.0000000000000000e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.9000000000000000e+01,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.2080892636673878e+10,
      "predicted_advised_flops_count": 8.2208358400000000e+08,
      "predicted_flops": 1.7337855872360739e+11,
      "predicted_flops_count": 6.4549775812744350e+09,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 9.2337848320000000e+09,
      "workspace_megabytes": 8.8060234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__6456733360940543154<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__6456733360940543154<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__12498308170152614192<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5398,
      "real_time": 1.2968385717037048e+05,
      "cpu_time": 1.3606216450536880e+05,
      "time_unit": "ns",
      "items_per_second": 3.1695679089803696e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.3107199966907501e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.3980000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.1695679089803696e+12,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 3.1695679089803696e+12,
      "predicted_flops_count": 4.1104179200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__12498308170152614192<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 6541,
      "real_time": 1.0679848086133534e+05,
      "cpu_time": 1.1318450634440964e+05,
      "time_unit": "ns",
      "items_per_second": 3.8487606629319678e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 1.1161600053310394e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.5410000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.8487606629319678e+12,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 3.8487606629319678e+12,
      "predicted_flops_count": 4.1104179200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__12498308170152614192<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2137,
      "real_time": 3.2711747862870601e+05,
      "cpu_time": 3.3482350116994861e+05,
      "time_unit": "ns",
      "items_per_second": 1.2565571051816282e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5690112000000000e+07,
      "advised_time": 3.3276799321174622e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.1370000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.2565571051816282e+12,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 1.2565571051816282e+12,
      "predicted_flops_count": 4.1104179200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.5690112000000000e+07,
      "workspace_megabytes": 2.4500000000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__12498308170152614192<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__12498308170152614192<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 559,
      "real_time": 1.2468145749979855e+06,
      "cpu_time": 1.2768750017885137e+06,
      "time_unit": "ns",
      "items_per_second": 3.2967355390488928e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.2295244800000000e+08,
      "advised_time": 1.2759040594100952e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.5900000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.2967355390488928e+11,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 8.8309276820056055e+11,
      "predicted_flops_count": 1.1010529344677763e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.2295244800000000e+08,
      "workspace_megabytes": 5.9409375000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__12498308170152614192<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2074,
      "real_time": 3.3823575409355585e+05,
      "cpu_time": 3.4602609161029937e+05,
      "time_unit": "ns",
      "items_per_second": 1.2152523410825044e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.1222976000000000e+07,
      "advised_time": 3.7887999415397644e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.0740000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.2152523410825044e+12,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 3.2552825097349868e+12,
      "predicted_flops_count": 1.1010529344677763e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.1222976000000000e+07,
      "workspace_megabytes": 3.9313293457031250e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__12498308170152614192<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__12498308170152614192<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__9389422956349192965<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2286,
      "real_time": 3.0617735500959557e+05,
      "cpu_time": 3.1371391294832889e+05,
      "time_unit": "ns",
      "items_per_second": 3.3562393272611389e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.0515199899673462e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.2860000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -3.2660808633893257e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 3.0206153945350254e+12,
      "predicted_flops_count": 9.2484403200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__9389422956349192965<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2327,
      "real_time": 3.0139716395421483e+05,
      "cpu_time": 3.0886808422862465e+05,
      "time_unit": "ns",
      "items_per_second": 3.4094696397213049e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 3.0310401320457458e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.3270000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -3.3178812530296727e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 3.0685226757491748e+12,
      "predicted_flops_count": 9.2484403200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__9389422956349192965<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2186,
      "real_time": 3.2058814784413081e+05,
      "cpu_time": 3.2823910704489419e+05,
      "time_unit": "ns",
      "items_per_second": 3.2053726468378949e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.4450688000000000e+07,
      "advised_time": 3.2256001234054565e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.1860000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -3.1192669059187974e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 2.8848353821541055e+12,
      "predicted_flops_count": 9.2484403200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.4450688000000000e+07,
      "workspace_megabytes": 1.3781250000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__9389422956349192965<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__9389422956349192965<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 944,
      "real_time": 7.3580919194944843e+05,
      "cpu_time": 7.4960591737263149e+05,
      "time_unit": "ns",
      "items_per_second": 1.3965637983910895e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.5807283200000000e+08,
      "advised_time": 7.5574398040771484e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 9.4400000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -1.3590479854574878e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 2.8089487808929681e+11,
      "predicted_flops_count": 2.0668503326962432e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.5807283200000000e+08,
      "workspace_megabytes": 1.5075000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__9389422956349192965<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 544,
      "real_time": 1.2782531082527437e+06,
      "cpu_time": 1.3080906323532257e+06,
      "time_unit": "ns",
      "items_per_second": 8.0391314784647171e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0306304000000000e+08,
      "advised_time": 1.3352960348129272e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 5.4400000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -7.8231767522702091e+02,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 1.6169335473171198e+11,
      "predicted_flops_count": 2.0668503326962432e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0306304000000000e+08,
      "workspace_megabytes": 2.8902343750000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__9389422956349192965<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 4691,
      "real_time": 1.4834899837648001e+05,
      "cpu_time": 1.5375364037513523e+05,
      "time_unit": "ns",
      "items_per_second": 6.9269391182011621e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.5546240000000000e+06,
      "advised_time": 1.7305600643157959e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnMathType_t math_type = (cudnnMathType_t)0]": 5.7500739770702787e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.6910000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -6.7408611513655151e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": -6.7408611513655151e+03,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.5546240000000000e+06,
      "workspace_megabytes": 6.2509765625000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__9389422956349192965<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 3694,
      "real_time": 1.8953709025008444e+05,
      "cpu_time": 1.9626596480781486e+05,
      "time_unit": "ns",
      "items_per_second": 5.4216537704790588e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.8311552000000000e+07,
      "advised_time": 2.0889599621295929e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.2538945752816425e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.6940000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -5.2760121972989637e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": -5.2760121972989637e+03,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.8311552000000000e+07,
      "workspace_megabytes": 2.7000000000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__17533681295315884137<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 7336,
      "real_time": 9.0857105579974901e+04,
      "cpu_time": 9.7213253816760684e+04,
      "time_unit": "ns",
      "items_per_second": 9.0480934732878945e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.1136001050472260e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 7.3360000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.2620233683219736e+12,
      "predicted_advised_flops_count": 2.0552089600000000e+08,
      "predicted_flops": 2.2620233683219736e+12,
      "predicted_flops_count": 2.0552089600000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__17533681295315884137<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 8480,
      "real_time": 7.7571928480056333e+04,
      "cpu_time": 8.3896978301871452e+04,
      "time_unit": "ns",
      "items_per_second": 1.0597694296221562e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 7.9871997237205505e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 8.4800000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.6494235740553906e+12,
      "predicted_advised_flops_count": 2.0552089600000000e+08,
      "predicted_flops": 2.6494235740553906e+12,
      "predicted_flops_count": 2.0552089600000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__17533681295315884137<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2924,
      "real_time": 2.3954689305777490e+05,
      "cpu_time": 2.4656465389865960e+05,
      "time_unit": "ns",
      "items_per_second": 3.4318273700244839e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 2.4371199309825897e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.9240000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 8.5795684250612097e+11,
      "predicted_advised_flops_count": 2.0552089600000000e+08,
      "predicted_flops": 8.5795684250612097e+11,
      "predicted_flops_count": 2.0552089600000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__17533681295315884137<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__17533681295315884137<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__17533681295315884137<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 406,
      "real_time": 1.7376141834848106e+06,
      "cpu_time": 1.7856539458128943e+06,
      "time_unit": "ns",
      "items_per_second": 4.7311053962007800e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6939417600000000e+08,
      "advised_time": 1.7541120052337646e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 4.0600000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.1827763490501950e+11,
      "predicted_advised_flops_count": 2.0552089600000000e+08,
      "predicted_flops": 1.2243857640958562e+12,
      "predicted_flops_count": 2.1275100697498472e+09,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.6939417600000000e+08,
      "workspace_megabytes": 1.6154687500000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__17533681295315884137<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_8__17533681295315884137<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_8__17959522267358107871<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 4541,
      "real_time": 1.5272634351017221e+05,
      "cpu_time": 1.5915594032151951e+05,
      "time_unit": "ns",
      "items_per_second": 2.6913614413391812e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.5360000729560852e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.5410000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.6913614413391812e+12,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 2.6913614413391812e+12,
      "predicted_flops_count": 4.1104179200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_8__17959522267358107871<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 6125,
      "real_time": 1.1285424095160347e+05,
      "cpu_time": 1.1929137763276955e+05,
      "time_unit": "ns",
      "items_per_second": 3.6422361138937754e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 1.3209599256515503e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 6.1250000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.6422361138937754e+12,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 3.6422361138937754e+12,
      "predicted_flops_count": 4.1104179200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_8__17959522267358107871<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 3258,
      "real_time": 2.1407278214965502e+05,
      "cpu_time": 2.2096537599764779e+05,
      "time_unit": "ns",
      "items_per_second": 1.9201030036254067e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 2.1503999829292297e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.2580000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.9201030036254067e+12,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 1.9201030036254067e+12,
      "predicted_flops_count": 4.1104179200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_8__17959522267358107871<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_8__17959522267358107871<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 538,
      "real_time": 1.2876234442726139e+06,
      "cpu_time": 1.3183587862454038e+06,
      "time_unit": "ns",
      "items_per_second": 3.1922515377327570e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.7104793600000000e+08,
      "advised_time": 1.3127679824829102e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 5.3800000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.1922515377327570e+11,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 8.5510475858861658e+11,
      "predicted_flops_count": 1.1010529344677763e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.7104793600000000e+08,
      "workspace_megabytes": 5.4459375000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_8__17959522267358107871<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2186,
      "real_time": 3.2040387873894861e+05,
      "cpu_time": 3.2803005397995323e+05,
      "time_unit": "ns",
      "items_per_second": 1.2828864420049648e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.1222976000000000e+07,
      "advised_time": 3.5942399501800537e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.1860000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.2828864420049648e+12,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 3.4364532002587500e+12,
      "predicted_flops_count": 1.1010529344677763e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.1222976000000000e+07,
      "workspace_megabytes": 3.9313293457031250e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_8__17959522267358107871<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_8__17959522267358107871<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_8__8450076185912108348<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5247,
      "real_time": 1.3249826033620795e+05,
      "cpu_time": 1.3897900019054921e+05,
      "time_unit": "ns",
      "items_per_second": 3.1022429347902471e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.3516800105571747e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.2470000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.1022429347902471e+12,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 3.1022429347902471e+12,
      "predicted_flops_count": 4.1104179200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_8__8450076185912108348<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 6912,
      "real_time": 1.0159894040489908e+05,
      "cpu_time": 1.0799055844915133e+05,
      "time_unit": "ns",
      "items_per_second": 4.0457291223893477e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 1.1059200018644333e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 6.9120000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.0457291223893477e+12,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 4.0457291223893477e+12,
      "predicted_flops_count": 4.1104179200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_8__8450076185912108348<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 3191,
      "real_time": 2.1888593584109380e+05,
      "cpu_time": 2.2582148480093430e+05,
      "time_unit": "ns",
      "items_per_second": 1.8778812371865088e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2112640000000000e+06,
      "advised_time": 2.2323200106620789e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.1910000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.8778812371865088e+12,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 1.8778812371865088e+12,
      "predicted_flops_count": 4.1104179200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.2112640000000000e+06,
      "workspace_megabytes": 3.0625000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_8__8450076185912108348<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_8__8450076185912108348<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 308,
      "real_time": 2.2808004665043349e+06,
      "cpu_time": 2.2856301525968686e+06,
      "time_unit": "ns",
      "items_per_second": 1.8021821638347107e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.7960038400000000e+08,
      "advised_time": 2.2886400222778320e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.0800000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.8021821638347107e+11,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 4.1373279505812354e+11,
      "predicted_flops_count": 9.4364195197671044e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.7960038400000000e+08,
      "workspace_megabytes": 5.5275000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_8__8450076185912108348<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2642,
      "real_time": 2.6496147958677757e+05,
      "cpu_time": 2.7213628841809847e+05,
      "time_unit": "ns",
      "items_per_second": 1.5513266027991804e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.8410272000000000e+07,
      "advised_time": 3.0617600679397583e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.6420000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.5513266027991804e+12,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 3.5614307160737988e+12,
      "predicted_flops_count": 9.4364195197671044e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.8410272000000000e+07,
      "workspace_megabytes": 2.7094146728515625e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_8__8450076185912108348<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_8__8450076185912108348<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__8483100846342331658<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 6078,
      "real_time": 1.1210875709905213e+05,
      "cpu_time": 1.1821328101352586e+05,
      "time_unit": "ns",
      "items_per_second": 7.3329114091743926e+12,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1366400122642517e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 6.0780000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.8332278522935981e+12,
      "predicted_advised_flops_count": 2.0552089600000000e+08,
      "predicted_flops": 1.8332278522935981e+12,
      "predicted_flops_count": 2.0552089600000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__8483100846342331658<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 4274,
      "real_time": 1.5964621406799325e+05,
      "cpu_time": 1.6612528661685454e+05,
      "time_unit": "ns",
      "items_per_second": 5.1494085769542578e+12,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.6179199516773224e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 4.2740000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.2873521442385645e+12,
      "predicted_advised_flops_count": 2.0552089600000000e+08,
      "predicted_flops": 1.2873521442385645e+12,
      "predicted_flops_count": 2.0552089600000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__8483100846342331658<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2681,
      "real_time": 2.5546377046132393e+05,
      "cpu_time": 2.6277473368139582e+05,
      "time_unit": "ns",
      "items_per_second": 3.2180045824715474e+12,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6056320000000000e+06,
      "advised_time": 2.5395199656486511e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.6810000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 8.0450114561788684e+11,
      "predicted_advised_flops_count": 2.0552089600000000e+08,
      "predicted_flops": 8.0450114561788684e+11,
      "predicted_flops_count": 2.0552089600000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.6056320000000000e+06,
      "workspace_megabytes": 1.5312500000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__8483100846342331658<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__8483100846342331658<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__8483100846342331658<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 75,
      "real_time": 9.0393391251564026e+06,
      "cpu_time": 1.0291964119998815e+07,
      "time_unit": "ns",
      "items_per_second": 9.0945098155699066e+10,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.3352033280000000e+09,
      "advised_time": 9.0746879577636719e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 7.5000000000000000e+01,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.2736274538924767e+10,
      "predicted_advised_flops_count": 2.0552089600000000e+08,
      "predicted_flops": 1.7953903368326700e+11,
      "predicted_flops_count": 1.6229142116659286e+09,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 2.3352033280000000e+09,
      "workspace_megabytes": 2.2270234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__8483100846342331658<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__8483100846342331658<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__11045106263834837633<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 3337,
      "real_time": 2.0985938826510846e+05,
      "cpu_time": 2.1675076625713293e+05,
      "time_unit": "ns",
      "items_per_second": 1.9586533411635813e+12,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.1296000480651855e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.3370000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.9586533411635813e+12,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 1.9586533411635813e+12,
      "predicted_flops_count": 4.1104179200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__11045106263834837633<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2594,
      "real_time": 2.6444852620831050e+05,
      "cpu_time": 2.7173571241316770e+05,
      "time_unit": "ns",
      "items_per_second": 1.5543357260997383e+12,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 2.6627200841903687e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.5940000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.5543357260997383e+12,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 1.5543357260997383e+12,
      "predicted_flops_count": 4.1104179200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__11045106263834837633<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2104,
      "real_time": 3.2604596438815905e+05,
      "cpu_time": 3.3391969819421793e+05,
      "time_unit": "ns",
      "items_per_second": 1.2606866420547166e+12,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2112640000000000e+06,
      "advised_time": 3.2767999172210693e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.1040000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.2606866420547166e+12,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 1.2606866420547166e+12,
      "predicted_flops_count": 4.1104179200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.2112640000000000e+06,
      "workspace_megabytes": 3.0625000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__11045106263834837633<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__11045106263834837633<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 91,
      "real_time": 7.2118294691400873e+06,
      "cpu_time": 7.9605300329678738e+06,
      "time_unit": "ns",
      "items_per_second": 5.6995495215031921e+10,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4578621440000000e+09,
      "advised_time": 7.2191681861877441e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 9.1000000000000000e+01,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.6995495215031921e+10,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 9.7778423370359024e+10,
      "predicted_flops_count": 7.0516131510841095e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.4578621440000000e+09,
      "workspace_megabytes": 2.3440000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__11045106263834837633<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 508,
      "real_time": 1.3558183978660046e+06,
      "cpu_time": 1.3889904232285304e+06,
      "time_unit": "ns",
      "items_per_second": 3.0316876703175049e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6210371200000000e+08,
      "advised_time": 1.4223359823226929e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.0800000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.0316876703175049e+11,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 5.2010012271429724e+11,
      "predicted_flops_count": 7.0516131510841095e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6210371200000000e+08,
      "workspace_megabytes": 1.5459414672851562e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__11045106263834837633<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__11045106263834837633<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__13959557228974145646<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2969,
      "real_time": 2.3542052195274917e+05,
      "cpu_time": 2.4251446817122167e+05,
      "time_unit": "ns",
      "items_per_second": 1.3967917107328457e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.3552000522613525e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 2.9690000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.4919792768321143e+12,
      "predicted_advised_flops_count": 8.2208358400000000e+08,
      "predicted_flops": 3.4919792768321143e+12,
      "predicted_flops_count": 8.2208358400000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__13959557228974145646<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 3736,
      "real_time": 1.8652073851053911e+05,
      "cpu_time": 1.9327487660594119e+05,
      "time_unit": "ns",
      "items_per_second": 1.7629859083011281e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 1.8841600418090820e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 3.7360000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.4074647707528203e+12,
      "predicted_advised_flops_count": 8.2208358400000000e+08,
      "predicted_flops": 4.4074647707528203e+12,
      "predicted_flops_count": 8.2208358400000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__13959557228974145646<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1880,
      "real_time": 3.7008611497127434e+05,
      "cpu_time": 3.7828052127644035e+05,
      "time_unit": "ns",
      "items_per_second": 8.8853220993044746e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2112640000000000e+06,
      "advised_time": 3.7068799138069153e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 1.8800000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.2213305248261187e+12,
      "predicted_advised_flops_count": 8.2208358400000000e+08,
      "predicted_flops": 2.2213305248261187e+12,
      "predicted_flops_count": 8.2208358400000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.2112640000000000e+06,
      "workspace_megabytes": 3.0625000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__13959557228974145646<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__13959557228974145646<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__13959557228974145646<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 72,
      "real_time": 9.3462484397201072e+06,
      "cpu_time": 1.0700698694444455e+07,
      "time_unit": "ns",
      "items_per_second": 3.5183468075009528e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.3352033280000000e+09,
      "advised_time": 9.2835836410522461e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 7.2000000000000000e+01,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 8.7958670187523819e+10,
      "predicted_advised_flops_count": 8.2208358400000000e+08,
      "predicted_flops": 7.8459373961209570e+11,
      "predicted_flops_count": 7.3330080146637135e+09,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 2.3352033280000000e+09,
      "workspace_megabytes": 2.2270234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__13959557228974145646<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__13959557228974145646<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__8401132130640513207<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2624,
      "real_time": 2.6647447392439598e+05,
      "cpu_time": 2.7369399428355286e+05,
      "time_unit": "ns",
      "items_per_second": 2.8922220903555054e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.7852800488471985e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.2042240000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.6240000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "predicted_advised_flops": 3.5429720606854937e+12,
      "predicted_advised_flops_count": 9.4411161600000000e+08,
      "predicted_flops": 3.5429720606854937e+12,
      "predicted_flops_count": 9.4411161600000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__8401132130640513207<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 3350,
      "real_time": 2.0795539797304559e+05,
      "cpu_time": 2.1477291641768042e+05,
      "time_unit": "ns",
      "items_per_second": 3.7060993247210431e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.5272000000000000e+04,
      "advised_time": 2.0582400262355804e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.2042240000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.3500000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "predicted_advised_flops": 4.5399716727832773e+12,
      "predicted_advised_flops_count": 9.4411161600000000e+08,
      "predicted_flops": 4.5399716727832773e+12,
      "predicted_flops_count": 9.4411161600000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 7.5272000000000000e+04,
      "workspace_megabytes": 7.1784973144531250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__8401132130640513207<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1287,
      "real_time": 5.4545081938778306e+05,
      "cpu_time": 5.5582689432763727e+05,
      "time_unit": "ns",
      "items_per_second": 1.4129658121424066e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.9006976000000000e+07,
      "advised_time": 5.4886400699615479e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.2042240000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.2870000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "predicted_advised_flops": 1.7308831198744480e+12,
      "predicted_advised_flops_count": 9.4411161600000000e+08,
      "predicted_flops": 1.7308831198744480e+12,
      "predicted_flops_count": 9.4411161600000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 5.9006976000000000e+07,
      "workspace_megabytes": 5.6273437500000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__8401132130640513207<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__8401132130640513207<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__8401132130640513207<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 266,
      "real_time": 2.6436610072080912e+06,
      "cpu_time": 2.7221195676688235e+06,
      "time_unit": "ns",
      "items_per_second": 2.9152881473783276e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.5500800000000000e+06,
      "advised_time": 2.6634240150451660e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.2042240000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.6600000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "predicted_advised_flops": 3.5712279805384509e+11,
      "predicted_advised_flops_count": 9.4411161600000000e+08,
      "predicted_flops": 2.4490524848057333e+11,
      "predicted_flops_count": 6.4744645586870039e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 5.5500800000000000e+06,
      "workspace_megabytes": 5.2929687500000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__8401132130640513207<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_8__8401132130640513207<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__41811883147562323<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 13195,
      "real_time": 5.2401259745238349e+04,
      "cpu_time": 5.8666914437242856e+04,
      "time_unit": "ns",
      "items_per_second": 1.9610301069019192e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.3247999399900436e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.3195000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.9610301069019192e+12,
      "predicted_advised_flops_count": 1.0276044800000000e+08,
      "predicted_flops": 1.9610301069019192e+12,
      "predicted_flops_count": 1.0276044800000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__41811883147562323<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 15990,
      "real_time": 4.4078232905127952e+04,
      "cpu_time": 5.0323016134982368e+04,
      "time_unit": "ns",
      "items_per_second": 2.3313195930784492e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 4.8128001391887665e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.5990000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.3313195930784492e+12,
      "predicted_advised_flops_count": 1.0276044800000000e+08,
      "predicted_flops": 2.3313195930784492e+12,
      "predicted_flops_count": 1.0276044800000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__41811883147562323<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 6485,
      "real_time": 1.0827636934378641e+05,
      "cpu_time": 1.1466205505018643e+05,
      "time_unit": "ns",
      "items_per_second": 9.4905701606716321e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 1.1059200018644333e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.4850000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 9.4905701606716321e+11,
      "predicted_advised_flops_count": 1.0276044800000000e+08,
      "predicted_flops": 9.4905701606716321e+11,
      "predicted_flops_count": 1.0276044800000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__41811883147562323<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__41811883147562323<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1973,
      "real_time": 3.5539173993253225e+05,
      "cpu_time": 3.6338004004071065e+05,
      "time_unit": "ns",
      "items_per_second": 2.8914697910398279e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.5581184000000000e+08,
      "advised_time": 3.7887999415397644e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.9730000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.8914697910398279e+11,
      "predicted_advised_flops_count": 1.0276044800000000e+08,
      "predicted_flops": 8.1389045794698340e+11,
      "predicted_flops_count": 2.8924994596426392e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.5581184000000000e+08,
      "workspace_megabytes": 1.4859375000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__41811883147562323<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5215,
      "real_time": 1.3433336469196124e+05,
      "cpu_time": 1.4076412540736812e+05,
      "time_unit": "ns",
      "items_per_second": 7.6496593557110083e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6155456000000000e+07,
      "advised_time": 1.4847999811172485e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.2150000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 7.6496593557110083e+11,
      "predicted_advised_flops_count": 1.0276044800000000e+08,
      "predicted_flops": 2.1532249015539858e+12,
      "predicted_flops_count": 2.8924994596426392e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6155456000000000e+07,
      "workspace_megabytes": 1.5407043457031250e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__41811883147562323<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__41811883147562323<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__14898924140339514659<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2433,
      "real_time": 2.8778754161407443e+05,
      "cpu_time": 2.9512922770241729e+05,
      "time_unit": "ns",
      "items_per_second": 3.5707052301034851e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.8774398565292358e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.4330000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -3.4747855810277169e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 3.2136347070931362e+12,
      "predicted_flops_count": 9.2484403200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__14898924140339514659<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2549,
      "real_time": 2.7462298710194405e+05,
      "cpu_time": 2.8184995488441235e+05,
      "time_unit": "ns",
      "items_per_second": 3.7418735075463232e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 2.7647998929023743e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.5490000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -3.6413557748856088e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 3.3676861567916909e+12,
      "predicted_flops_count": 9.2484403200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__14898924140339514659<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2170,
      "real_time": 3.2173667276333930e+05,
      "cpu_time": 3.2944723087537050e+05,
      "time_unit": "ns",
      "items_per_second": 3.1939302137182159e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.8901376000000000e+07,
      "advised_time": 3.2767999172210693e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.1700000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -3.1081318502214158e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 2.8745371923463940e+12,
      "predicted_flops_count": 9.2484403200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.8901376000000000e+07,
      "workspace_megabytes": 2.7562500000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__14898924140339514659<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__14898924140339514659<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1152,
      "real_time": 6.0750394408791582e+05,
      "cpu_time": 6.1903022135391238e+05,
      "time_unit": "ns",
      "items_per_second": 1.6915190263378580e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.5210905600000000e+08,
      "advised_time": 6.1340802907943726e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.1520000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -1.6460798480927779e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 3.9785687404995612e+11,
      "predicted_flops_count": 2.4169962016783750e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.5210905600000000e+08,
      "workspace_megabytes": 1.4506250000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__14898924140339514659<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1890,
      "real_time": 3.7281314191647444e+05,
      "cpu_time": 3.8089653333298262e+05,
      "time_unit": "ns",
      "items_per_second": 2.7563526186805554e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.0240640000000000e+07,
      "advised_time": 4.0243199467658997e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.8900000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -2.6823088769334245e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 6.4831303672762756e+11,
      "predicted_flops_count": 2.4169962016783750e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 8.0240640000000000e+07,
      "workspace_megabytes": 7.6523437500000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__14898924140339514659<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 4810,
      "real_time": 1.4567562360669876e+05,
      "cpu_time": 1.5215956361729579e+05,
      "time_unit": "ns",
      "items_per_second": 7.0540592486109436e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6389120000000000e+06,
      "advised_time": 1.6076800227165222e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnMathType_t math_type = (cudnnMathType_t)0]": 5.7500739770702787e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 4.8100000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -6.8645664610288031e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": -6.8645664610288031e+03,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6389120000000000e+06,
      "workspace_megabytes": 1.5629882812500000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__14898924140339514659<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 3688,
      "real_time": 1.8904580264542290e+05,
      "cpu_time": 1.9574473345975386e+05,
      "time_unit": "ns",
      "items_per_second": 5.4357434315925555e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.1260672000000000e+07,
      "advised_time": 2.0992000401020050e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.2538945752816425e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.6880000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -5.2897233686569325e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": -5.2897233686569325e+03,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.1260672000000000e+07,
      "workspace_megabytes": 2.9812500000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__10222180864330322105<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 4805,
      "real_time": 1.4514833796308079e+05,
      "cpu_time": 1.5165892341285109e+05,
      "time_unit": "ns",
      "items_per_second": 2.8318739144264297e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.4537599682807922e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 4.8050000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.8318739144264297e+12,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 2.8318739144264297e+12,
      "predicted_flops_count": 4.1104179200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__10222180864330322105<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5356,
      "real_time": 1.2999965794375089e+05,
      "cpu_time": 1.3644572908886371e+05,
      "time_unit": "ns",
      "items_per_second": 3.1618682579753574e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.3209599256515503e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 5.3560000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.1618682579753574e+12,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 3.1618682579753574e+12,
      "predicted_flops_count": 4.1104179200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__10222180864330322105<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2589,
      "real_time": 2.6549151999897126e+05,
      "cpu_time": 2.7270165314782009e+05,
      "time_unit": "ns",
      "items_per_second": 1.5482294575796345e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.0281600000000000e+05,
      "advised_time": 2.6419198513031006e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.5890000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.5482294575796345e+12,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 1.5482294575796345e+12,
      "predicted_flops_count": 4.1104179200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 8.0281600000000000e+05,
      "workspace_megabytes": 7.6562500000000000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__10222180864330322105<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__10222180864330322105<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 85,
      "real_time": 8.1215253976338049e+06,
      "cpu_time": 9.0369633411743212e+06,
      "time_unit": "ns",
      "items_per_second": 5.0611402646078835e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4295505920000000e+09,
      "advised_time": 8.1725435256958008e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 8.5000000000000000e+01,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.0611402646078835e+10,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 8.6826215591698898e+10,
      "predicted_flops_count": 7.0516131510841095e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.4295505920000000e+09,
      "workspace_megabytes": 2.3170000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__10222180864330322105<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 595,
      "real_time": 1.1567116826537901e+06,
      "cpu_time": 1.1821909310926071e+06,
      "time_unit": "ns",
      "items_per_second": 3.5535371360386523e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6210371200000000e+08,
      "advised_time": 1.2288000583648682e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 5.9500000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.5535371360386523e+11,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 6.0962582610957288e+11,
      "predicted_flops_count": 7.0516131510841095e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6210371200000000e+08,
      "workspace_megabytes": 1.5459414672851562e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__10222180864330322105<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__10222180864330322105<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__3618408154961504976<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5212,
      "real_time": 1.3391915687616912e+05,
      "cpu_time": 1.4043885072905401e+05,
      "time_unit": "ns",
      "items_per_second": 3.0693278063277949e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.3619199395179749e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 5.2120000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.0693278063277949e+12,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 3.0693278063277949e+12,
      "predicted_flops_count": 4.1104179200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__3618408154961504976<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 6519,
      "real_time": 1.0642501448381398e+05,
      "cpu_time": 1.1281149163966479e+05,
      "time_unit": "ns",
      "items_per_second": 3.8622667236048599e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 1.0854399949312210e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 6.5190000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.8622667236048599e+12,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 3.8622667236048599e+12,
      "predicted_flops_count": 4.1104179200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__3618408154961504976<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2540,
      "real_time": 2.7588458450357098e+05,
      "cpu_time": 2.8321580984280712e+05,
      "time_unit": "ns",
      "items_per_second": 1.4899048917127139e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6056320000000000e+06,
      "advised_time": 2.7852800488471985e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 2.5400000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.4899048917127139e+12,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 1.4899048917127139e+12,
      "predicted_flops_count": 4.1104179200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6056320000000000e+06,
      "workspace_megabytes": 1.5312500000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__3618408154961504976<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__3618408154961504976<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 260,
      "real_time": 2.6749742799438536e+06,
      "cpu_time": 2.7852720384614188e+06,
      "time_unit": "ns",
      "items_per_second": 1.5366196044644870e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.0974694400000000e+08,
      "advised_time": 2.6839039325714111e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 2.6000000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.5366196044644870e+11,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 3.0563670195301385e+11,
      "predicted_flops_count": 8.1757031673117745e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.0974694400000000e+08,
      "workspace_megabytes": 5.8150000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__3618408154961504976<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1343,
      "real_time": 5.1674984304660175e+05,
      "cpu_time": 5.2691951079750375e+05,
      "time_unit": "ns",
      "items_per_second": 7.9543670410545496e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.5148960000000000e+07,
      "advised_time": 5.5808001756668091e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 1.3430000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 7.9543670410545496e+11,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 1.5821394582551370e+12,
      "predicted_flops_count": 8.1757031673117745e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.5148960000000000e+07,
      "workspace_megabytes": 5.2594146728515625e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__3618408154961504976<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__3618408154961504976<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__17437442221947362045<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 4942,
      "real_time": 1.4141246156663081e+05,
      "cpu_time": 1.4788627316872260e+05,
      "time_unit": "ns",
      "items_per_second": 2.9066872003096069e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.4233599603176117e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 4.9420000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.9066872003096069e+12,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 2.9066872003096069e+12,
      "predicted_flops_count": 4.1104179200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__17437442221947362045<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5441,
      "real_time": 1.2846989731791404e+05,
      "cpu_time": 1.3487153354157964e+05,
      "time_unit": "ns",
      "items_per_second": 3.1995183352784053e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 1.3312000036239624e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 5.4410000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.1995183352784053e+12,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 3.1995183352784053e+12,
      "predicted_flops_count": 4.1104179200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__17437442221947362045<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2194,
      "real_time": 3.1630428700110177e+05,
      "cpu_time": 3.2395901595268992e+05,
      "time_unit": "ns",
      "items_per_second": 1.2995138191047288e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2845056000000000e+07,
      "advised_time": 3.1948798894882202e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.1940000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.2995138191047288e+12,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 1.2995138191047288e+12,
      "predicted_flops_count": 4.1104179200000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.2845056000000000e+07,
      "workspace_megabytes": 1.2250000000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__17437442221947362045<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__17437442221947362045<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 299,
      "real_time": 2.3431165445982213e+06,
      "cpu_time": 2.4279726120404657e+06,
      "time_unit": "ns",
      "items_per_second": 1.7542524418924374e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.0633907200000000e+08,
      "advised_time": 2.3429439067840576e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.9900000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.7542524418924374e+11,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 4.0272941358899353e+11,
      "predicted_flops_count": 9.4364195197671044e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.0633907200000000e+08,
      "workspace_megabytes": 5.7825000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__17437442221947362045<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2084,
      "real_time": 3.3514789897367993e+05,
      "cpu_time": 3.4286804462542501e+05,
      "time_unit": "ns",
      "items_per_second": 1.2264489595749495e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.8410272000000000e+07,
      "advised_time": 3.7580800056457520e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.0840000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.2264489595749495e+12,
      "predicted_advised_flops_count": 4.1104179200000000e+08,
      "predicted_flops": 2.8155985905518604e+12,
      "predicted_flops_count": 9.4364195197671044e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.8410272000000000e+07,
      "workspace_megabytes": 2.7094146728515625e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__17437442221947362045<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_8__17437442221947362045<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_8__15738530095251692753/input[0]:8/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 5280,
      "real_time": 1.3261381201862771e+05,
      "cpu_time": 1.3907301174273877e+05,
      "time_unit": "ns",
      "items_per_second": 4.8430309801349007e+10,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_op_tensor.cpp": 1.3194847084940028e+19,
      "benchmark_func:void iLAYER_CUDNN_OP_TENSOR_Impl(benchmark::State&) [with T = float; cudnnOpTensorOp_t op_type = (cudnnOpTensorOp_t)0]": 1.4844646694895837e+19,
      "beta": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_OP_TENSOR_Impl": 3.0075642356307840e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_c": 2.5600000000000000e+02,
      "input_h": 5.6000000000000000e+01,
      "input_n": 8.0000000000000000e+00,
      "input_size": 6.4225280000000000e+06,
      "input_w": 5.6000000000000000e+01,
      "num_iterations": 5.2800000000000000e+03,
      "op_type": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_8__12695919320263654141/input[0]:8/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 10036,
      "real_time": 6.9670800705560381e+04,
      "cpu_time": 7.6003609405962576e+04,
      "time_unit": "ns",
      "items_per_second": 4.6091963454981667e+10,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_op_tensor.cpp": 1.3194847084940028e+19,
      "benchmark_func:void iLAYER_CUDNN_OP_TENSOR_Impl(benchmark::State&) [with T = float; cudnnOpTensorOp_t op_type = (cudnnOpTensorOp_t)0]": 1.4844646694895837e+19,
      "beta": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_OP_TENSOR_Impl": 3.0075642356307840e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_c": 5.1200000000000000e+02,
      "input_h": 2.8000000000000000e+01,
      "input_n": 8.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_w": 2.8000000000000000e+01,
      "num_iterations": 1.0036000000000000e+04,
      "op_type": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_8__11192476552145604474/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 31497,
      "real_time": 2.2215509051451187e+04,
      "cpu_time": 2.8416258215023659e+04,
      "time_unit": "ns",
      "items_per_second": 3.6137636915754471e+10,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_op_tensor.cpp": 1.3194847084940028e+19,
      "benchmark_func:void iLAYER_CUDNN_OP_TENSOR_Impl(benchmark::State&) [with T = float; cudnnOpTensorOp_t op_type = (cudnnOpTensorOp_t)0]": 1.4844646694895837e+19,
      "beta": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_OP_TENSOR_Impl": 3.0075642356307840e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_c": 2.0480000000000000e+03,
      "input_h": 7.0000000000000000e+00,
      "input_n": 8.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_w": 7.0000000000000000e+00,
      "num_iterations": 3.1497000000000000e+04,
      "op_type": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_8__9060437728988133445/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:8/manual_time",
      "iterations": 18230,
      "real_time": 3.8413908992012352e+04,
      "cpu_time": 4.4657872408056915e+04,
      "time_unit": "ns",
      "items_per_second": 4.1798193470335686e+10,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_op_tensor.cpp": 1.3194847084940028e+19,
      "benchmark_func:void iLAYER_CUDNN_OP_TENSOR_Impl(benchmark::State&) [with T = float; cudnnOpTensorOp_t op_type = (cudnnOpTensorOp_t)0]": 1.4844646694895837e+19,
      "beta": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_OP_TENSOR_Impl": 3.0075642356307840e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_c": 1.0240000000000000e+03,
      "input_h": 1.4000000000000000e+01,
      "input_n": 8.0000000000000000e+00,
      "input_size": 1.6056320000000000e+06,
      "input_w": 1.4000000000000000e+01,
      "num_iterations": 1.8230000000000000e+04,
      "op_type": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_8__18307926197624827978<CUDNN_POOLING_MAX>/input[0]:8/input[1]:64/input[2]:112/input[3]:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:8/manual_time",
      "iterations": 9204,
      "real_time": 7.6034633296203188e+04,
      "cpu_time": 8.2337200890985609e+04,
      "time_unit": "ns",
      "items_per_second": 8.4468454986560837e+10,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_pooling_fwd.cpp": 9.1239988607066061e+18,
      "benchmark_func:void iLAYER_CUDNN_POOLING_FWD_Impl(benchmark::State&) [with T = float; cudnnPoolingMode_t pooling_mode = (cudnnPoolingMode_t)0]": 1.5686689287215342e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_POOLING_FWD_Impl": 1.4645785230092718e+19,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "horizontal_padding": 1.0000000000000000e+00,
      "horizontal_stride": 2.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 9.2040000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "pooling_mode": 0.0000000000000000e+00,
      "predicted_flops": 8.4468454986560837e+10,
      "predicted_flops_count": 6.4225280000000000e+06,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "vertical_padding": 1.0000000000000000e+00,
      "vertical_stride": 2.0000000000000000e+00,
      "window_height": 3.0000000000000000e+00,
      "window_width": 3.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_8__18307926197624827978<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:8/input[1]:64/input[2]:112/input[3]:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:8/manual_time",
      "iterations": 9205,
      "real_time": 7.6029004801597417e+04,
      "cpu_time": 8.2308620749721274e+04,
      "time_unit": "ns",
      "items_per_second": 8.4474708261143234e+10,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_pooling_fwd.cpp": 9.1239988607066061e+18,
      "benchmark_func:void iLAYER_CUDNN_POOLING_FWD_Impl(benchmark::State&) [with T = float; cudnnPoolingMode_t pooling_mode = (cudnnPoolingMode_t)3]": 1.5689715143215610e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_POOLING_FWD_Impl": 1.4645785230092718e+19,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "horizontal_padding": 1.0000000000000000e+00,
      "horizontal_stride": 2.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 9.2050000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "pooling_mode": 3.0000000000000000e+00,
      "predicted_flops": 8.4474708261143234e+10,
      "predicted_flops_count": 6.4225280000000000e+06,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "vertical_padding": 1.0000000000000000e+00,
      "vertical_stride": 2.0000000000000000e+00,
      "window_height": 3.0000000000000000e+00,
      "window_width": 3.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6071,
      "real_time": 1.1362376729050367e+05,
      "cpu_time": 1.1920356349866724e+05,
      "time_unit": "ns",
      "items_per_second": 7.2351375385940684e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1264000087976456e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 6.0710000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6075,
      "real_time": 1.1283922234694799e+05,
      "cpu_time": 1.1927112098778764e+05,
      "time_unit": "ns",
      "items_per_second": 7.2854417719428320e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1363200098276138e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 6.0750000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6071,
      "real_time": 1.1304799401806836e+05,
      "cpu_time": 1.1945820144949839e+05,
      "time_unit": "ns",
      "items_per_second": 7.2719873637793799e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1264000087976456e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 6.0710000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6071,
      "real_time": 1.1280765394736809e+05,
      "cpu_time": 1.1923624625287157e+05,
      "time_unit": "ns",
      "items_per_second": 7.2874805497112285e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1366400122642517e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 6.0710000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6080,
      "real_time": 1.1268321099315041e+05,
      "cpu_time": 1.1906788733551110e+05,
      "time_unit": "ns",
      "items_per_second": 7.2955285597068350e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1366400122642517e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 6.0800000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4267,
      "real_time": 1.5955054897604149e+05,
      "cpu_time": 1.6612335130075359e+05,
      "time_unit": "ns",
      "items_per_second": 5.1524961165971680e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.6179199516773224e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 4.2670000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4278,
      "real_time": 1.5889084869362204e+05,
      "cpu_time": 1.6543531860695669e+05,
      "time_unit": "ns",
      "items_per_second": 5.1738888095762236e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.6179199516773224e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 4.2780000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4277,
      "real_time": 1.5914742024082461e+05,
      "cpu_time": 1.6571503577260347e+05,
      "time_unit": "ns",
      "items_per_second": 5.1655476586174570e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.6179199516773224e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 4.2770000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4283,
      "real_time": 1.5892140908856507e+05,
      "cpu_time": 1.6546111463911587e+05,
      "time_unit": "ns",
      "items_per_second": 5.1728938770097510e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.6076800227165222e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 4.2830000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4274,
      "real_time": 1.5917632910601661e+05,
      "cpu_time": 1.6574332030870984e+05,
      "time_unit": "ns",
      "items_per_second": 5.1646095158562520e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.6179199516773224e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 4.2740000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2662,
      "real_time": 2.5506323671336114e+05,
      "cpu_time": 2.6219698046554194e+05,
      "time_unit": "ns",
      "items_per_second": 3.2230579153351436e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6056320000000000e+06,
      "advised_time": 2.5395199656486511e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.6620000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.6056320000000000e+06,
      "workspace_megabytes": 1.5312500000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2656,
      "real_time": 2.5461379537083273e+05,
      "cpu_time": 2.6176611972875163e+05,
      "time_unit": "ns",
      "items_per_second": 3.2287472200894492e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6056320000000000e+06,
      "advised_time": 2.5292798876762390e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.6560000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.6056320000000000e+06,
      "workspace_megabytes": 1.5312500000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2690,
      "real_time": 2.5589662446289024e+05,
      "cpu_time": 2.6207191895926557e+05,
      "time_unit": "ns",
      "items_per_second": 3.2125612665876235e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6056320000000000e+06,
      "advised_time": 2.5395199656486511e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.6900000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.6056320000000000e+06,
      "workspace_megabytes": 1.5312500000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 76,
      "real_time": 9.0401953846020140e+06,
      "cpu_time": 1.0261539131579561e+07,
      "time_unit": "ns",
      "items_per_second": 9.0936484116287888e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.3352033280000000e+09,
      "advised_time": 9.0511360168457031e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 7.6000000000000000e+01,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 2.3352033280000000e+09,
      "workspace_megabytes": 2.2270234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 76,
      "real_time": 9.0071019520492926e+06,
      "cpu_time": 9.8694223684203196e+06,
      "time_unit": "ns",
      "items_per_second": 9.1270598287494659e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.3352033280000000e+09,
      "advised_time": 9.0562562942504883e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 7.6000000000000000e+01,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 2.3352033280000000e+09,
      "workspace_megabytes": 2.2270234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 77,
      "real_time": 9.0376390628032871e+06,
      "cpu_time": 1.0248670220779456e+07,
      "time_unit": "ns",
      "items_per_second": 9.0962205758304184e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.3352033280000000e+09,
      "advised_time": 9.0255355834960938e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 7.7000000000000000e+01,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 2.3352033280000000e+09,
      "workspace_megabytes": 2.2270234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__15593705588088621734<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2251,
      "real_time": 3.0983244360346795e+05,
      "cpu_time": 3.1732331941326748e+05,
      "time_unit": "ns",
      "items_per_second": 1.0613266634557162e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.1231999397277832e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.2510000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2243,
      "real_time": 3.0845795789261436e+05,
      "cpu_time": 3.1604123718237784e+05,
      "time_unit": "ns",
      "items_per_second": 1.0660559249195287e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.1027200818061829e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.2430000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2270,
      "real_time": 3.0915312752864085e+05,
      "cpu_time": 3.1672867665159900e+05,
      "time_unit": "ns",
      "items_per_second": 1.0636587642786691e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.1439998745918274e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.2700000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2242,
      "real_time": 3.0857588546778460e+05,
      "cpu_time": 3.1617287154331018e+05,
      "time_unit": "ns",
      "items_per_second": 1.0656485133357264e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.1539198756217957e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.2420000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2253,
      "real_time": 3.0827646700905520e+05,
      "cpu_time": 3.1584203905872261e+05,
      "time_unit": "ns",
      "items_per_second": 1.0666835415313779e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.0720001459121704e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.2530000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2902,
      "real_time": 2.4001642558669133e+05,
      "cpu_time": 2.4703330909711102e+05,
      "time_unit": "ns",
      "items_per_second": 1.3700455408258256e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 2.6931199431419373e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.9020000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2903,
      "real_time": 2.4081840412109758e+05,
      "cpu_time": 2.4674793937296560e+05,
      "time_unit": "ns",
      "items_per_second": 1.3654829862365639e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 2.4371199309825897e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.9030000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2905,
      "real_time": 2.4017727897356611e+05,
      "cpu_time": 2.4716358657456026e+05,
      "time_unit": "ns",
      "items_per_second": 1.3691279833184859e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 2.6214399933815002e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.9050000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2904,
      "real_time": 2.4010788562490165e+05,
      "cpu_time": 2.4710592183177453e+05,
      "time_unit": "ns",
      "items_per_second": 1.3695236736776986e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 2.4473600089550018e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.9040000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2902,
      "real_time": 2.4000517850066841e+05,
      "cpu_time": 2.4704044693338542e+05,
      "time_unit": "ns",
      "items_per_second": 1.3701097436907355e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 2.4473600089550018e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.9020000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1817,
      "real_time": 3.8296312502373662e+05,
      "cpu_time": 3.9130100055088161e+05,
      "time_unit": "ns",
      "items_per_second": 8.5865560445178213e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6056320000000000e+06,
      "advised_time": 3.9321601390838623e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.8170000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.6056320000000000e+06,
      "workspace_megabytes": 1.5312500000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1816,
      "real_time": 3.8308863288511126e+05,
      "cpu_time": 3.9140933315020922e+05,
      "time_unit": "ns",
      "items_per_second": 8.5837429088797197e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6056320000000000e+06,
      "advised_time": 3.8297599554061890e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.8160000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.6056320000000000e+06,
      "workspace_megabytes": 1.5312500000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1815,
      "real_time": 3.8308582102530956e+05,
      "cpu_time": 3.9136791460044350e+05,
      "time_unit": "ns",
      "items_per_second": 8.5838059137739463e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6056320000000000e+06,
      "advised_time": 3.8195198774337769e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.8150000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.6056320000000000e+06,
      "workspace_megabytes": 1.5312500000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 19,
      "real_time": 3.7298607787019327e+07,
      "cpu_time": 5.6911229105263837e+07,
      "time_unit": "ns",
      "items_per_second": 8.8162388118529373e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 9.2337848320000000e+09,
      "advised_time": -1.0000000000000000e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.9000000000000000e+01,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 9.2337848320000000e+09,
      "workspace_megabytes": 8.8060234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 19,
      "real_time": 3.7361395202184975e+07,
      "cpu_time": 5.6971224052632935e+07,
      "time_unit": "ns",
      "items_per_second": 8.8014227472096405e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 9.2337848320000000e+09,
      "advised_time": -1.0000000000000000e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.9000000000000000e+01,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 9.2337848320000000e+09,
      "workspace_megabytes": 8.8060234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 19,
      "real_time": 3.7279529595061354e+07,
      "cpu_time": 5.6896387631579012e+07,
      "time_unit": "ns",
      "items_per_second": 8.8207506149316483e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 9.2337848320000000e+09,
      "advised_time": -1.0000000000000000e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.9000000000000000e+01,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 9.2337848320000000e+09,
      "workspace_megabytes": 8.8060234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14152339845814873604<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3315,
      "real_time": 2.1117910192552448e+05,
      "cpu_time": 2.1813235203612983e+05,
      "time_unit": "ns",
      "items_per_second": 1.5571305616971896e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.1811200678348541e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.3150000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3320,
      "real_time": 2.1101833340089142e+05,
      "cpu_time": 2.1789376536158542e+05,
      "time_unit": "ns",
      "items_per_second": 1.5583168926620426e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.1811200678348541e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.3200000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3321,
      "real_time": 2.1100289387819413e+05,
      "cpu_time": 2.1783973863294770e+05,
      "time_unit": "ns",
      "items_per_second": 1.5584309179656373e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.1811200678348541e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.3210000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3314,
      "real_time": 2.1087415902173502e+05,
      "cpu_time": 2.1772334550402965e+05,
      "time_unit": "ns",
      "items_per_second": 1.5593823118275332e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.1503999829292297e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.3140000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3319,
      "real_time": 2.1084795250730214e+05,
      "cpu_time": 2.1769204941245521e+05,
      "time_unit": "ns",
      "items_per_second": 1.5595761291000051e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.1913599967956543e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.3190000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3444,
      "real_time": 2.0496405796873281e+05,
      "cpu_time": 2.1176080429741391e+05,
      "time_unit": "ns",
      "items_per_second": 1.6043468150409250e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 2.1094399690628052e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.4440000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3441,
      "real_time": 2.0456508938792851e+05,
      "cpu_time": 2.1134632723063556e+05,
      "time_unit": "ns",
      "items_per_second": 1.6074758140985352e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 2.0684799551963806e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.4410000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3417,
      "real_time": 2.0428972059431821e+05,
      "cpu_time": 2.1112334152773459e+05,
      "time_unit": "ns",
      "items_per_second": 1.6096425833045348e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 2.0787200331687927e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.4170000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3428,
      "real_time": 2.0502262560706673e+05,
      "cpu_time": 2.1182223220535147e+05,
      "time_unit": "ns",
      "items_per_second": 1.6038885104818684e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 2.2630399465560913e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.4280000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3422,
      "real_time": 2.0395682276363883e+05,
      "cpu_time": 2.1078801051995787e+05,
      "time_unit": "ns",
      "items_per_second": 1.6122698380189908e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 2.0172800123691559e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.4220000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1897,
      "real_time": 3.6849488235009037e+05,
      "cpu_time": 3.7661239536092896e+05,
      "time_unit": "ns",
      "items_per_second": 8.9236906494562969e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 3.7785598635673523e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.8970000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1897,
      "real_time": 3.6846925855224434e+05,
      "cpu_time": 3.7660819715340203e+05,
      "time_unit": "ns",
      "items_per_second": 8.9243112136958789e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 3.7683200836181641e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.8970000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1900,
      "real_time": 3.6876953625132481e+05,
      "cpu_time": 3.7688424578976166e+05,
      "time_unit": "ns",
      "items_per_second": 8.9170444213670781e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 3.7478399276733398e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.9000000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 112,
      "real_time": 6.2472140000733947e+06,
      "cpu_time": 6.8082482232131464e+06,
      "time_unit": "ns",
      "items_per_second": 5.2636812761038239e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.2395187200000000e+08,
      "advised_time": 6.2771201133728027e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.1200000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 6.2395187200000000e+08,
      "workspace_megabytes": 5.9504687500000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 112,
      "real_time": 6.2463357379393922e+06,
      "cpu_time": 6.8079117857135739e+06,
      "time_unit": "ns",
      "items_per_second": 5.2644213727211389e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.2395187200000000e+08,
      "advised_time": 6.2770881652832031e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.1200000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 6.2395187200000000e+08,
      "workspace_megabytes": 5.9504687500000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 112,
      "real_time": 6.2754197195837544e+06,
      "cpu_time": 6.8397823928566677e+06,
      "time_unit": "ns",
      "items_per_second": 5.2400229513542621e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.2395187200000000e+08,
      "advised_time": 6.2289919853210449e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.1200000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 6.2395187200000000e+08,
      "workspace_megabytes": 5.9504687500000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__14032951822386116681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 7763,
      "real_time": 8.8925527953725119e+04,
      "cpu_time": 9.5233219889449145e+04,
      "time_unit": "ns",
      "items_per_second": 9.2446297808633105e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 8.9088000357151031e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 7.7630000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 7892,
      "real_time": 8.8123535892303480e+04,
      "cpu_time": 9.4453070577696053e+04,
      "time_unit": "ns",
      "items_per_second": 9.3287630333475859e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.0112000703811646e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 7.8920000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 7926,
      "real_time": 8.8467388058328856e+04,
      "cpu_time": 9.4801470603007896e+04,
      "time_unit": "ns",
      "items_per_second": 9.2925043006579883e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 8.8064000010490417e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 7.9260000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 7909,
      "real_time": 8.8159276002966566e+04,
      "cpu_time": 9.4524570236415733e+04,
      "time_unit": "ns",
      "items_per_second": 9.3249811168178926e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 8.9088000357151031e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 7.9090000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 7886,
      "real_time": 8.8087044442637023e+04,
      "cpu_time": 9.4448626046255798e+04,
      "time_unit": "ns",
      "items_per_second": 9.3326276208000977e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.1104000806808472e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 7.8860000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 8003,
      "real_time": 8.6632854956620038e+04,
      "cpu_time": 9.3024033237583455e+04,
      "time_unit": "ns",
      "items_per_second": 9.4892819174855156e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 8.9088000357151031e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 8.0030000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 8048,
      "real_time": 8.7131159170984945e+04,
      "cpu_time": 9.3479708747626428e+04,
      "time_unit": "ns",
      "items_per_second": 9.4350125927597832e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 8.9088000357151031e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 8.0480000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 8021,
      "real_time": 8.7205791034842099e+04,
      "cpu_time": 9.3520561650991192e+04,
      "time_unit": "ns",
      "items_per_second": 9.4269379847898594e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 8.9088000357151031e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 8.0210000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 8013,
      "real_time": 8.6744170838957201e+04,
      "cpu_time": 9.3082109072829364e+04,
      "time_unit": "ns",
      "items_per_second": 9.4771046405667930e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 8.9088000357151031e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 8.0130000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 8036,
      "real_time": 8.7093768199529281e+04,
      "cpu_time": 9.3450735440538541e+04,
      "time_unit": "ns",
      "items_per_second": 9.4390632188129766e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 8.9088000357151031e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 8.0360000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2989,
      "real_time": 2.3406889961099089e+05,
      "cpu_time": 2.4110460655729446e+05,
      "time_unit": "ns",
      "items_per_second": 3.5121435840739878e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2112640000000000e+06,
      "advised_time": 2.3449599742889404e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.9890000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.2112640000000000e+06,
      "workspace_megabytes": 3.0625000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2976,
      "real_time": 2.3379462516615645e+05,
      "cpu_time": 2.4082401075273176e+05,
      "time_unit": "ns",
      "items_per_second": 3.5162638294860293e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2112640000000000e+06,
      "advised_time": 2.3555199801921844e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.9760000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.2112640000000000e+06,
      "workspace_megabytes": 3.0625000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2986,
      "real_time": 2.3429103434794318e+05,
      "cpu_time": 2.4140423141338505e+05,
      "time_unit": "ns",
      "items_per_second": 3.5088136696649355e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2112640000000000e+06,
      "advised_time": 2.3552000522613525e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.9860000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.2112640000000000e+06,
      "workspace_megabytes": 3.0625000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 279,
      "real_time": 2.4295672932873382e+06,
      "cpu_time": 2.5225860107540148e+06,
      "time_unit": "ns",
      "items_per_second": 3.3836625405327863e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.9718860800000000e+08,
      "advised_time": 2.3930881023406982e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.7900000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 5.9718860800000000e+08,
      "workspace_megabytes": 5.6952343750000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 288,
      "real_time": 2.4268483426163178e+06,
      "cpu_time": 2.5198231666669655e+06,
      "time_unit": "ns",
      "items_per_second": 3.3874534702639655e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.9718860800000000e+08,
      "advised_time": 2.3982079029083252e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.8800000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 5.9718860800000000e+08,
      "workspace_megabytes": 5.6952343750000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 288,
      "real_time": 2.4272845718466365e+06,
      "cpu_time": 2.5191842222224521e+06,
      "time_unit": "ns",
      "items_per_second": 3.3868446804099811e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.9718860800000000e+08,
      "advised_time": 2.3982079029083252e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.8800000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 5.9718860800000000e+08,
      "workspace_megabytes": 5.6952343750000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__348019490868906165<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4900,
      "real_time": 1.4232065750176695e+05,
      "cpu_time": 1.4884798326540491e+05,
      "time_unit": "ns",
      "items_per_second": 2.8881386526400552e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.4336000382900238e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 4.9000000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4920,
      "real_time": 1.4186387535762441e+05,
      "cpu_time": 1.4838770040638768e+05,
      "time_unit": "ns",
      "items_per_second": 2.8974380614078496e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.4131200313568115e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 4.9200000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4919,
      "real_time": 1.4211709844788641e+05,
      "cpu_time": 1.4864345923981344e+05,
      "time_unit": "ns",
      "items_per_second": 2.8922754298331440e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.4233599603176117e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 4.9190000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4916,
      "real_time": 1.4203254514512327e+05,
      "cpu_time": 1.4852745138303356e+05,
      "time_unit": "ns",
      "items_per_second": 2.8939972284522095e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.4336000382900238e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 4.9160000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4921,
      "real_time": 1.4165910301465364e+05,
      "cpu_time": 1.4815030664521083e+05,
      "time_unit": "ns",
      "items_per_second": 2.9016263921809570e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.4233599603176117e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 4.9210000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5444,
      "real_time": 1.2929876642672480e+05,
      "cpu_time": 1.3581256649545478e+05,
      "time_unit": "ns",
      "items_per_second": 3.1790078386628882e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 1.3414399325847626e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 5.4440000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5437,
      "real_time": 1.2903792255402454e+05,
      "cpu_time": 1.3551711256199496e+05,
      "time_unit": "ns",
      "items_per_second": 3.1854340481024746e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 1.3107199966907501e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 5.4370000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5409,
      "real_time": 1.2833541214617957e+05,
      "cpu_time": 1.3480010815317577e+05,
      "time_unit": "ns",
      "items_per_second": 3.2028711727033350e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 1.3414399325847626e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 5.4090000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5452,
      "real_time": 1.2938707335885397e+05,
      "cpu_time": 1.3585227934732501e+05,
      "time_unit": "ns",
      "items_per_second": 3.1768381595584824e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 1.3209599256515503e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 5.4520000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5434,
      "real_time": 1.2845384291031532e+05,
      "cpu_time": 1.3492780916444439e+05,
      "time_unit": "ns",
      "items_per_second": 3.1999182172150635e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 1.3312000036239624e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 5.4340000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2214,
      "real_time": 3.1881375902560784e+05,
      "cpu_time": 3.2646045257497864e+05,
      "time_unit": "ns",
      "items_per_second": 1.2892849833591538e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2845056000000000e+07,
      "advised_time": 3.1641599535942078e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.2140000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.2845056000000000e+07,
      "workspace_megabytes": 1.2250000000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2201,
      "real_time": 3.1595031686877407e+05,
      "cpu_time": 3.2362368832306075e+05,
      "time_unit": "ns",
      "items_per_second": 1.3009697096481184e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2845056000000000e+07,
      "advised_time": 3.2358399033546448e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.2010000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.2845056000000000e+07,
      "workspace_megabytes": 1.2250000000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2198,
      "real_time": 3.1794687400756741e+05,
      "cpu_time": 3.2559969745276653e+05,
      "time_unit": "ns",
      "items_per_second": 1.2928002304882446e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2845056000000000e+07,
      "advised_time": 3.1948798894882202e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.1980000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.2845056000000000e+07,
      "workspace_megabytes": 1.2250000000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 313,
      "real_time": 2.2178329497623369e+06,
      "cpu_time": 2.2953235846615373e+06,
      "time_unit": "ns",
      "items_per_second": 1.8533487476775348e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.0633907200000000e+08,
      "advised_time": 2.2435839176177979e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.1300000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.0633907200000000e+08,
      "workspace_megabytes": 5.7825000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 313,
      "real_time": 2.2246621752949283e+06,
      "cpu_time": 2.3023539392964998e+06,
      "time_unit": "ns",
      "items_per_second": 1.8476593730259619e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.0633907200000000e+08,
      "advised_time": 2.2425599098205566e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.1300000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.0633907200000000e+08,
      "workspace_megabytes": 5.7825000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 313,
      "real_time": 2.2331254286007187e+06,
      "cpu_time": 2.3110083386591314e+06,
      "time_unit": "ns",
      "items_per_second": 1.8406569856560168e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.0633907200000000e+08,
      "advised_time": 2.2446079254150391e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.1300000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.0633907200000000e+08,
      "workspace_megabytes": 5.7825000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2059,
      "real_time": 3.3982574588389846e+05,
      "cpu_time": 3.4770045701799978e+05,
      "time_unit": "ns",
      "items_per_second": 1.2095663644638406e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.8410272000000000e+07,
      "advised_time": 3.8400000333786011e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.0590000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.8410272000000000e+07,
      "workspace_megabytes": 2.7094146728515625e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2060,
      "real_time": 3.3995089437914290e+05,
      "cpu_time": 3.4774657572802535e+05,
      "time_unit": "ns",
      "items_per_second": 1.2091210783566003e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.8410272000000000e+07,
      "advised_time": 3.8092800974845886e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.0600000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.8410272000000000e+07,
      "workspace_megabytes": 2.7094146728515625e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2059,
      "real_time": 3.4075710372517596e+05,
      "cpu_time": 3.4856073579407489e+05,
      "time_unit": "ns",
      "items_per_second": 1.2062603758115911e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.8410272000000000e+07,
      "advised_time": 3.8400000333786011e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.0590000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.8410272000000000e+07,
      "workspace_megabytes": 2.7094146728515625e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_8__5225403459068315017<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2615,
      "real_time": 2.6813026853297511e+05,
      "cpu_time": 2.7535673154958867e+05,
      "time_unit": "ns",
      "items_per_second": 2.8743616459893176e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.6931199431419373e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.2042240000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.6150000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2612,
      "real_time": 2.6800398723130324e+05,
      "cpu_time": 2.7524924540648691e+05,
      "time_unit": "ns",
      "items_per_second": 2.8757160218472333e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.6726400852203369e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.2042240000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.6120000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2610,
      "real_time": 2.6785973207472014e+05,
      "cpu_time": 2.7507369846756826e+05,
      "time_unit": "ns",
      "items_per_second": 2.8772647311728455e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.6624000072479248e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.2042240000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.6100000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2609,
      "real_time": 2.6785901695393148e+05,
      "cpu_time": 2.7513316136475693e+05,
      "time_unit": "ns",
      "items_per_second": 2.8772724127952417e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.6828798651695251e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.2042240000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.6090000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2610,
      "real_time": 2.6806673752920079e+05,
      "cpu_time": 2.7527487969299557e+05,
      "time_unit": "ns",
      "items_per_second": 2.8750428609817596e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.6624000072479248e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.2042240000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.6100000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3295,
      "real_time": 2.0894054664819670e+05,
      "cpu_time": 2.1471160667672122e+05,
      "time_unit": "ns",
      "items_per_second": 3.6886251728711639e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.5272000000000000e+04,
      "advised_time": 2.0992000401020050e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.2042240000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.2950000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 7.5272000000000000e+04,
      "workspace_megabytes": 7.1784973144531250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3330,
      "real_time": 2.0897035891128643e+05,
      "cpu_time": 2.1570629579544431e+05,
      "time_unit": "ns",
      "items_per_second": 3.6880989438659308e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.5272000000000000e+04,
      "advised_time": 2.4473600089550018e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.2042240000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.3300000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 7.5272000000000000e+04,
      "workspace_megabytes": 7.1784973144531250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3355,
      "real_time": 2.0859715473354445e+05,
      "cpu_time": 2.1539453412848382e+05,
      "time_unit": "ns",
      "items_per_second": 3.6946973748729822e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.5272000000000000e+04,
      "advised_time": 2.4678400158882141e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.2042240000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.3550000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 7.5272000000000000e+04,
      "workspace_megabytes": 7.1784973144531250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3353,
      "real_time": 2.0900488366865070e+05,
      "cpu_time": 2.1580106919241644e+05,
      "time_unit": "ns",
      "items_per_second": 3.6874897202012134e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.5272000000000000e+04,
      "advised_time": 2.1196800470352173e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.2042240000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.3530000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 7.5272000000000000e+04,
      "workspace_megabytes": 7.1784973144531250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3348,
      "real_time": 2.0886570081580567e+05,
      "cpu_time": 2.1564366039435705e+05,
      "time_unit": "ns",
      "items_per_second": 3.6899469706597119e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.5272000000000000e+04,
      "advised_time": 2.4678400158882141e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.2042240000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.3480000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 7.5272000000000000e+04,
      "workspace_megabytes": 7.1784973144531250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1287,
      "real_time": 5.4188760020281677e+05,
      "cpu_time": 5.5218754156874702e+05,
      "time_unit": "ns",
      "items_per_second": 1.4222568660208176e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.9006976000000000e+07,
      "advised_time": 5.4988801479339600e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.2042240000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.2870000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 5.9006976000000000e+07,
      "workspace_megabytes": 5.6273437500000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1288,
      "real_time": 5.4200511595295009e+05,
      "cpu_time": 5.5234941381943144e+05,
      "time_unit": "ns",
      "items_per_second": 1.4219484970081030e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.9006976000000000e+07,
      "advised_time": 5.4067200422286987e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.2042240000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.2880000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 5.9006976000000000e+07,
      "workspace_megabytes": 5.6273437500000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1291,
      "real_time": 5.4271687404703465e+05,
      "cpu_time": 5.4876286754387978e+05,
      "time_unit": "ns",
      "items_per_second": 1.4200836510810367e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.9006976000000000e+07,
      "advised_time": 5.4579198360443115e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.2042240000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.2910000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 5.9006976000000000e+07,
      "workspace_megabytes": 5.6273437500000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 264,
      "real_time": 2.6499292086527655e+06,
      "cpu_time": 2.6929788939374550e+06,
      "time_unit": "ns",
      "items_per_second": 2.9083922600024044e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.5500800000000000e+06,
      "advised_time": 2.6726400852203369e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.2042240000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.6400000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 5.5500800000000000e+06,
      "workspace_megabytes": 5.2929687500000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 264,
      "real_time": 2.6506472839338873e+06,
      "cpu_time": 2.7323817121233610e+06,
      "time_unit": "ns",
      "items_per_second": 2.9076043601553097e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.5500800000000000e+06,
      "advised_time": 2.6798079013824463e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.2042240000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.6400000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 5.5500800000000000e+06,
      "workspace_megabytes": 5.2929687500000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 264,
      "real_time": 2.6487412141057467e+06,
      "cpu_time": 2.7349598522726749e+06,
      "time_unit": "ns",
      "items_per_second": 2.9096967113874908e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.5500800000000000e+06,
      "advised_time": 2.6900479793548584e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.2042240000000000e+06,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.6400000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 5.5500800000000000e+06,
      "workspace_megabytes": 5.2929687500000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_8__7829673180858493350<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4690,
      "real_time": 1.4878928450110956e+05,
      "cpu_time": 1.5530662878430108e+05,
      "time_unit": "ns",
      "items_per_second": 2.7625765751762500e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.5360000729560852e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.6900000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4703,
      "real_time": 1.4935603923046085e+05,
      "cpu_time": 1.5588986115273685e+05,
      "time_unit": "ns",
      "items_per_second": 2.7520935485290298e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.5564799308776855e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.7030000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4697,
      "real_time": 1.4926531413358977e+05,
      "cpu_time": 1.5579598935485660e+05,
      "time_unit": "ns",
      "items_per_second": 2.7537663012059521e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.5257599949836731e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.6970000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4685,
      "real_time": 1.4872447411249430e+05,
      "cpu_time": 1.5524261792956287e+05,
      "time_unit": "ns",
      "items_per_second": 2.7637804366286782e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.5564799308776855e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.6850000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4703,
      "real_time": 1.4927436888819732e+05,
      "cpu_time": 1.5579433638116947e+05,
      "time_unit": "ns",
      "items_per_second": 2.7535992619594312e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.5462400019168854e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.7030000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6284,
      "real_time": 1.1095225984316929e+05,
      "cpu_time": 1.1733128707818878e+05,
      "time_unit": "ns",
      "items_per_second": 3.7046725553946030e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 1.1468800157308578e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 6.2840000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6318,
      "real_time": 1.1140823309357614e+05,
      "cpu_time": 1.1778433570729355e+05,
      "time_unit": "ns",
      "items_per_second": 3.6895100172242197e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 1.1571200191974640e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 6.3180000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6312,
      "real_time": 1.1123093048214293e+05,
      "cpu_time": 1.1759722908769661e+05,
      "time_unit": "ns",
      "items_per_second": 3.6953911130500596e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 1.1366400122642517e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 6.3120000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6281,
      "real_time": 1.1094056113712865e+05,
      "cpu_time": 1.1732806049959689e+05,
      "time_unit": "ns",
      "items_per_second": 3.7050632139126260e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 1.1571200191974640e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 6.2810000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6317,
      "real_time": 1.1159249030225225e+05,
      "cpu_time": 1.1799751511838012e+05,
      "time_unit": "ns",
      "items_per_second": 3.6834180408258530e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 1.1776000261306763e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 6.3170000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3431,
      "real_time": 2.0388739526123749e+05,
      "cpu_time": 2.1068180821879872e+05,
      "time_unit": "ns",
      "items_per_second": 2.0160235578729087e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 2.1811200678348541e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.4310000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3434,
      "real_time": 2.0368094753081969e+05,
      "cpu_time": 2.1047338031477146e+05,
      "time_unit": "ns",
      "items_per_second": 2.0180669669056985e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 2.1196800470352173e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.4340000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3439,
      "real_time": 2.0388060400247446e+05,
      "cpu_time": 2.1067045129379813e+05,
      "time_unit": "ns",
      "items_per_second": 2.0160907115765229e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 2.1404799818992615e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.4390000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 539,
      "real_time": 1.2535605800350185e+06,
      "cpu_time": 1.2835978905365001e+06,
      "time_unit": "ns",
      "items_per_second": 3.2789942388625323e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.7104793600000000e+08,
      "advised_time": 1.2851200103759766e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 5.3900000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.7104793600000000e+08,
      "workspace_megabytes": 5.4459375000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 560,
      "real_time": 1.2559814422274940e+06,
      "cpu_time": 1.2846601089286481e+06,
      "time_unit": "ns",
      "items_per_second": 3.2726740872143286e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.7104793600000000e+08,
      "advised_time": 1.2861440181732178e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 5.6000000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.7104793600000000e+08,
      "workspace_megabytes": 5.4459375000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 559,
      "real_time": 1.2491611471859496e+06,
      "cpu_time": 1.2781856314848620e+06,
      "time_unit": "ns",
      "items_per_second": 3.2905425607094434e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.7104793600000000e+08,
      "advised_time": 1.2902400493621826e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 5.5900000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.7104793600000000e+08,
      "workspace_megabytes": 5.4459375000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2136,
      "real_time": 3.2877905578197731e+05,
      "cpu_time": 3.3643509737881174e+05,
      "time_unit": "ns",
      "items_per_second": 1.2502067414919929e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.1222976000000000e+07,
      "advised_time": 3.5942399501800537e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.1360000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.1222976000000000e+07,
      "workspace_megabytes": 3.9313293457031250e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2131,
      "real_time": 3.2756803949242906e+05,
      "cpu_time": 3.3516823040922853e+05,
      "time_unit": "ns",
      "items_per_second": 1.2548287453101792e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.1222976000000000e+07,
      "advised_time": 3.5843199491500854e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.1310000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.1222976000000000e+07,
      "workspace_megabytes": 3.9313293457031250e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2133,
      "real_time": 3.2768700706505729e+05,
      "cpu_time": 3.3530179465486394e+05,
      "time_unit": "ns",
      "items_per_second": 1.2543731766526646e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.1222976000000000e+07,
      "advised_time": 3.6044800281524658e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.1330000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.1222976000000000e+07,
      "workspace_megabytes": 3.9313293457031250e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__6361409922115067110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1486,
      "real_time": 4.7100618195533258e+05,
      "cpu_time": 4.8032912180232431e+05,
      "time_unit": "ns",
      "items_per_second": 2.1817218528512903e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.7100800275802612e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.4860000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1486,
      "real_time": 4.6953578076286498e+05,
      "cpu_time": 4.7370812247713585e+05,
      "time_unit": "ns",
      "items_per_second": 2.1885541466731857e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.7104001045227051e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.4860000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1485,
      "real_time": 4.6984210076525511e+05,
      "cpu_time": 4.7918664713736257e+05,
      "time_unit": "ns",
      "items_per_second": 2.1871272887769949e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.7001600265502930e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.4850000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1489,
      "real_time": 4.7006721397557860e+05,
      "cpu_time": 4.7937801880461688e+05,
      "time_unit": "ns",
      "items_per_second": 2.1860798827237228e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.7206398844718933e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.4890000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1489,
      "real_time": 4.6988421460160764e+05,
      "cpu_time": 4.7698036668990151e+05,
      "time_unit": "ns",
      "items_per_second": 2.1869312653357733e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.8025599122047424e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.4890000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1180,
      "real_time": 5.8080292374913779e+05,
      "cpu_time": 5.8263012457632425e+05,
      "time_unit": "ns",
      "items_per_second": 1.7692825534808188e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 6.0108798742294312e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.1800000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1181,
      "real_time": 5.8218729748310975e+05,
      "cpu_time": 5.8461561304025701e+05,
      "time_unit": "ns",
      "items_per_second": 1.7650754051874734e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 5.8367997407913208e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.1810000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1174,
      "real_time": 5.8068911232818966e+05,
      "cpu_time": 5.9180107580855920e+05,
      "time_unit": "ns",
      "items_per_second": 1.7696293217552631e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 6.0927999019622803e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.1740000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1183,
      "real_time": 5.8042782222826919e+05,
      "cpu_time": 5.9145583431941119e+05,
      "time_unit": "ns",
      "items_per_second": 1.7704259524552328e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 5.8265602588653564e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.1830000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1181,
      "real_time": 5.8047677679886366e+05,
      "cpu_time": 5.9150856900902162e+05,
      "time_unit": "ns",
      "items_per_second": 1.7702766433945847e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 6.0207998752593994e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.1810000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1630,
      "real_time": 4.2795814744102559e+05,
      "cpu_time": 4.3678692515314743e+05,
      "time_unit": "ns",
      "items_per_second": 2.4011798493487222e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.2253440000000000e+06,
      "advised_time": 4.4028800725936890e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.6300000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.2253440000000000e+06,
      "workspace_megabytes": 6.8906250000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1628,
      "real_time": 4.2832812092853920e+05,
      "cpu_time": 4.3717724201424414e+05,
      "time_unit": "ns",
      "items_per_second": 2.3991058018145911e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.2253440000000000e+06,
      "advised_time": 4.3007999658584595e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.6280000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.2253440000000000e+06,
      "workspace_megabytes": 6.8906250000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1635,
      "real_time": 4.2778228517103405e+05,
      "cpu_time": 4.3658564220167598e+05,
      "time_unit": "ns",
      "items_per_second": 2.4021669798438419e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.2253440000000000e+06,
      "advised_time": 4.3929600715637207e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.6350000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.2253440000000000e+06,
      "workspace_megabytes": 6.8906250000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 304,
      "real_time": 2.2849724574418934e+06,
      "cpu_time": 2.3669502236838164e+06,
      "time_unit": "ns",
      "items_per_second": 4.4972291751404266e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.2285414400000000e+08,
      "advised_time": 2.2804479598999023e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.0400000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.2285414400000000e+08,
      "workspace_megabytes": 5.9400000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 302,
      "real_time": 2.2981680855648406e+06,
      "cpu_time": 2.3810969867558894e+06,
      "time_unit": "ns",
      "items_per_second": 4.4714069717291229e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.2285414400000000e+08,
      "advised_time": 2.2824959754943848e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.0200000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.2285414400000000e+08,
      "workspace_megabytes": 5.9400000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 308,
      "real_time": 2.2976464666002854e+06,
      "cpu_time": 2.3791093084408971e+06,
      "time_unit": "ns",
      "items_per_second": 4.4724220846756111e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.2285414400000000e+08,
      "advised_time": 2.2794239521026611e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.0800000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.2285414400000000e+08,
      "workspace_megabytes": 5.9400000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 146,
      "real_time": 4.8248059186472064e+06,
      "cpu_time": 5.1698512534282561e+06,
      "time_unit": "ns",
      "items_per_second": 2.1298358883793671e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1765268480000000e+09,
      "advised_time": 4.9879040718078613e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.4600000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1765268480000000e+09,
      "workspace_megabytes": 1.1220234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 146,
      "real_time": 4.8223311872514961e+06,
      "cpu_time": 5.1672539246560335e+06,
      "time_unit": "ns",
      "items_per_second": 2.1309288808628815e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1765268480000000e+09,
      "advised_time": 4.9704642295837402e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.4600000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1765268480000000e+09,
      "workspace_megabytes": 1.1220234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 146,
      "real_time": 4.8237626109119151e+06,
      "cpu_time": 5.1691974657552699e+06,
      "time_unit": "ns",
      "items_per_second": 2.1302965400400066e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1765268480000000e+09,
      "advised_time": 4.9838080406188965e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.4600000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1765268480000000e+09,
      "workspace_megabytes": 1.1220234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2267,
      "real_time": 3.0672935716120544e+05,
      "cpu_time": 3.1232203484764358e+05,
      "time_unit": "ns",
      "items_per_second": 3.3501993076584766e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.6216448000000000e+07,
      "advised_time": 3.4611201286315918e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.1941256922983490e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.2670000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.6216448000000000e+07,
      "workspace_megabytes": 2.5001953125000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2266,
      "real_time": 3.0632095870659302e+05,
      "cpu_time": 3.1384507193249511e+05,
      "time_unit": "ns",
      "items_per_second": 3.3546659175361304e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.6216448000000000e+07,
      "advised_time": 3.4713599085807800e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.1941256922983490e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.2660000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.6216448000000000e+07,
      "workspace_megabytes": 2.5001953125000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2281,
      "real_time": 3.0749463483641000e+05,
      "cpu_time": 3.1351132792558067e+05,
      "time_unit": "ns",
      "items_per_second": 3.3418614947434619e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.6216448000000000e+07,
      "advised_time": 3.3177599310874939e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.1941256922983490e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.2810000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.6216448000000000e+07,
      "workspace_megabytes": 2.5001953125000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1988,
      "real_time": 3.4978878370172792e+05,
      "cpu_time": 3.5769840794704779e+05,
      "time_unit": "ns",
      "items_per_second": 2.9377856806187915e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7185920000000000e+07,
      "advised_time": 3.7887999415397644e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.0444073425867530e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.9880000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7185920000000000e+07,
      "workspace_megabytes": 4.5000000000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1987,
      "real_time": 3.4958037019181839e+05,
      "cpu_time": 3.5751577352815983e+05,
      "time_unit": "ns",
      "items_per_second": 2.9395371354408221e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7185920000000000e+07,
      "advised_time": 3.8092800974845886e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.0444073425867530e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.9870000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7185920000000000e+07,
      "workspace_megabytes": 4.5000000000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1997,
      "real_time": 3.4950377684425603e+05,
      "cpu_time": 3.5745592538826057e+05,
      "time_unit": "ns",
      "items_per_second": 2.9401813315966406e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7185920000000000e+07,
      "advised_time": 3.7990400195121765e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.0444073425867530e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.9970000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7185920000000000e+07,
      "workspace_megabytes": 4.5000000000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__2826052438624205483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5368,
      "real_time": 1.3157554792389728e+05,
      "cpu_time": 1.3788900577511909e+05,
      "time_unit": "ns",
      "items_per_second": 3.1239983301285186e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.3107199966907501e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.3680000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5311,
      "real_time": 1.3144654091520363e+05,
      "cpu_time": 1.3791165016034050e+05,
      "time_unit": "ns",
      "items_per_second": 3.1270643497964976e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.3107199966907501e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.3110000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5323,
      "real_time": 1.3155204230026650e+05,
      "cpu_time": 1.3799723050902414e+05,
      "time_unit": "ns",
      "items_per_second": 3.1245565238873325e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.3107199966907501e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.3230000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5349,
      "real_time": 1.3136755030527437e+05,
      "cpu_time": 1.3782321592816565e+05,
      "time_unit": "ns",
      "items_per_second": 3.1289446369732358e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.3107199966907501e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.3490000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5341,
      "real_time": 1.3147274627356985e+05,
      "cpu_time": 1.3790755139529146e+05,
      "time_unit": "ns",
      "items_per_second": 3.1264410583216997e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.3107199966907501e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.3410000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6567,
      "real_time": 1.0678447261482102e+05,
      "cpu_time": 1.1314198142144785e+05,
      "time_unit": "ns",
      "items_per_second": 3.8492655527049907e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 1.0956799983978271e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.5670000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6552,
      "real_time": 1.0672088892233960e+05,
      "cpu_time": 1.1306700946298853e+05,
      "time_unit": "ns",
      "items_per_second": 3.8515589230062881e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 1.0956799983978271e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.5520000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6555,
      "real_time": 1.0673315159168946e+05,
      "cpu_time": 1.1312072341702752e+05,
      "time_unit": "ns",
      "items_per_second": 3.8511164138809604e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 1.1062400043010712e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.5550000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6561,
      "real_time": 1.0680734754130221e+05,
      "cpu_time": 1.1315585840587541e+05,
      "time_unit": "ns",
      "items_per_second": 3.8484411556147939e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 1.0956799983978271e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.5610000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6556,
      "real_time": 1.0666057362409831e+05,
      "cpu_time": 1.1302825838928275e+05,
      "time_unit": "ns",
      "items_per_second": 3.8537369342173818e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 1.0956799983978271e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.5560000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2147,
      "real_time": 3.2645188754361123e+05,
      "cpu_time": 3.3416216767586773e+05,
      "time_unit": "ns",
      "items_per_second": 1.2591190545500776e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5690112000000000e+07,
      "advised_time": 3.3075198531150818e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.1470000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.5690112000000000e+07,
      "workspace_megabytes": 2.4500000000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2144,
      "real_time": 3.2615494608002499e+05,
      "cpu_time": 3.3384484001873556e+05,
      "time_unit": "ns",
      "items_per_second": 1.2602653951448809e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5690112000000000e+07,
      "advised_time": 3.3280000090599060e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.1440000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.5690112000000000e+07,
      "workspace_megabytes": 2.4500000000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2146,
      "real_time": 3.2651895358386030e+05,
      "cpu_time": 3.3420138816468092e+05,
      "time_unit": "ns",
      "items_per_second": 1.2588604351705164e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5690112000000000e+07,
      "advised_time": 3.3280000090599060e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.1460000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.5690112000000000e+07,
      "workspace_megabytes": 2.4500000000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 525,
      "real_time": 1.2128349216211410e+06,
      "cpu_time": 1.2438979047635172e+06,
      "time_unit": "ns",
      "items_per_second": 3.3890992473285583e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.2295244800000000e+08,
      "advised_time": 1.2503039836883545e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.2500000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.2295244800000000e+08,
      "workspace_megabytes": 5.9409375000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 571,
      "real_time": 1.2223075299757009e+06,
      "cpu_time": 1.2511810700512852e+06,
      "time_unit": "ns",
      "items_per_second": 3.3628344906635022e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.2295244800000000e+08,
      "advised_time": 1.2410880327224731e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.7100000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.2295244800000000e+08,
      "workspace_megabytes": 5.9409375000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 573,
      "real_time": 1.2131858408616867e+06,
      "cpu_time": 1.2416246143119405e+06,
      "time_unit": "ns",
      "items_per_second": 3.3881189357440106e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.2295244800000000e+08,
      "advised_time": 1.2400640249252319e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.7300000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.2295244800000000e+08,
      "workspace_megabytes": 5.9409375000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2040,
      "real_time": 3.4434484833207750e+05,
      "cpu_time": 3.5211818774512288e+05,
      "time_unit": "ns",
      "items_per_second": 1.1936922941957351e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.1222976000000000e+07,
      "advised_time": 3.7990400195121765e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.0400000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.1222976000000000e+07,
      "workspace_megabytes": 3.9313293457031250e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2035,
      "real_time": 3.4301476185530401e+05,
      "cpu_time": 3.5084165356213233e+05,
      "time_unit": "ns",
      "items_per_second": 1.1983209987137292e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.1222976000000000e+07,
      "advised_time": 3.8297599554061890e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.0350000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.1222976000000000e+07,
      "workspace_megabytes": 3.9313293457031250e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2040,
      "real_time": 3.4387170318023342e+05,
      "cpu_time": 3.5168760392119613e+05,
      "time_unit": "ns",
      "items_per_second": 1.1953347373411553e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.1222976000000000e+07,
      "advised_time": 3.7478399276733398e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.0400000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.1222976000000000e+07,
      "workspace_megabytes": 3.9313293457031250e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__14078084679921424674<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3111,
      "real_time": 2.2465893713503983e+05,
      "cpu_time": 2.3156763516617363e+05,
      "time_unit": "ns",
      "items_per_second": 1.4637006557292760e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.3961600661277771e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 3.1110000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3111,
      "real_time": 2.2471190031096389e+05,
      "cpu_time": 2.3164467341674454e+05,
      "time_unit": "ns",
      "items_per_second": 1.4633556707274926e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.2937600314617157e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 3.1110000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3110,
      "real_time": 2.2468325726248452e+05,
      "cpu_time": 2.3157594308675287e+05,
      "time_unit": "ns",
      "items_per_second": 1.4635422220884170e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.2937600314617157e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 3.1100000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3112,
      "real_time": 2.2446206710478655e+05,
      "cpu_time": 2.3135052891975638e+05,
      "time_unit": "ns",
      "items_per_second": 1.4649844307389779e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.2937600314617157e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 3.1120000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3115,
      "real_time": 2.2463770997172361e+05,
      "cpu_time": 2.3152592905287832e+05,
      "time_unit": "ns",
      "items_per_second": 1.4638389682720326e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.2835199534893036e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 3.1150000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3721,
      "real_time": 1.8675781559649363e+05,
      "cpu_time": 1.9343586401459723e+05,
      "time_unit": "ns",
      "items_per_second": 1.7607479106013586e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 1.9046400487422943e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 3.7210000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3740,
      "real_time": 1.8671649349196613e+05,
      "cpu_time": 1.9339480695192562e+05,
      "time_unit": "ns",
      "items_per_second": 1.7611375805648832e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 1.8943999707698822e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 3.7400000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3699,
      "real_time": 1.8677031656507016e+05,
      "cpu_time": 1.9342994647236177e+05,
      "time_unit": "ns",
      "items_per_second": 1.7606300596777941e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 1.8943999707698822e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 3.6990000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3733,
      "real_time": 1.8667197214751240e+05,
      "cpu_time": 1.9337442566251228e+05,
      "time_unit": "ns",
      "items_per_second": 1.7615576126240762e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 1.8943999707698822e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 3.7330000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3741,
      "real_time": 1.8670589693693633e+05,
      "cpu_time": 1.9342618765093535e+05,
      "time_unit": "ns",
      "items_per_second": 1.7612375345116715e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 1.9148799777030945e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 3.7410000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1882,
      "real_time": 3.6899322943821823e+05,
      "cpu_time": 3.7715868225334288e+05,
      "time_unit": "ns",
      "items_per_second": 8.9116386796754941e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2112640000000000e+06,
      "advised_time": 3.7376001477241516e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 1.8820000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.2112640000000000e+06,
      "workspace_megabytes": 3.0625000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1886,
      "real_time": 3.6791533788565884e+05,
      "cpu_time": 3.7607161293738801e+05,
      "time_unit": "ns",
      "items_per_second": 8.9377473494240469e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2112640000000000e+06,
      "advised_time": 3.7273600697517395e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 1.8860000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.2112640000000000e+06,
      "workspace_megabytes": 3.0625000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1890,
      "real_time": 3.6902048379594268e+05,
      "cpu_time": 3.7718355502672348e+05,
      "time_unit": "ns",
      "items_per_second": 8.9109805021510684e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2112640000000000e+06,
      "advised_time": 3.7376001477241516e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 1.8900000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.2112640000000000e+06,
      "workspace_megabytes": 3.0625000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 75,
      "real_time": 9.2842522139350567e+06,
      "cpu_time": 1.0573073759999260e+07,
      "time_unit": "ns",
      "items_per_second": 3.5418408076683057e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.3352033280000000e+09,
      "advised_time": 9.3204479217529297e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 7.5000000000000000e+01,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 2.3352033280000000e+09,
      "workspace_megabytes": 2.2270234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 75,
      "real_time": 9.3058543528119717e+06,
      "cpu_time": 1.0599659293333540e+07,
      "time_unit": "ns",
      "items_per_second": 3.5336189578406158e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.3352033280000000e+09,
      "advised_time": 9.3265924453735352e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 7.5000000000000000e+01,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 2.3352033280000000e+09,
      "workspace_megabytes": 2.2270234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 75,
      "real_time": 9.3152192731698360e+06,
      "cpu_time": 1.0609684986669285e+07,
      "time_unit": "ns",
      "items_per_second": 3.5300664853603894e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.3352033280000000e+09,
      "advised_time": 9.3562879562377930e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 7.5000000000000000e+01,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 2.3352033280000000e+09,
      "workspace_megabytes": 2.2270234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_8__11508918323232429414<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 13202,
      "real_time": 5.1518034951204616e+04,
      "cpu_time": 5.7802242918134449e+04,
      "time_unit": "ns",
      "items_per_second": 1.9946499919364106e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.4271999746561050e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.3202000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 13610,
      "real_time": 5.1292555763024458e+04,
      "cpu_time": 5.7548810727298725e+04,
      "time_unit": "ns",
      "items_per_second": 2.0034183610339316e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.2223999053239822e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.3610000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 13553,
      "real_time": 5.1240889748771609e+04,
      "cpu_time": 5.7487230502415150e+04,
      "time_unit": "ns",
      "items_per_second": 2.0054384009298638e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.2223999053239822e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.3553000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 13621,
      "real_time": 5.1284890360575038e+04,
      "cpu_time": 5.7538451214974717e+04,
      "time_unit": "ns",
      "items_per_second": 2.0037178061122754e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.2223999053239822e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.3621000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 13587,
      "real_time": 5.1426018878323586e+04,
      "cpu_time": 5.7678850960686228e+04,
      "time_unit": "ns",
      "items_per_second": 1.9982189996689441e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.3247999399900436e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.3587000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 15918,
      "real_time": 4.4000291498291983e+04,
      "cpu_time": 5.0273888302316380e+04,
      "time_unit": "ns",
      "items_per_second": 2.3354492550120713e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 4.6080000698566437e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.5918000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 15960,
      "real_time": 4.3991003510147821e+04,
      "cpu_time": 5.0233001378732079e+04,
      "time_unit": "ns",
      "items_per_second": 2.3359423473096104e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 4.8128001391887665e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.5960000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 15907,
      "real_time": 4.3925621672778187e+04,
      "cpu_time": 5.0164660149548494e+04,
      "time_unit": "ns",
      "items_per_second": 2.3394193203572402e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 4.7104001045227051e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.5907000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 15961,
      "real_time": 4.3775759398753995e+04,
      "cpu_time": 5.0034893365143391e+04,
      "time_unit": "ns",
      "items_per_second": 2.3474281065909941e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 4.7104001045227051e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.5961000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 15988,
      "real_time": 4.3881387034585350e+04,
      "cpu_time": 5.0131373717840252e+04,
      "time_unit": "ns",
      "items_per_second": 2.3417775723226069e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 4.7104001045227051e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.5988000000000000e+04,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6482,
      "real_time": 1.0784515867598337e+05,
      "cpu_time": 1.1424081595200105e+05,
      "time_unit": "ns",
      "items_per_second": 9.5285174839178284e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 1.1059200018644333e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.4820000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6473,
      "real_time": 1.0810028593557750e+05,
      "cpu_time": 1.1449609593678657e+05,
      "time_unit": "ns",
      "items_per_second": 9.5060292496580640e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 1.1264000087976456e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.4730000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6472,
      "real_time": 1.0804653134865881e+05,
      "cpu_time": 1.1444620024762252e+05,
      "time_unit": "ns",
      "items_per_second": 9.5107586256886877e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 1.1161600053310394e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.4720000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1983,
      "real_time": 3.5051194589833514e+05,
      "cpu_time": 3.5842897428112413e+05,
      "time_unit": "ns",
      "items_per_second": 2.9317245589628302e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.5581184000000000e+08,
      "advised_time": 3.7171199917793274e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.9830000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.5581184000000000e+08,
      "workspace_megabytes": 1.4859375000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2018,
      "real_time": 3.4795989496107289e+05,
      "cpu_time": 3.5582479534188361e+05,
      "time_unit": "ns",
      "items_per_second": 2.9532267795257281e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.5581184000000000e+08,
      "advised_time": 3.6966401338577271e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.0180000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.5581184000000000e+08,
      "workspace_megabytes": 1.4859375000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2011,
      "real_time": 3.4857483685256529e+05,
      "cpu_time": 3.5648501442037104e+05,
      "time_unit": "ns",
      "items_per_second": 2.9480168140611945e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.5581184000000000e+08,
      "advised_time": 3.6969599127769470e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.0110000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.5581184000000000e+08,
      "workspace_megabytes": 1.4859375000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5035,
      "real_time": 1.3915253575389989e+05,
      "cpu_time": 1.4558717636606441e+05,
      "time_unit": "ns",
      "items_per_second": 7.3847341295841272e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6155456000000000e+07,
      "advised_time": 1.5155200660228729e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.0350000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6155456000000000e+07,
      "workspace_megabytes": 1.5407043457031250e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5031,
      "real_time": 1.3906960688165145e+05,
      "cpu_time": 1.4552397614777694e+05,
      "time_unit": "ns",
      "items_per_second": 7.3891377349940576e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6155456000000000e+07,
      "advised_time": 1.5360000729560852e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.0310000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6155456000000000e+07,
      "workspace_megabytes": 1.5407043457031250e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5022,
      "real_time": 1.3905420790857417e+05,
      "cpu_time": 1.4547336200703785e+05,
      "time_unit": "ns",
      "items_per_second": 7.3899560139570386e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6155456000000000e+07,
      "advised_time": 1.5360000729560852e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.0220000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6155456000000000e+07,
      "workspace_megabytes": 1.5407043457031250e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__16984560470518988758<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4784,
      "real_time": 1.4580675048688304e+05,
      "cpu_time": 1.5232889590326848e+05,
      "time_unit": "ns",
      "items_per_second": 2.8190861577220171e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.4847999811172485e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 4.7840000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4786,
      "real_time": 1.4549861885020544e+05,
      "cpu_time": 1.5201351817808932e+05,
      "time_unit": "ns",
      "items_per_second": 2.8250563149549761e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.4643199741840363e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 4.7860000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4788,
      "real_time": 1.4562313929125285e+05,
      "cpu_time": 1.5215296470355702e+05,
      "time_unit": "ns",
      "items_per_second": 2.8226406462636260e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.4540800452232361e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 4.7880000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4788,
      "real_time": 1.4559417305359189e+05,
      "cpu_time": 1.5210345008310015e+05,
      "time_unit": "ns",
      "items_per_second": 2.8232022159890918e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.4844800531864166e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 4.7880000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4784,
      "real_time": 1.4571972687948297e+05,
      "cpu_time": 1.5223381040991656e+05,
      "time_unit": "ns",
      "items_per_second": 2.8207697118451973e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.4745600521564484e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 4.7840000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5295,
      "real_time": 1.2975496375338352e+05,
      "cpu_time": 1.3628090047192495e+05,
      "time_unit": "ns",
      "items_per_second": 3.1678309646884829e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.3312000036239624e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 5.2950000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5361,
      "real_time": 1.2963603321387127e+05,
      "cpu_time": 1.3606575937271173e+05,
      "time_unit": "ns",
      "items_per_second": 3.1707371925047290e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.3312000036239624e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 5.3610000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5371,
      "real_time": 1.2950831757345743e+05,
      "cpu_time": 1.3593993651089375e+05,
      "time_unit": "ns",
      "items_per_second": 3.1738640397892290e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.3312000036239624e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 5.3710000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5373,
      "real_time": 1.2957197062812625e+05,
      "cpu_time": 1.3604381872277043e+05,
      "time_unit": "ns",
      "items_per_second": 3.1723048588934170e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.3414399325847626e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 5.3730000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5368,
      "real_time": 1.2968671058509593e+05,
      "cpu_time": 1.3612688934482905e+05,
      "time_unit": "ns",
      "items_per_second": 3.1694981709809707e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.3312000036239624e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 5.3680000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2561,
      "real_time": 2.6528006717737229e+05,
      "cpu_time": 2.7251747286232252e+05,
      "time_unit": "ns",
      "items_per_second": 1.5494635400750562e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.0281600000000000e+05,
      "advised_time": 2.6214399933815002e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.5610000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 8.0281600000000000e+05,
      "workspace_megabytes": 7.6562500000000000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2618,
      "real_time": 2.6549110785608710e+05,
      "cpu_time": 2.7265343048136804e+05,
      "time_unit": "ns",
      "items_per_second": 1.5482318610189028e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.0281600000000000e+05,
      "advised_time": 2.6624000072479248e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.6180000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 8.0281600000000000e+05,
      "workspace_megabytes": 7.6562500000000000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2588,
      "real_time": 2.6517241836149088e+05,
      "cpu_time": 2.7240638987683965e+05,
      "time_unit": "ns",
      "items_per_second": 1.5500925569101072e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.0281600000000000e+05,
      "advised_time": 2.6624000072479248e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.5880000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 8.0281600000000000e+05,
      "workspace_megabytes": 7.6562500000000000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 111,
      "real_time": 6.1685119772346709e+06,
      "cpu_time": 6.6901637567559341e+06,
      "time_unit": "ns",
      "items_per_second": 6.6635485756853317e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4295505920000000e+09,
      "advised_time": 6.2228479385375977e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.1100000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.4295505920000000e+09,
      "workspace_megabytes": 2.3170000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 111,
      "real_time": 6.1856619845907968e+06,
      "cpu_time": 6.7136363963956544e+06,
      "time_unit": "ns",
      "items_per_second": 6.6450736077068695e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4295505920000000e+09,
      "advised_time": 6.1798720359802246e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.1100000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.4295505920000000e+09,
      "workspace_megabytes": 2.3170000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 111,
      "real_time": 6.1712236235941853e+06,
      "cpu_time": 6.7002956126167839e+06,
      "time_unit": "ns",
      "items_per_second": 6.6606206008883041e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4295505920000000e+09,
      "advised_time": 6.2074880599975586e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.1100000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.4295505920000000e+09,
      "workspace_megabytes": 2.3170000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 587,
      "real_time": 1.1702668811456386e+06,
      "cpu_time": 1.1960259454859265e+06,
      "time_unit": "ns",
      "items_per_second": 3.5123765238712781e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6210371200000000e+08,
      "advised_time": 1.2195839881896973e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 5.8700000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6210371200000000e+08,
      "workspace_megabytes": 1.5459414672851562e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 589,
      "real_time": 1.1727080227022890e+06,
      "cpu_time": 1.1984567317480852e+06,
      "time_unit": "ns",
      "items_per_second": 3.5050650634488715e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6210371200000000e+08,
      "advised_time": 1.2226560115814209e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 5.8900000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6210371200000000e+08,
      "workspace_megabytes": 1.5459414672851562e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 588,
      "real_time": 1.1692219871162837e+06,
      "cpu_time": 1.1950170289127044e+06,
      "time_unit": "ns",
      "items_per_second": 3.5155154156292847e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6210371200000000e+08,
      "advised_time": 1.2216320037841797e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 5.8800000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6210371200000000e+08,
      "workspace_megabytes": 1.5459414672851562e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__7421289225498010172<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5282,
      "real_time": 1.3187233676185051e+05,
      "cpu_time": 1.3836403085919164e+05,
      "time_unit": "ns",
      "items_per_second": 3.1169675315779399e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.3312000036239624e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 5.2820000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5280,
      "real_time": 1.3275720360373575e+05,
      "cpu_time": 1.3908223409073110e+05,
      "time_unit": "ns",
      "items_per_second": 3.0961920019565210e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.3107199966907501e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 5.2800000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5317,
      "real_time": 1.3184061734098117e+05,
      "cpu_time": 1.3828866748154067e+05,
      "time_unit": "ns",
      "items_per_second": 3.1177174401187534e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.3619199395179749e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 5.3170000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5285,
      "real_time": 1.3197093386528615e+05,
      "cpu_time": 1.3844925752168446e+05,
      "time_unit": "ns",
      "items_per_second": 3.1146388069026240e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.3823999464511871e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 5.2850000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5275,
      "real_time": 1.3206502285585145e+05,
      "cpu_time": 1.3852659071052889e+05,
      "time_unit": "ns",
      "items_per_second": 3.1124197998182368e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.3516800105571747e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 5.2750000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6500,
      "real_time": 1.0720073810639756e+05,
      "cpu_time": 1.1356928400026880e+05,
      "time_unit": "ns",
      "items_per_second": 3.8343186741124663e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 1.1059200018644333e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 6.5000000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6516,
      "real_time": 1.0724364855985648e+05,
      "cpu_time": 1.1359185926974018e+05,
      "time_unit": "ns",
      "items_per_second": 3.8327844820626650e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 1.1161600053310394e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 6.5160000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6510,
      "real_time": 1.0727518731126448e+05,
      "cpu_time": 1.1364696374790232e+05,
      "time_unit": "ns",
      "items_per_second": 3.8316576489150381e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 1.1161600053310394e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 6.5100000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6512,
      "real_time": 1.0724217159554260e+05,
      "cpu_time": 1.1364867567544752e+05,
      "time_unit": "ns",
      "items_per_second": 3.8328372680685674e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 1.1161600053310394e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 6.5120000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6502,
      "real_time": 1.0719306024946597e+05,
      "cpu_time": 1.1358258581998544e+05,
      "time_unit": "ns",
      "items_per_second": 3.8345933126957979e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 1.1161600053310394e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 6.5020000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2543,
      "real_time": 2.7337596179561113e+05,
      "cpu_time": 2.7924471962259256e+05,
      "time_unit": "ns",
      "items_per_second": 1.5035769396115171e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6056320000000000e+06,
      "advised_time": 2.7443200349807739e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 2.5430000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6056320000000000e+06,
      "workspace_megabytes": 1.5312500000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2553,
      "real_time": 2.7361895156580309e+05,
      "cpu_time": 2.8091031296569674e+05,
      "time_unit": "ns",
      "items_per_second": 1.5022416745908328e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6056320000000000e+06,
      "advised_time": 2.7545601129531860e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 2.5530000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6056320000000000e+06,
      "workspace_megabytes": 1.5312500000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2550,
      "real_time": 2.7361436826907389e+05,
      "cpu_time": 2.8087806627483730e+05,
      "time_unit": "ns",
      "items_per_second": 1.5022668385447478e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6056320000000000e+06,
      "advised_time": 2.7955201268196106e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 2.5500000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6056320000000000e+06,
      "workspace_megabytes": 1.5312500000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 314,
      "real_time": 2.2189398511212058e+06,
      "cpu_time": 2.2961970414003320e+06,
      "time_unit": "ns",
      "items_per_second": 1.8524242186749908e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.0974694400000000e+08,
      "advised_time": 2.2220799922943115e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 3.1400000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.0974694400000000e+08,
      "workspace_megabytes": 5.8150000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 313,
      "real_time": 2.2199998108354714e+06,
      "cpu_time": 2.2979555718829609e+06,
      "time_unit": "ns",
      "items_per_second": 1.8515397613719125e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.0974694400000000e+08,
      "advised_time": 2.2262079715728760e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 3.1300000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.0974694400000000e+08,
      "workspace_megabytes": 5.8150000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 314,
      "real_time": 2.2184506694898959e+06,
      "cpu_time": 2.2958114140128032e+06,
      "time_unit": "ns",
      "items_per_second": 1.8528326892863196e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.0974694400000000e+08,
      "advised_time": 2.2261760234832764e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 3.1400000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.0974694400000000e+08,
      "workspace_megabytes": 5.8150000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1309,
      "real_time": 5.3044293238372286e+05,
      "cpu_time": 5.4055338960990973e+05,
      "time_unit": "ns",
      "items_per_second": 7.7490294790590588e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.5148960000000000e+07,
      "advised_time": 5.5500799417495728e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 1.3090000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.5148960000000000e+07,
      "workspace_megabytes": 5.2594146728515625e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1317,
      "real_time": 5.2995523379517382e+05,
      "cpu_time": 5.4005393546041055e+05,
      "time_unit": "ns",
      "items_per_second": 7.7561606299536340e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.5148960000000000e+07,
      "advised_time": 5.6627202033996582e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 1.3170000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.5148960000000000e+07,
      "workspace_megabytes": 5.2594146728515625e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1317,
      "real_time": 5.3021964136562007e+05,
      "cpu_time": 5.4036048063833476e+05,
      "time_unit": "ns",
      "items_per_second": 7.7522928222977820e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.5148960000000000e+07,
      "advised_time": 5.6524801254272461e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 1.3170000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.5148960000000000e+07,
      "workspace_megabytes": 5.2594146728515625e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__15642944783504185429<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2287,
      "real_time": 3.0658284693585394e+05,
      "cpu_time": 3.1411250284222484e+05,
      "time_unit": "ns",
      "items_per_second": 3.3518003054326282e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.1539198756217957e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.2870000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2288,
      "real_time": 3.0616747977177880e+05,
      "cpu_time": 3.1367870760562894e+05,
      "time_unit": "ns",
      "items_per_second": 3.3563475806313251e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.0412799119949341e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.2880000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2284,
      "real_time": 3.0613654441340471e+05,
      "cpu_time": 3.1364021628597513e+05,
      "time_unit": "ns",
      "items_per_second": 3.3566867424110272e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.0515199899673462e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.2840000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2275,
      "real_time": 3.0621937652640452e+05,
      "cpu_time": 3.1369812087879813e+05,
      "time_unit": "ns",
      "items_per_second": 3.3557787611503162e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.0614399909973145e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.2750000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2282,
      "real_time": 3.0619721395154565e+05,
      "cpu_time": 3.1369352892259933e+05,
      "time_unit": "ns",
      "items_per_second": 3.3560216526418622e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.0412799119949341e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.2820000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2332,
      "real_time": 3.0018314867964137e+05,
      "cpu_time": 3.0759244039343740e+05,
      "time_unit": "ns",
      "items_per_second": 3.4232583824905853e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 3.0614399909973145e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.3320000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2331,
      "real_time": 3.0015537346777570e+05,
      "cpu_time": 3.0757901072503132e+05,
      "time_unit": "ns",
      "items_per_second": 3.4235751575186188e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 3.2153600454330444e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.3310000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2328,
      "real_time": 3.0221945049448812e+05,
      "cpu_time": 3.0758529596121551e+05,
      "time_unit": "ns",
      "items_per_second": 3.4001930660605890e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 3.2358399033546448e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.3280000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2327,
      "real_time": 3.0042393412751186e+05,
      "cpu_time": 3.0786693296051369e+05,
      "time_unit": "ns",
      "items_per_second": 3.4205146902970911e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 3.2153600454330444e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.3270000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2323,
      "real_time": 3.0110862050808844e+05,
      "cpu_time": 3.0854071157950361e+05,
      "time_unit": "ns",
      "items_per_second": 3.4127368331933765e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 3.0412799119949341e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.3230000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2192,
      "real_time": 3.1913326914361882e+05,
      "cpu_time": 3.2678537545558769e+05,
      "time_unit": "ns",
      "items_per_second": 3.2199854398055548e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.4450688000000000e+07,
      "advised_time": 3.2153600454330444e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.1920000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.4450688000000000e+07,
      "workspace_megabytes": 1.3781250000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2192,
      "real_time": 3.1932960509749159e+05,
      "cpu_time": 3.2698967427103902e+05,
      "time_unit": "ns",
      "items_per_second": 3.2180056706182050e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.4450688000000000e+07,
      "advised_time": 3.2153600454330444e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.1920000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.4450688000000000e+07,
      "workspace_megabytes": 1.3781250000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2192,
      "real_time": 3.1942413089999568e+05,
      "cpu_time": 3.2704613412352733e+05,
      "time_unit": "ns",
      "items_per_second": 3.2170533801083405e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.4450688000000000e+07,
      "advised_time": 3.2563200592994690e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.1920000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.4450688000000000e+07,
      "workspace_megabytes": 1.3781250000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1106,
      "real_time": 6.1542148534275906e+05,
      "cpu_time": 6.2718069981924375e+05,
      "time_unit": "ns",
      "items_per_second": 1.6697572386958112e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.5807283200000000e+08,
      "advised_time": 6.3999998569488525e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.1060000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.5807283200000000e+08,
      "workspace_megabytes": 1.5075000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1139,
      "real_time": 6.1725089344898390e+05,
      "cpu_time": 6.2881041615540418e+05,
      "time_unit": "ns",
      "items_per_second": 1.6648084124400412e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.5807283200000000e+08,
      "advised_time": 6.3590401411056519e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.1390000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.5807283200000000e+08,
      "workspace_megabytes": 1.5075000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1135,
      "real_time": 6.2040320165775355e+05,
      "cpu_time": 6.3200172687279095e+05,
      "time_unit": "ns",
      "items_per_second": 1.6563494147905441e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.5807283200000000e+08,
      "advised_time": 6.0927999019622803e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.1350000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.5807283200000000e+08,
      "workspace_megabytes": 1.5075000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 549,
      "real_time": 1.2774150470824733e+06,
      "cpu_time": 1.3067129071046342e+06,
      "time_unit": "ns",
      "items_per_second": 8.0444056326640030e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0306304000000000e+08,
      "advised_time": 1.3302079439163208e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 5.4900000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0306304000000000e+08,
      "workspace_megabytes": 2.8902343750000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 548,
      "real_time": 1.2755239801736292e+06,
      "cpu_time": 1.3048116770072279e+06,
      "time_unit": "ns",
      "items_per_second": 8.0563321111385040e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0306304000000000e+08,
      "advised_time": 1.3342720270156860e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 5.4800000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0306304000000000e+08,
      "workspace_megabytes": 2.8902343750000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 550,
      "real_time": 1.2848180517638947e+06,
      "cpu_time": 1.3143189145466750e+06,
      "time_unit": "ns",
      "items_per_second": 7.9980544995396606e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0306304000000000e+08,
      "advised_time": 1.3312000036239624e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 5.5000000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0306304000000000e+08,
      "workspace_megabytes": 2.8902343750000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4752,
      "real_time": 1.4714601107845388e+05,
      "cpu_time": 1.5363822579997982e+05,
      "time_unit": "ns",
      "items_per_second": 6.9835700775613403e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.5546240000000000e+06,
      "advised_time": 1.7612800002098083e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.1941256922983490e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.7520000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.5546240000000000e+06,
      "workspace_megabytes": 6.2509765625000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4746,
      "real_time": 1.4739060365655069e+05,
      "cpu_time": 1.5389781605595021e+05,
      "time_unit": "ns",
      "items_per_second": 6.9719809438770056e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.5546240000000000e+06,
      "advised_time": 1.7100800573825836e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.1941256922983490e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.7460000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.5546240000000000e+06,
      "workspace_megabytes": 6.2509765625000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4744,
      "real_time": 1.4741112936094651e+05,
      "cpu_time": 1.5395559000780576e+05,
      "time_unit": "ns",
      "items_per_second": 6.9710101567964954e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.5546240000000000e+06,
      "advised_time": 1.6998399794101715e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.1941256922983490e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.7440000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.5546240000000000e+06,
      "workspace_megabytes": 6.2509765625000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3675,
      "real_time": 1.9017256885453375e+05,
      "cpu_time": 1.9688283047607107e+05,
      "time_unit": "ns",
      "items_per_second": 5.4035368307299475e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.8311552000000000e+07,
      "advised_time": 2.1094399690628052e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.0444073425867530e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.6750000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.8311552000000000e+07,
      "workspace_megabytes": 2.7000000000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3681,
      "real_time": 1.8994503597565339e+05,
      "cpu_time": 1.9661952920443835e+05,
      "time_unit": "ns",
      "items_per_second": 5.4100096626463849e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.8311552000000000e+07,
      "advised_time": 2.0992000401020050e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.0444073425867530e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.6810000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.8311552000000000e+07,
      "workspace_megabytes": 2.7000000000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3678,
      "real_time": 1.9005745681037047e+05,
      "cpu_time": 1.9674969276763467e+05,
      "time_unit": "ns",
      "items_per_second": 5.4068095892985181e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.8311552000000000e+07,
      "advised_time": 2.1196800470352173e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.0444073425867530e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.6780000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.8311552000000000e+07,
      "workspace_megabytes": 2.7000000000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__5614749869252203586<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5356,
      "real_time": 1.3075785480707097e+05,
      "cpu_time": 1.3725713386859832e+05,
      "time_unit": "ns",
      "items_per_second": 3.1435342267313809e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.3209599256515503e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.3560000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5371,
      "real_time": 1.3078669860387359e+05,
      "cpu_time": 1.3725761087355981e+05,
      "time_unit": "ns",
      "items_per_second": 3.1428409493304995e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.3414399325847626e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.3710000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5372,
      "real_time": 1.2978197786595905e+05,
      "cpu_time": 1.3622974292670679e+05,
      "time_unit": "ns",
      "items_per_second": 3.1671715808224985e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.3312000036239624e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.3720000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5368,
      "real_time": 1.3009491166703757e+05,
      "cpu_time": 1.3654607786913449e+05,
      "time_unit": "ns",
      "items_per_second": 3.1595531810806909e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.3107199966907501e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.3680000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5388,
      "real_time": 1.3022914562779602e+05,
      "cpu_time": 1.3667403600650624e+05,
      "time_unit": "ns",
      "items_per_second": 3.1562964651153135e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.3209599256515503e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.3880000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6895,
      "real_time": 1.0151397427676537e+05,
      "cpu_time": 1.0788446004340339e+05,
      "time_unit": "ns",
      "items_per_second": 4.0491153550874194e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 1.1059200018644333e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 6.8950000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6894,
      "real_time": 1.0154225779881868e+05,
      "cpu_time": 1.0792931665206028e+05,
      "time_unit": "ns",
      "items_per_second": 4.0479875168265361e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 1.0035199671983719e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 6.8940000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6902,
      "real_time": 1.0155302995720711e+05,
      "cpu_time": 1.0792241292391790e+05,
      "time_unit": "ns",
      "items_per_second": 4.0475581297102285e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 1.0854399949312210e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 6.9020000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6897,
      "real_time": 1.0148355350771260e+05,
      "cpu_time": 1.0785317326415052e+05,
      "time_unit": "ns",
      "items_per_second": 4.0503291202624419e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 9.9327996373176575e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 6.8970000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6912,
      "real_time": 1.0158515811482444e+05,
      "cpu_time": 1.0793778544565740e+05,
      "time_unit": "ns",
      "items_per_second": 4.0462780156859956e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 1.0137599706649780e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 6.9120000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3279,
      "real_time": 2.1293691129079438e+05,
      "cpu_time": 2.1981981335815019e+05,
      "time_unit": "ns",
      "items_per_second": 1.9303454225400425e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2112640000000000e+06,
      "advised_time": 2.1606400609016418e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.2790000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.2112640000000000e+06,
      "workspace_megabytes": 3.0625000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3283,
      "real_time": 2.1328561551330774e+05,
      "cpu_time": 2.2012633901912521e+05,
      "time_unit": "ns",
      "items_per_second": 1.9271894685009990e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2112640000000000e+06,
      "advised_time": 2.1913599967956543e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.2830000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.2112640000000000e+06,
      "workspace_megabytes": 3.0625000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3283,
      "real_time": 2.1311442587389762e+05,
      "cpu_time": 2.1998705848300070e+05,
      "time_unit": "ns",
      "items_per_second": 1.9287375329684082e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2112640000000000e+06,
      "advised_time": 2.1811200678348541e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.2830000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.2112640000000000e+06,
      "workspace_megabytes": 3.0625000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 320,
      "real_time": 2.1742523204011377e+06,
      "cpu_time": 2.2486680749983275e+06,
      "time_unit": "ns",
      "items_per_second": 1.8904971982468210e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.7960038400000000e+08,
      "advised_time": 2.1893119812011719e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.2000000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.7960038400000000e+08,
      "workspace_megabytes": 5.5275000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 322,
      "real_time": 2.1760602979139881e+06,
      "cpu_time": 2.2501272857143548e+06,
      "time_unit": "ns",
      "items_per_second": 1.8889264805485046e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.7960038400000000e+08,
      "advised_time": 2.1882879734039307e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.2200000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.7960038400000000e+08,
      "workspace_megabytes": 5.5275000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 322,
      "real_time": 2.1758278599008918e+06,
      "cpu_time": 2.2500429534181664e+06,
      "time_unit": "ns",
      "items_per_second": 1.8891282696358286e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.7960038400000000e+08,
      "advised_time": 2.1903359889984131e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.2200000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.7960038400000000e+08,
      "workspace_megabytes": 5.5275000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2563,
      "real_time": 2.7317175114721019e+05,
      "cpu_time": 2.8039409598153341e+05,
      "time_unit": "ns",
      "items_per_second": 1.5047009446393770e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.8410272000000000e+07,
      "advised_time": 2.9900801181793213e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.5630000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.8410272000000000e+07,
      "workspace_megabytes": 2.7094146728515625e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2562,
      "real_time": 2.7304600753538258e+05,
      "cpu_time": 2.8028043989147019e+05,
      "time_unit": "ns",
      "items_per_second": 1.5053938920778225e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.8410272000000000e+07,
      "advised_time": 3.0310401320457458e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.5620000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.8410272000000000e+07,
      "workspace_megabytes": 2.7094146728515625e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2562,
      "real_time": 2.7316200428233016e+05,
      "cpu_time": 2.8041745277124207e+05,
      "time_unit": "ns",
      "items_per_second": 1.5047546348179609e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.8410272000000000e+07,
      "advised_time": 3.0208000540733337e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.5620000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.8410272000000000e+07,
      "workspace_megabytes": 2.7094146728515625e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_8__8483097298064199248<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2428,
      "real_time": 2.8799996427755151e+05,
      "cpu_time": 2.9537983319681691e+05,
      "time_unit": "ns",
      "items_per_second": 3.5680715536814313e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.8774398565292358e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.4280000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2429,
      "real_time": 2.8828232575347129e+05,
      "cpu_time": 2.9565841416206368e+05,
      "time_unit": "ns",
      "items_per_second": 3.5645767645109485e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.8774398565292358e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.4290000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2427,
      "real_time": 2.8825542365210794e+05,
      "cpu_time": 2.9560405768475070e+05,
      "time_unit": "ns",
      "items_per_second": 3.5649094368479382e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.8979200124740601e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.4270000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2429,
      "real_time": 2.8805288440603862e+05,
      "cpu_time": 2.9540045491993445e+05,
      "time_unit": "ns",
      "items_per_second": 3.5674160393113483e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.8774398565292358e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.4290000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2428,
      "real_time": 2.8808227037756646e+05,
      "cpu_time": 2.9542835049509763e+05,
      "time_unit": "ns",
      "items_per_second": 3.5670521433103149e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.8668799996376038e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.4280000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2550,
      "real_time": 2.7461281004042237e+05,
      "cpu_time": 2.8185010117587860e+05,
      "time_unit": "ns",
      "items_per_second": 3.7420121801628229e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 2.7750399708747864e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.5500000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2547,
      "real_time": 2.7448398087698052e+05,
      "cpu_time": 2.8169733608132723e+05,
      "time_unit": "ns",
      "items_per_second": 3.7437684950385376e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 2.7750399708747864e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.5470000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2548,
      "real_time": 2.7447912537153251e+05,
      "cpu_time": 2.8169863422270335e+05,
      "time_unit": "ns",
      "items_per_second": 3.7438347218902118e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 2.7852800488471985e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.5480000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2550,
      "real_time": 2.7468978583712276e+05,
      "cpu_time": 2.8190647411805665e+05,
      "time_unit": "ns",
      "items_per_second": 3.7409635632004089e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 2.7750399708747864e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.5500000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2548,
      "real_time": 2.7438758329345426e+05,
      "cpu_time": 2.8161796860285063e+05,
      "time_unit": "ns",
      "items_per_second": 3.7450837522082379e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 2.9593598842620850e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.5480000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2151,
      "real_time": 3.2613713219092909e+05,
      "cpu_time": 3.3379002649863018e+05,
      "time_unit": "ns",
      "items_per_second": 3.1508355797965802e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.8901376000000000e+07,
      "advised_time": 3.3689600229263306e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.1510000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.8901376000000000e+07,
      "workspace_megabytes": 2.7562500000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2147,
      "real_time": 3.2522178764819825e+05,
      "cpu_time": 3.3288980251531559e+05,
      "time_unit": "ns",
      "items_per_second": 3.1597036823116821e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.8901376000000000e+07,
      "advised_time": 3.2665601372718811e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.1470000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.8901376000000000e+07,
      "workspace_megabytes": 2.7562500000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2145,
      "real_time": 3.2512104879014002e+05,
      "cpu_time": 3.3278000839201460e+05,
      "time_unit": "ns",
      "items_per_second": 3.1606827174801001e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.8901376000000000e+07,
      "advised_time": 3.2972800731658936e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.1450000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.8901376000000000e+07,
      "workspace_megabytes": 2.7562500000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1178,
      "real_time": 5.8759134054280410e+05,
      "cpu_time": 5.9871067657071468e+05,
      "time_unit": "ns",
      "items_per_second": 1.7488421103189188e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.5210905600000000e+08,
      "advised_time": 6.1030399799346924e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.1780000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.5210905600000000e+08,
      "workspace_megabytes": 1.4506250000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1194,
      "real_time": 5.8748900085583120e+05,
      "cpu_time": 5.9845031407087599e+05,
      "time_unit": "ns",
      "items_per_second": 1.7491467559444104e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.5210905600000000e+08,
      "advised_time": 5.9903997182846069e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.1940000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.5210905600000000e+08,
      "workspace_megabytes": 1.4506250000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1195,
      "real_time": 5.8628420864726766e+05,
      "cpu_time": 5.9723336819997209e+05,
      "time_unit": "ns",
      "items_per_second": 1.7527411873688184e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.5210905600000000e+08,
      "advised_time": 6.0416001081466675e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.1950000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.5210905600000000e+08,
      "workspace_megabytes": 1.4506250000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1894,
      "real_time": 3.7032213223578822e+05,
      "cpu_time": 3.7832176293538086e+05,
      "time_unit": "ns",
      "items_per_second": 2.7748935063533081e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.0240640000000000e+07,
      "advised_time": 3.9731198549270630e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.8940000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 8.0240640000000000e+07,
      "workspace_megabytes": 7.6523437500000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1893,
      "real_time": 3.6973053926717135e+05,
      "cpu_time": 3.7774844743847748e+05,
      "time_unit": "ns",
      "items_per_second": 2.7793335168817145e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.0240640000000000e+07,
      "advised_time": 3.9628800749778748e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.8930000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 8.0240640000000000e+07,
      "workspace_megabytes": 7.6523437500000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1889,
      "real_time": 3.7058466602505819e+05,
      "cpu_time": 3.7863871519320540e+05,
      "time_unit": "ns",
      "items_per_second": 2.7729276848452100e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.0240640000000000e+07,
      "advised_time": 3.9731198549270630e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.8890000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 8.0240640000000000e+07,
      "workspace_megabytes": 7.6523437500000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4801,
      "real_time": 1.4558120539957099e+05,
      "cpu_time": 1.5204625536370371e+05,
      "time_unit": "ns",
      "items_per_second": 7.0586342322113257e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6389120000000000e+06,
      "advised_time": 1.6281600296497345e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.1941256922983490e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 4.8010000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6389120000000000e+06,
      "workspace_megabytes": 1.5629882812500000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4799,
      "real_time": 1.4584802605602681e+05,
      "cpu_time": 1.5234254490477929e+05,
      "time_unit": "ns",
      "items_per_second": 7.0457208629292712e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6389120000000000e+06,
      "advised_time": 1.6896000504493713e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.1941256922983490e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 4.7990000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6389120000000000e+06,
      "workspace_megabytes": 1.5629882812500000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4796,
      "real_time": 1.4562502237625406e+05,
      "cpu_time": 1.5210366722254382e+05,
      "time_unit": "ns",
      "items_per_second": 7.0565103663638196e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6389120000000000e+06,
      "advised_time": 1.6383999586105347e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.1941256922983490e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 4.7960000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6389120000000000e+06,
      "workspace_megabytes": 1.5629882812500000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3688,
      "real_time": 1.8852368586143269e+05,
      "cpu_time": 1.9523366567310377e+05,
      "time_unit": "ns",
      "items_per_second": 5.4507977355975439e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.1260672000000000e+07,
      "advised_time": 2.0582400262355804e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.0444073425867530e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.6880000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.1260672000000000e+07,
      "workspace_megabytes": 2.9812500000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3681,
      "real_time": 1.8886496339940702e+05,
      "cpu_time": 1.9536527709885983e+05,
      "time_unit": "ns",
      "items_per_second": 5.4409481859631488e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.1260672000000000e+07,
      "advised_time": 2.1503999829292297e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.0444073425867530e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.6810000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.1260672000000000e+07,
      "workspace_megabytes": 2.9812500000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3690,
      "real_time": 1.8993365757156615e+05,
      "cpu_time": 1.9661582791383847e+05,
      "time_unit": "ns",
      "items_per_second": 5.4103337614756531e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.1260672000000000e+07,
      "advised_time": 2.0889599621295929e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.0444073425867530e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.6900000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.1260672000000000e+07,
      "workspace_megabytes": 2.9812500000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__9297510983925491624<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2657,
      "real_time": 2.6380167243745294e+05,
      "cpu_time": 2.7099258938463510e+05,
      "time_unit": "ns",
      "items_per_second": 3.8953675710439014e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.6726400852203369e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.6570000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2655,
      "real_time": 2.6373511315989896e+05,
      "cpu_time": 2.7089555028067005e+05,
      "time_unit": "ns",
      "items_per_second": 3.8963506515606726e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.6316800713539124e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.6550000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2652,
      "real_time": 2.6438698621374043e+05,
      "cpu_time": 2.7155933823471115e+05,
      "time_unit": "ns",
      "items_per_second": 3.8867438020162067e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.6316800713539124e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.6520000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2661,
      "real_time": 2.6420616130351566e+05,
      "cpu_time": 2.7137781661014247e+05,
      "time_unit": "ns",
      "items_per_second": 3.8894039220361133e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.6624000072479248e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.6610000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2646,
      "real_time": 2.6457241506645567e+05,
      "cpu_time": 2.7174447656631470e+05,
      "time_unit": "ns",
      "items_per_second": 3.8840197295015991e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.5289601087570190e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.6460000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3306,
      "real_time": 2.1147978038726942e+05,
      "cpu_time": 2.1829653599317890e+05,
      "time_unit": "ns",
      "items_per_second": 4.8591145598799731e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 2.1503999829292297e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.3060000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3307,
      "real_time": 2.1149675554687696e+05,
      "cpu_time": 2.1828605866402693e+05,
      "time_unit": "ns",
      "items_per_second": 4.8587245574660260e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 2.1708799898624420e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.3070000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3306,
      "real_time": 2.1149512223908660e+05,
      "cpu_time": 2.1828943587416442e+05,
      "time_unit": "ns",
      "items_per_second": 4.8587620798097418e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 2.1503999829292297e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.3060000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3305,
      "real_time": 2.1146052962492406e+05,
      "cpu_time": 2.1827580060544168e+05,
      "time_unit": "ns",
      "items_per_second": 4.8595569197840503e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 2.1708799898624420e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.3050000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3308,
      "real_time": 2.1150751950631302e+05,
      "cpu_time": 2.1832527962458797e+05,
      "time_unit": "ns",
      "items_per_second": 4.8584772891222351e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 2.1507200598716736e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.3080000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1656,
      "real_time": 4.2342075188140885e+05,
      "cpu_time": 4.3213725301880628e+05,
      "time_unit": "ns",
      "items_per_second": 2.4269109991279077e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.7802752000000000e+07,
      "advised_time": 4.2393600940704346e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.6560000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.7802752000000000e+07,
      "workspace_megabytes": 5.5125000000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1668,
      "real_time": 4.2345291053138149e+05,
      "cpu_time": 4.3108243944892514e+05,
      "time_unit": "ns",
      "items_per_second": 2.4267266901306274e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.7802752000000000e+07,
      "advised_time": 4.3212801218032837e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.6680000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.7802752000000000e+07,
      "workspace_megabytes": 5.5125000000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1658,
      "real_time": 4.2038280241973855e+05,
      "cpu_time": 4.2902398190715187e+05,
      "time_unit": "ns",
      "items_per_second": 2.4444493782454266e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.7802752000000000e+07,
      "advised_time": 4.2393600940704346e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.6580000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.7802752000000000e+07,
      "workspace_megabytes": 5.5125000000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1986,
      "real_time": 3.5141890929565905e+05,
      "cpu_time": 3.5932977643508429e+05,
      "time_unit": "ns",
      "items_per_second": 2.9241581850549945e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.5586099200000000e+08,
      "advised_time": 3.9116799831390381e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.9860000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.5586099200000000e+08,
      "workspace_megabytes": 1.4864062500000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2000,
      "real_time": 3.4846100694267085e+05,
      "cpu_time": 3.5634808499952441e+05,
      "time_unit": "ns",
      "items_per_second": 2.9489798270859692e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.5586099200000000e+08,
      "advised_time": 3.7887999415397644e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.0000000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.5586099200000000e+08,
      "workspace_megabytes": 1.4864062500000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2007,
      "real_time": 3.4809029038091097e+05,
      "cpu_time": 3.5600542999545956e+05,
      "time_unit": "ns",
      "items_per_second": 2.9521204940117834e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.5586099200000000e+08,
      "advised_time": 3.9321601390838623e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.0070000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.5586099200000000e+08,
      "workspace_megabytes": 1.4864062500000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2145,
      "real_time": 3.2587761934824928e+05,
      "cpu_time": 3.3336754731942539e+05,
      "time_unit": "ns",
      "items_per_second": 3.1533447496492535e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.6787840000000000e+07,
      "advised_time": 3.6454400420188904e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.1450000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.6787840000000000e+07,
      "workspace_megabytes": 2.5546875000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2148,
      "real_time": 3.2632354734124255e+05,
      "cpu_time": 3.3375614012931252e+05,
      "time_unit": "ns",
      "items_per_second": 3.1490356377053448e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.6787840000000000e+07,
      "advised_time": 3.6966401338577271e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.1480000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.6787840000000000e+07,
      "workspace_megabytes": 2.5546875000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2141,
      "real_time": 3.2568742255325743e+05,
      "cpu_time": 3.3320077487135923e+05,
      "time_unit": "ns",
      "items_per_second": 3.1551862578665063e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.6787840000000000e+07,
      "advised_time": 3.6351999640464783e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.1410000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.6787840000000000e+07,
      "workspace_megabytes": 2.5546875000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5764,
      "real_time": 1.2110800444569427e+05,
      "cpu_time": 1.2749624704938463e+05,
      "time_unit": "ns",
      "items_per_second": 8.4850252855151746e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.0985600000000000e+05,
      "advised_time": 1.4847999811172485e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.1941256922983490e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.7640000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.0985600000000000e+05,
      "workspace_megabytes": 3.9086914062500000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5762,
      "real_time": 1.2132888956025180e+05,
      "cpu_time": 1.2772315619652317e+05,
      "time_unit": "ns",
      "items_per_second": 8.4695778863919519e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.0985600000000000e+05,
      "advised_time": 1.4233599603176117e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.1941256922983490e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.7620000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.0985600000000000e+05,
      "workspace_megabytes": 3.9086914062500000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5760,
      "real_time": 1.2114035157790367e+05,
      "cpu_time": 1.2755187829905801e+05,
      "time_unit": "ns",
      "items_per_second": 8.4827595975661511e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.0985600000000000e+05,
      "advised_time": 1.6486400365829468e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.1941256922983490e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.7600000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.0985600000000000e+05,
      "workspace_megabytes": 3.9086914062500000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2718,
      "real_time": 2.5766623576113101e+05,
      "cpu_time": 2.6271515011003258e+05,
      "time_unit": "ns",
      "items_per_second": 3.9881223745304321e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.8392576000000000e+07,
      "advised_time": 2.8774398565292358e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.0444073425867530e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.7180000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.8392576000000000e+07,
      "workspace_megabytes": 5.5687500000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2716,
      "real_time": 2.5719790149588807e+05,
      "cpu_time": 2.6428558947134187e+05,
      "time_unit": "ns",
      "items_per_second": 3.9953843869773132e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.8392576000000000e+07,
      "advised_time": 2.8979200124740601e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.0444073425867530e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.7160000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.8392576000000000e+07,
      "workspace_megabytes": 5.5687500000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2717,
      "real_time": 2.5703318499210011e+05,
      "cpu_time": 2.6418026168488309e+05,
      "time_unit": "ns",
      "items_per_second": 3.9979447791209656e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.8392576000000000e+07,
      "advised_time": 2.8979200124740601e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.0444073425867530e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.7170000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.8392576000000000e+07,
      "workspace_megabytes": 5.5687500000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__12906987293610259640<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4828,
      "real_time": 1.4501715499062635e+05,
      "cpu_time": 1.5151971934619008e+05,
      "time_unit": "ns",
      "items_per_second": 2.8344356364360410e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.4745600521564484e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.8280000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4825,
      "real_time": 1.4487908289941520e+05,
      "cpu_time": 1.5141081098553105e+05,
      "time_unit": "ns",
      "items_per_second": 2.8371368990882754e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.4540800452232361e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.8250000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4827,
      "real_time": 1.4496149340843593e+05,
      "cpu_time": 1.5145334679906900e+05,
      "time_unit": "ns",
      "items_per_second": 2.8355239887179565e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.4643199741840363e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.8270000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4820,
      "real_time": 1.4483645616685660e+05,
      "cpu_time": 1.5131783568437671e+05,
      "time_unit": "ns",
      "items_per_second": 2.8379718951868418e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.4748799800872803e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.8200000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4827,
      "real_time": 1.4499245254326842e+05,
      "cpu_time": 1.5149263559155309e+05,
      "time_unit": "ns",
      "items_per_second": 2.8349185408622393e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.4540800452232361e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.8270000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4880,
      "real_time": 1.4267514471597321e+05,
      "cpu_time": 1.4914407008291630e+05,
      "time_unit": "ns",
      "items_per_second": 2.8809628531884136e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 1.4643199741840363e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.8800000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4878,
      "real_time": 1.4286942888617265e+05,
      "cpu_time": 1.4935919126743171e+05,
      "time_unit": "ns",
      "items_per_second": 2.8770451117816567e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 1.5151999890804291e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.8780000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4871,
      "real_time": 1.4310035113102521e+05,
      "cpu_time": 1.4958419113039965e+05,
      "time_unit": "ns",
      "items_per_second": 2.8724023997931558e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 1.4540800452232361e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.8710000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4881,
      "real_time": 1.4292202788780339e+05,
      "cpu_time": 1.4940261811061238e+05,
      "time_unit": "ns",
      "items_per_second": 2.8759862847921240e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 1.4543999731540680e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.8810000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4876,
      "real_time": 1.4259259447682602e+05,
      "cpu_time": 1.4911182383086253e+05,
      "time_unit": "ns",
      "items_per_second": 2.8826307109995254e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 1.4643199741840363e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.8760000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2480,
      "real_time": 2.8356360846608423e+05,
      "cpu_time": 2.9092239032318123e+05,
      "time_unit": "ns",
      "items_per_second": 1.4495576291453591e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 2.8569599986076355e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.4800000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2472,
      "real_time": 2.8220773074104567e+05,
      "cpu_time": 2.8955174029196356e+05,
      "time_unit": "ns",
      "items_per_second": 1.4565220836461516e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 2.8467199206352234e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.4720000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2479,
      "real_time": 2.8371937868713931e+05,
      "cpu_time": 2.9105850181629159e+05,
      "time_unit": "ns",
      "items_per_second": 1.4487617796923933e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 2.8467199206352234e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.4790000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 313,
      "real_time": 2.2491426608813838e+06,
      "cpu_time": 2.3275299233243396e+06,
      "time_unit": "ns",
      "items_per_second": 1.8275487773591153e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.2390272000000000e+08,
      "advised_time": 2.2323200702667236e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.1300000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.2390272000000000e+08,
      "workspace_megabytes": 5.9500000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 311,
      "real_time": 2.2387310077954335e+06,
      "cpu_time": 2.3171910932460874e+06,
      "time_unit": "ns",
      "items_per_second": 1.8360481476725916e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.2390272000000000e+08,
      "advised_time": 2.2322878837585449e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.1100000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.2390272000000000e+08,
      "workspace_megabytes": 5.9500000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 311,
      "real_time": 2.2386677272713645e+06,
      "cpu_time": 2.3172215627014823e+06,
      "time_unit": "ns",
      "items_per_second": 1.8361000473304041e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.2390272000000000e+08,
      "advised_time": 2.2302720546722412e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.1100000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.2390272000000000e+08,
      "workspace_megabytes": 5.9500000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1123,
      "real_time": 6.1783926838881208e+05,
      "cpu_time": 6.2943052626857138e+05,
      "time_unit": "ns",
      "items_per_second": 6.6528919903700183e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.5148960000000000e+07,
      "advised_time": 6.5945601463317871e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.1230000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.5148960000000000e+07,
      "workspace_megabytes": 5.2594146728515625e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1132,
      "real_time": 6.1751015531845298e+05,
      "cpu_time": 6.2900135423974833e+05,
      "time_unit": "ns",
      "items_per_second": 6.6564377680238110e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.5148960000000000e+07,
      "advised_time": 6.6150397062301636e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.1320000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.5148960000000000e+07,
      "workspace_megabytes": 5.2594146728515625e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1131,
      "real_time": 6.1789653945391439e+05,
      "cpu_time": 6.2943223430508899e+05,
      "time_unit": "ns",
      "items_per_second": 6.6522753528166895e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.5148960000000000e+07,
      "advised_time": 6.6150397062301636e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.1310000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.5148960000000000e+07,
      "workspace_megabytes": 5.2594146728515625e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__14888803610485870835<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3286,
      "real_time": 2.1373049696822092e+05,
      "cpu_time": 2.2057553377996269e+05,
      "time_unit": "ns",
      "items_per_second": 1.9231780107689397e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.1503999829292297e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.2860000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3291,
      "real_time": 2.1372464947024401e+05,
      "cpu_time": 2.2056125767308721e+05,
      "time_unit": "ns",
      "items_per_second": 1.9232306288434346e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.1401600539684296e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.2910000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3276,
      "real_time": 2.1370908341248849e+05,
      "cpu_time": 2.2055385775312249e+05,
      "time_unit": "ns",
      "items_per_second": 1.9233707123558794e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.1503999829292297e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.2760000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3286,
      "real_time": 2.1364359251420200e+05,
      "cpu_time": 2.2046406543044452e+05,
      "time_unit": "ns",
      "items_per_second": 1.9239603077385808e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.1503999829292297e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.2860000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 3289,
      "real_time": 2.1352676088257990e+05,
      "cpu_time": 2.1960385527603174e+05,
      "time_unit": "ns",
      "items_per_second": 1.9250130068054336e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.1401600539684296e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.2890000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2619,
      "real_time": 2.6432963589065161e+05,
      "cpu_time": 2.7149906147531921e+05,
      "time_unit": "ns",
      "items_per_second": 1.5550348360107473e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 2.6726400852203369e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.6190000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2598,
      "real_time": 2.6437847707829252e+05,
      "cpu_time": 2.7154365781337791e+05,
      "time_unit": "ns",
      "items_per_second": 1.5547475594175349e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 2.6624000072479248e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.5980000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2582,
      "real_time": 2.6422040353269089e+05,
      "cpu_time": 2.7142657978391589e+05,
      "time_unit": "ns",
      "items_per_second": 1.5556777088531829e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 2.8467199206352234e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.5820000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2597,
      "real_time": 2.6428441115944408e+05,
      "cpu_time": 2.7147758683168131e+05,
      "time_unit": "ns",
      "items_per_second": 1.5553009358240828e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 2.6723200082778931e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.5970000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2602,
      "real_time": 2.6423241016317194e+05,
      "cpu_time": 2.7141704458018084e+05,
      "time_unit": "ns",
      "items_per_second": 1.5556070193893647e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 2.6726400852203369e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.6020000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2073,
      "real_time": 3.2672056131621083e+05,
      "cpu_time": 3.3454931162506295e+05,
      "time_unit": "ns",
      "items_per_second": 1.2580836368060117e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2112640000000000e+06,
      "advised_time": 3.2870399951934814e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.0730000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.2112640000000000e+06,
      "workspace_megabytes": 3.0625000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2127,
      "real_time": 3.2665371869331237e+05,
      "cpu_time": 3.3444931734869332e+05,
      "time_unit": "ns",
      "items_per_second": 1.2583410764287600e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2112640000000000e+06,
      "advised_time": 3.3075198531150818e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.1270000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.2112640000000000e+06,
      "workspace_megabytes": 3.0625000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2104,
      "real_time": 3.2655574636314303e+05,
      "cpu_time": 3.3433131226385006e+05,
      "time_unit": "ns",
      "items_per_second": 1.2587186003547004e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2112640000000000e+06,
      "advised_time": 3.2665601372718811e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.1040000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.2112640000000000e+06,
      "workspace_megabytes": 3.0625000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 123,
      "real_time": 5.3423843800839856e+06,
      "cpu_time": 5.7215537886237158e+06,
      "time_unit": "ns",
      "items_per_second": 7.6939763737767258e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4578621440000000e+09,
      "advised_time": 5.2111358642578125e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.2300000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.4578621440000000e+09,
      "workspace_megabytes": 2.3440000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 122,
      "real_time": 5.3332870917730648e+06,
      "cpu_time": 5.7066670491823349e+06,
      "time_unit": "ns",
      "items_per_second": 7.7071004228153809e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4578621440000000e+09,
      "advised_time": 5.1742720603942871e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.2200000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.4578621440000000e+09,
      "workspace_megabytes": 2.3440000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 122,
      "real_time": 5.3011816430104068e+06,
      "cpu_time": 5.6389068688484961e+06,
      "time_unit": "ns",
      "items_per_second": 7.7537767931788834e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4578621440000000e+09,
      "advised_time": 5.0964159965515137e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.2200000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.4578621440000000e+09,
      "workspace_megabytes": 2.3440000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 506,
      "real_time": 1.3585196487723368e+06,
      "cpu_time": 1.3912747134395072e+06,
      "time_unit": "ns",
      "items_per_second": 3.0256595285276080e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6210371200000000e+08,
      "advised_time": 1.4233599901199341e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.0600000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6210371200000000e+08,
      "workspace_megabytes": 1.5459414672851562e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 505,
      "real_time": 1.3608066544932600e+06,
      "cpu_time": 1.3937292099016495e+06,
      "time_unit": "ns",
      "items_per_second": 3.0205745293997302e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6210371200000000e+08,
      "advised_time": 1.4254080057144165e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.0500000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6210371200000000e+08,
      "workspace_megabytes": 1.5459414672851562e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 507,
      "real_time": 1.3586958859729371e+06,
      "cpu_time": 1.3916255621329071e+06,
      "time_unit": "ns",
      "items_per_second": 3.0252670685438965e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6210371200000000e+08,
      "advised_time": 1.4274560213088989e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.0700000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6210371200000000e+08,
      "workspace_megabytes": 1.5459414672851562e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__13991416866017321170<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 7649,
      "real_time": 9.0964346684509743e+04,
      "cpu_time": 9.7292064974559835e+04,
      "time_unit": "ns",
      "items_per_second": 9.0374263539892168e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.2160001397132874e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 7.6490000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 7693,
      "real_time": 9.0803897548186666e+04,
      "cpu_time": 9.7116462887981979e+04,
      "time_unit": "ns",
      "items_per_second": 9.0533953519313105e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.3184001743793488e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 7.6930000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 7710,
      "real_time": 9.0968112072500619e+04,
      "cpu_time": 9.7317165370724921e+04,
      "time_unit": "ns",
      "items_per_second": 9.0370522732714102e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.2160001397132874e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 7.7100000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 7716,
      "real_time": 9.0259332233814668e+04,
      "cpu_time": 9.6572174572745760e+04,
      "time_unit": "ns",
      "items_per_second": 9.1080175717499414e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.6256002783775330e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 7.7160000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 7662,
      "real_time": 9.0960795589913774e+04,
      "cpu_time": 9.7274974158608762e+04,
      "time_unit": "ns",
      "items_per_second": 9.0377791736372754e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.3184001743793488e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 7.6620000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 9018,
      "real_time": 7.7587658410599775e+04,
      "cpu_time": 8.3878444998582709e+04,
      "time_unit": "ns",
      "items_per_second": 1.0595545745812707e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 8.0895997583866119e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 9.0180000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 9015,
      "real_time": 7.7377218207083817e+04,
      "cpu_time": 8.3684083859306425e+04,
      "time_unit": "ns",
      "items_per_second": 1.0624362093243861e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 7.9871997237205505e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 9.0150000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 9017,
      "real_time": 7.7332183213713579e+04,
      "cpu_time": 8.3631899967214224e+04,
      "time_unit": "ns",
      "items_per_second": 1.0630549272456299e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 8.1919997930526733e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 9.0170000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 9017,
      "real_time": 7.7708410087432349e+04,
      "cpu_time": 8.3979387379514490e+04,
      "time_unit": "ns",
      "items_per_second": 1.0579081248413732e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 7.9871997237205505e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 9.0170000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 8985,
      "real_time": 7.7316815981947977e+04,
      "cpu_time": 8.3643446855155620e+04,
      "time_unit": "ns",
      "items_per_second": 1.0632662164876799e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 7.9871997237205505e-02,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 8.9850000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2909,
      "real_time": 2.3984178615503153e+05,
      "cpu_time": 2.4559846132635578e+05,
      "time_unit": "ns",
      "items_per_second": 3.4276078292237734e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 2.4063999950885773e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.9090000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2915,
      "real_time": 2.3995769622206120e+05,
      "cpu_time": 2.4654771217836329e+05,
      "time_unit": "ns",
      "items_per_second": 3.4259521446614863e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 2.4063999950885773e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.9150000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2923,
      "real_time": 2.4045417877157091e+05,
      "cpu_time": 2.4566955969910169e+05,
      "time_unit": "ns",
      "items_per_second": 3.4188783418106919e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4225280000000000e+06,
      "advised_time": 2.4063999950885773e-01,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.9230000000000000e+03,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 6.4225280000000000e+06,
      "workspace_megabytes": 6.1250000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 405,
      "real_time": 1.7360794044640146e+06,
      "cpu_time": 1.7843990740733894e+06,
      "time_unit": "ns",
      "items_per_second": 4.7352879245393994e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6939417600000000e+08,
      "advised_time": 1.7367039918899536e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 4.0500000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.6939417600000000e+08,
      "workspace_megabytes": 1.6154687500000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 405,
      "real_time": 1.7361961046440734e+06,
      "cpu_time": 1.7843453357991278e+06,
      "time_unit": "ns",
      "items_per_second": 4.7349696373643817e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6939417600000000e+08,
      "advised_time": 1.7520639896392822e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 4.0500000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.6939417600000000e+08,
      "workspace_megabytes": 1.6154687500000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 405,
      "real_time": 1.7362020280281149e+06,
      "cpu_time": 1.7840288617255709e+06,
      "time_unit": "ns",
      "items_per_second": 4.7349534831132428e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6939417600000000e+08,
      "advised_time": 1.7489919662475586e+00,
      "batch_size": 8.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 3.7241290715759565e+17,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 8.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 4.0500000000000000e+02,
      "output_batch_size": 8.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.6939417600000000e+08,
      "workspace_megabytes": 1.6154687500000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_8__10959339369183260448<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:8/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:8/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    }
  ]
}
