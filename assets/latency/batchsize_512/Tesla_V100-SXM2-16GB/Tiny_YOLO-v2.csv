LayerName,LayerType,BenchmarkName,RealTime(ms),Theoretical Flops
batchnorm,BatchNorm,BATCHNORM_FWD_INFERENCE10192737418752381644<CUDNN_BAT...,15.525364,2835349504
activation,Relu,ACTIVATION_FWD15902962014910814925<CUDNN_ACTIVATION_R...,18.269615,4253024256
batchnorm1,BatchNorm,BATCHNORM_FWD_INFERENCE4038308242110099184<CUDNN_BATC...,7.721578,1417674752
activation1,Relu,ACTIVATION_FWD7623390132675700465<CUDNN_ACTIVATION_RE...,8.766937,2126512128
convolution2,Conv,CONV_FWD_010003276336779241172<CUDNN_CONVOLUTION_FWD_...,15.124146,204145164288
batchnorm2,BatchNorm,BATCHNORM_FWD_INFERENCE12675215585998569480<CUDNN_BAT...,3.717615,708837376
activation2,Relu,ACTIVATION_FWD18313362831194179593<CUDNN_ACTIVATION_R...,4.187460,1063256064
batchnorm3,BatchNorm,BATCHNORM_FWD_INFERENCE2385690281876086487<CUDNN_BATC...,1.789876,354418688
activation3,Relu,ACTIVATION_FWD8132066853582804694<CUDNN_ACTIVATION_RE...,1.993326,531628032
convolution4,Conv,CONV_FWD_0717961830668622622<CUDNN_CONVOLUTION_FWD_AL...,5.532622,204145164288
batchnorm4,BatchNorm,BATCHNORM_FWD_INFERENCE13061523624665044097<CUDNN_BAT...,0.953131,177209344
activation4,Relu,ACTIVATION_FWD17781638411039652601<CUDNN_ACTIVATION_R...,0.975613,265814016
convolution5,Conv,CONV_FWD_010059280453333533468<CUDNN_CONVOLUTION_FWD_...,4.416325,204145164288
batchnorm5,BatchNorm,BATCHNORM_FWD_INFERENCE598518193442707970<CUDNN_BATCH...,0.519609,88604672
activation5,Relu,ACTIVATION_FWD6453401238353056259<CUDNN_ACTIVATION_RE...,0.485069,132907008
batchnorm6,BatchNorm,BATCHNORM_FWD_INFERENCE13012487771625153780<CUDNN_BAT...,0.867414,150994944
activation6,Relu,ACTIVATION_FWD16525096485966032117<CUDNN_ACTIVATION_R...,0.823762,226492416
batchnorm7,BatchNorm,BATCHNORM_FWD_INFERENCE13012487771625153780<CUDNN_BAT...,0.867414,150994944
activation7,Relu,ACTIVATION_FWD16525096485966032117<CUDNN_ACTIVATION_R...,0.823762,226492416
,,Total,95.036323,646020071424
