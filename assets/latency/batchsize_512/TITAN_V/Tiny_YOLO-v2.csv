LayerName,LayerType,BenchmarkName,RealTime(ms),Theoretical Flops
batchnorm,BatchNorm,BATCHNORM_FWD_INFERENCE10192737418752381644<CUDNN_BAT...,20.593121,2835349504
activation,Relu,ACTIVATION_FWD15902962014910814925<CUDNN_ACTIVATION_R...,22.842896,4253024256
convolution1,Conv,CONV_FWD_114890007717820903930<CUDNN_CONVOLUTION_FWD_...,26.287710,204145164288
batchnorm1,BatchNorm,BATCHNORM_FWD_INFERENCE4038308242110099184<CUDNN_BATC...,10.078888,1417674752
activation1,Relu,ACTIVATION_FWD7623390132675700465<CUDNN_ACTIVATION_RE...,11.142957,2126512128
convolution2,Conv,CONV_FWD_010003276336779241172<CUDNN_CONVOLUTION_FWD_...,14.280578,204145164288
batchnorm2,BatchNorm,BATCHNORM_FWD_INFERENCE12675215585998569480<CUDNN_BAT...,4.905332,708837376
activation2,Relu,ACTIVATION_FWD18313362831194179593<CUDNN_ACTIVATION_R...,5.405902,1063256064
batchnorm3,BatchNorm,BATCHNORM_FWD_INFERENCE2385690281876086487<CUDNN_BATC...,2.398103,354418688
activation3,Relu,ACTIVATION_FWD8132066853582804694<CUDNN_ACTIVATION_RE...,2.610565,531628032
batchnorm4,BatchNorm,BATCHNORM_FWD_INFERENCE13061523624665044097<CUDNN_BAT...,1.206060,177209344
activation4,Relu,ACTIVATION_FWD17781638411039652601<CUDNN_ACTIVATION_R...,1.268735,265814016
batchnorm5,BatchNorm,BATCHNORM_FWD_INFERENCE598518193442707970<CUDNN_BATCH...,0.601925,88604672
activation5,Relu,ACTIVATION_FWD6453401238353056259<CUDNN_ACTIVATION_RE...,0.628946,132907008
convolution6,Conv,CONV_FWD_1843968789910403817<CUDNN_CONVOLUTION_FWD_AL...,17.179049,695784701952
batchnorm6,BatchNorm,BATCHNORM_FWD_INFERENCE13012487771625153780<CUDNN_BAT...,1.013743,150994944
activation6,Relu,ACTIVATION_FWD16525096485966032117<CUDNN_ACTIVATION_R...,1.076845,226492416
batchnorm7,BatchNorm,BATCHNORM_FWD_INFERENCE13012487771625153780<CUDNN_BAT...,1.013743,150994944
activation7,Relu,ACTIVATION_FWD16525096485966032117<CUDNN_ACTIVATION_R...,1.076845,226492416
,,Total,144.535098,1118785241088
