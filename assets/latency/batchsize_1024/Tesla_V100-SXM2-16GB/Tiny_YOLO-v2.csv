LayerName,LayerType,BenchmarkName,RealTime(ms),Theoretical Flops
batchnorm1,BatchNorm,BATCHNORM_FWD_INFERENCE12750882933557314581<CUDNN_BAT...,15.391106,2835349504
activation1,Relu,ACTIVATION_FWD6457311766921523624<CUDNN_ACTIVATION_RE...,18.292008,4253024256
convolution2,Conv,CONV_FWD_118366711844164108936<CUDNN_CONVOLUTION_FWD_...,30.169844,408290328576
batchnorm2,BatchNorm,BATCHNORM_FWD_INFERENCE8830988389231517649<CUDNN_BATC...,7.432366,1417674752
activation2,Relu,ACTIVATION_FWD10656993949404015212<CUDNN_ACTIVATION_R...,8.752076,2126512128
convolution3,Conv,CONV_FWD_15158358673546407767<CUDNN_CONVOLUTION_FWD_A...,22.356397,408290328576
batchnorm3,BatchNorm,BATCHNORM_FWD_INFERENCE1111603692329127546<CUDNN_BATC...,3.574731,708837376
activation3,Relu,ACTIVATION_FWD16574921207619697607<CUDNN_ACTIVATION_R...,4.208615,1063256064
batchnorm4,BatchNorm,BATCHNORM_FWD_INFERENCE16121768953429194684<CUDNN_BAT...,1.903509,354418688
activation4,Relu,ACTIVATION_FWD17280675299550628892<CUDNN_ACTIVATION_R...,1.990167,531628032
batchnorm5,BatchNorm,BATCHNORM_FWD_INFERENCE8544233319322008275<CUDNN_BATC...,1.031991,177209344
activation5,Relu,ACTIVATION_FWD11528071833688887150<CUDNN_ACTIVATION_R...,0.971910,265814016
batchnorm6,BatchNorm,BATCHNORM_FWD_INFERENCE14155761943380867445<CUDNN_BAT...,1.728420,301989888
activation6,Relu,ACTIVATION_FWD3250359587349286088<CUDNN_ACTIVATION_RE...,1.670729,452984832
convolution7,Conv,CONV_FWD_111244315917026898566<CUDNN_CONVOLUTION_FWD_...,58.216533,2783138807808
batchnorm7,BatchNorm,BATCHNORM_FWD_INFERENCE14155761943380867445<CUDNN_BAT...,1.728420,301989888
activation7,Relu,ACTIVATION_FWD3250359587349286088<CUDNN_ACTIVATION_RE...,1.670729,452984832
,,Total,181.089551,3614963138560
