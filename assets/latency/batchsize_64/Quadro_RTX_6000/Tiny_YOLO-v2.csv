LayerName,LayerType,BenchmarkName,RealTime(ms),Theoretical Flops
batchnorm,BatchNorm,BATCHNORM_FWD_INFERENCE16658017616467584502<CUDNN_BAT...,2.978081,354418688
activation,Relu,ACTIVATION_FWD17315341123322895563<CUDNN_ACTIVATION_R...,3.825393,531628032
batchnorm1,BatchNorm,BATCHNORM_FWD_INFERENCE5144071037578962086<CUDNN_BATC...,1.396948,177209344
activation1,Relu,ACTIVATION_FWD5765223918917180827<CUDNN_ACTIVATION_RE...,1.820834,265814016
batchnorm2,BatchNorm,BATCHNORM_FWD_INFERENCE4593220302806436934<CUDNN_BATC...,0.648988,88604672
activation2,Relu,ACTIVATION_FWD2945138956897088891<CUDNN_ACTIVATION_RE...,0.848166,132907008
batchnorm3,BatchNorm,BATCHNORM_FWD_INFERENCE6109524177744274813<CUDNN_BATC...,0.320294,44302336
activation3,Relu,ACTIVATION_FWD4875210504919555136<CUDNN_ACTIVATION_RE...,0.384336,66453504
batchnorm4,BatchNorm,BATCHNORM_FWD_INFERENCE8427814650144125407<CUDNN_BATC...,0.162206,22151168
activation4,Relu,ACTIVATION_FWD9886387398182271691<CUDNN_ACTIVATION_RE...,0.170919,33226752
batchnorm5,BatchNorm,BATCHNORM_FWD_INFERENCE12370610703289465304<CUDNN_BAT...,0.084099,11075584
activation5,Relu,ACTIVATION_FWD13604359784099119333<CUDNN_ACTIVATION_R...,0.086732,16613376
convolution6,Conv,CONV_FWD_010017072541919575219<CUDNN_CONVOLUTION_FWD_...,2.443161,86973087744
batchnorm6,BatchNorm,BATCHNORM_FWD_INFERENCE16948399973379536954<CUDNN_BAT...,0.141644,18874368
activation6,Relu,ACTIVATION_FWD18182604254003773703<CUDNN_ACTIVATION_R...,0.145514,28311552
batchnorm7,BatchNorm,BATCHNORM_FWD_INFERENCE16948399973379536954<CUDNN_BAT...,0.141644,18874368
activation7,Relu,ACTIVATION_FWD18182604254003773703<CUDNN_ACTIVATION_R...,0.145514,28311552
,,Total,15.598958,88811864064
