LayerName,LayerType,BenchmarkName,RealTime(ms),Theoretical Flops
batchnorm,BatchNorm,BATCHNORM_FWD_INFERENCE16658017616467584502<CUDNN_BAT...,2.658779,354418688
activation,Relu,ACTIVATION_FWD17315341123322895563<CUDNN_ACTIVATION_R...,2.608223,531628032
batchnorm1,BatchNorm,BATCHNORM_FWD_INFERENCE5144071037578962086<CUDNN_BATC...,1.264673,177209344
activation1,Relu,ACTIVATION_FWD5765223918917180827<CUDNN_ACTIVATION_RE...,1.268849,265814016
batchnorm2,BatchNorm,BATCHNORM_FWD_INFERENCE4593220302806436934<CUDNN_BATC...,0.623418,88604672
activation2,Relu,ACTIVATION_FWD2945138956897088891<CUDNN_ACTIVATION_RE...,0.628897,132907008
batchnorm3,BatchNorm,BATCHNORM_FWD_INFERENCE6109524177744274813<CUDNN_BATC...,0.305939,44302336
activation3,Relu,ACTIVATION_FWD4875210504919555136<CUDNN_ACTIVATION_RE...,0.315608,66453504
batchnorm4,BatchNorm,BATCHNORM_FWD_INFERENCE8427814650144125407<CUDNN_BATC...,0.156343,22151168
activation4,Relu,ACTIVATION_FWD9886387398182271691<CUDNN_ACTIVATION_RE...,0.160039,33226752
batchnorm5,BatchNorm,BATCHNORM_FWD_INFERENCE12370610703289465304<CUDNN_BAT...,0.081032,11075584
activation5,Relu,ACTIVATION_FWD13604359784099119333<CUDNN_ACTIVATION_R...,0.082532,16613376
convolution6,Conv,CONV_FWD_010017072541919575219<CUDNN_CONVOLUTION_FWD_...,2.559932,86973087744
batchnorm6,BatchNorm,BATCHNORM_FWD_INFERENCE16948399973379536954<CUDNN_BAT...,0.133199,18874368
activation6,Relu,ACTIVATION_FWD18182604254003773703<CUDNN_ACTIVATION_R...,0.136951,28311552
batchnorm7,BatchNorm,BATCHNORM_FWD_INFERENCE16948399973379536954<CUDNN_BAT...,0.133199,18874368
activation7,Relu,ACTIVATION_FWD18182604254003773703<CUDNN_ACTIVATION_R...,0.136951,28311552
,,Total,13.117612,88811864064
