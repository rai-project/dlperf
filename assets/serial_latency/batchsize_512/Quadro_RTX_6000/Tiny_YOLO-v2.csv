LayerName,LayerType,BenchmarkName,RealTime(ms),Theoretical Flops
batchnorm,BatchNorm,BATCHNORM_FWD_INFERENCE10192737418752381644<CUDNN_BAT...,23.401452,2835349504
activation,Relu,ACTIVATION_FWD15902962014910814925<CUDNN_ACTIVATION_R...,32.471824,4253024256
convolution1,Conv,CONV_FWD_114890007717820903930<CUDNN_CONVOLUTION_FWD_...,19.037822,204145164288
batchnorm1,BatchNorm,BATCHNORM_FWD_INFERENCE4038308242110099184<CUDNN_BATC...,11.101220,1417674752
activation1,Relu,ACTIVATION_FWD7623390132675700465<CUDNN_ACTIVATION_RE...,16.066931,2126512128
convolution2,Conv,CONV_FWD_010003276336779241172<CUDNN_CONVOLUTION_FWD_...,15.626845,204145164288
batchnorm2,BatchNorm,BATCHNORM_FWD_INFERENCE12675215585998569480<CUDNN_BAT...,5.140340,708837376
activation2,Relu,ACTIVATION_FWD18313362831194179593<CUDNN_ACTIVATION_R...,7.916698,1063256064
batchnorm3,BatchNorm,BATCHNORM_FWD_INFERENCE2385690281876086487<CUDNN_BATC...,2.517807,354418688
activation3,Relu,ACTIVATION_FWD8132066853582804694<CUDNN_ACTIVATION_RE...,3.803552,531628032
batchnorm4,BatchNorm,BATCHNORM_FWD_INFERENCE13061523624665044097<CUDNN_BAT...,1.260855,177209344
activation4,Relu,ACTIVATION_FWD17781638411039652601<CUDNN_ACTIVATION_R...,1.802078,265814016
batchnorm5,BatchNorm,BATCHNORM_FWD_INFERENCE598518193442707970<CUDNN_BATCH...,0.633107,88604672
activation5,Relu,ACTIVATION_FWD6453401238353056259<CUDNN_ACTIVATION_RE...,0.828666,132907008
convolution6,Conv,CONV_FWD_1843968789910403817<CUDNN_CONVOLUTION_FWD_AL...,16.478240,695784701952
batchnorm6,BatchNorm,BATCHNORM_FWD_INFERENCE13012487771625153780<CUDNN_BAT...,1.093019,150994944
activation6,Relu,ACTIVATION_FWD16525096485966032117<CUDNN_ACTIVATION_R...,1.527286,226492416
batchnorm7,BatchNorm,BATCHNORM_FWD_INFERENCE13012487771625153780<CUDNN_BAT...,1.093019,150994944
activation7,Relu,ACTIVATION_FWD16525096485966032117<CUDNN_ACTIVATION_R...,1.527286,226492416
,,Total,163.328046,1118785241088
