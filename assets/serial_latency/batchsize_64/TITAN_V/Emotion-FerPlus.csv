LayerName,LayerType,BenchmarkName,RealTime(ms),Theoretical Flops
Convolution362,Conv,CONV_FWD_017504095727960022390<CUDNN_CONVOLUTION_FWD_...,0.130652,301989888
ReLU366,Relu,ACTIVATION_FWD16777172162637662734<CUDNN_ACTIVATION_R...,0.240276,50331648
ReLU384,Relu,ACTIVATION_FWD16777172162637662734<CUDNN_ACTIVATION_R...,0.240276,50331648
ReLU422,Relu,ACTIVATION_FWD10211824732294482079<CUDNN_ACTIVATION_R...,0.122122,25165824
ReLU440,Relu,ACTIVATION_FWD10211824732294482079<CUDNN_ACTIVATION_R...,0.122122,25165824
Convolution474,Conv,CONV_FWD_08173108997062867098<CUDNN_CONVOLUTION_FWD_A...,0.376908,9663676416
ReLU478,Relu,ACTIVATION_FWD7484669048989193371<CUDNN_ACTIVATION_RE...,0.064029,12582912
ReLU496,Relu,ACTIVATION_FWD7484669048989193371<CUDNN_ACTIVATION_RE...,0.064029,12582912
ReLU514,Relu,ACTIVATION_FWD7484669048989193371<CUDNN_ACTIVATION_RE...,0.064029,12582912
ReLU552,Relu,ACTIVATION_FWD5708987712671602724<CUDNN_ACTIVATION_RE...,0.020562,3145728
ReLU570,Relu,ACTIVATION_FWD5708987712671602724<CUDNN_ACTIVATION_RE...,0.020562,3145728
ReLU588,Relu,ACTIVATION_FWD5708987712671602724<CUDNN_ACTIVATION_RE...,0.020562,3145728
Times622,Gemm,GEMV_FWD1404263558367592260,0.052485,8389632
ReLU636,Relu,ACTIVATION_FWD10404430894903856683<CUDNN_ACTIVATION_R...,0.006194,3072
Times656,Gemm,GEMV_FWD6610639734550256167,0.012915,2098176
ReLU670,Relu,ACTIVATION_FWD10404430894903856683<CUDNN_ACTIVATION_R...,0.006194,3072
Times690,Gemm,GEMV_FWD10271248668658711484,0.007104,16392
,,Total,1.571020,10174357512
