LayerName,LayerType,BenchmarkName,RealTime(ms),Theoretical Flops
Convolution362,Conv,CONV_FWD_017504095727960022390<CUDNN_CONVOLUTION_FWD_...,1.406627,301989888
ReLU366,Relu,ACTIVATION_FWD16777172162637662734<CUDNN_ACTIVATION_R...,1.032753,50331648
ReLU384,Relu,ACTIVATION_FWD16777172162637662734<CUDNN_ACTIVATION_R...,1.032753,50331648
ReLU422,Relu,ACTIVATION_FWD10211824732294482079<CUDNN_ACTIVATION_R...,0.525221,25165824
ReLU440,Relu,ACTIVATION_FWD10211824732294482079<CUDNN_ACTIVATION_R...,0.525221,25165824
Convolution474,Conv,CONV_FWD_08173108997062867098<CUDNN_CONVOLUTION_FWD_A...,7.318927,9663676416
ReLU478,Relu,ACTIVATION_FWD7484669048989193371<CUDNN_ACTIVATION_RE...,0.270076,12582912
ReLU496,Relu,ACTIVATION_FWD7484669048989193371<CUDNN_ACTIVATION_RE...,0.270076,12582912
ReLU514,Relu,ACTIVATION_FWD7484669048989193371<CUDNN_ACTIVATION_RE...,0.270076,12582912
ReLU552,Relu,ACTIVATION_FWD5708987712671602724<CUDNN_ACTIVATION_RE...,0.080282,3145728
ReLU570,Relu,ACTIVATION_FWD5708987712671602724<CUDNN_ACTIVATION_RE...,0.080282,3145728
ReLU588,Relu,ACTIVATION_FWD5708987712671602724<CUDNN_ACTIVATION_RE...,0.080282,3145728
Times622,Gemm,GEMV_FWD1404263558367592260,0.220546,8389632
ReLU636,Relu,ACTIVATION_FWD10404430894903856683<CUDNN_ACTIVATION_R...,0.014615,3072
Times656,Gemm,GEMV_FWD6610639734550256167,0.064657,2098176
ReLU670,Relu,ACTIVATION_FWD10404430894903856683<CUDNN_ACTIVATION_R...,0.014615,3072
Times690,Gemm,GEMV_FWD10271248668658711484,0.022573,16392
,,Total,13.229581,10174357512
