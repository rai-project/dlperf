LayerName,LayerType,BenchmarkName,RealTime(ms),Theoretical Flops
batchnorm,BatchNorm,BATCHNORM_FWD_INFERENCE4496119707191152535<CUDNN_BATC...,32.933546,708837376
activation,Relu,ACTIVATION_FWD13811507302503856802<CUDNN_ACTIVATION_R...,31.956292,1063256064
batchnorm1,BatchNorm,BATCHNORM_FWD_INFERENCE7006336951657907319<CUDNN_BATC...,15.705132,354418688
activation1,Relu,ACTIVATION_FWD16209224632504742210<CUDNN_ACTIVATION_R...,15.987115,531628032
batchnorm2,BatchNorm,BATCHNORM_FWD_INFERENCE16838400792959797723<CUDNN_BAT...,7.491975,177209344
activation2,Relu,ACTIVATION_FWD7523049824865877230<CUDNN_ACTIVATION_RE...,7.999473,265814016
batchnorm3,BatchNorm,BATCHNORM_FWD_INFERENCE2272772328970393420<CUDNN_BATC...,3.551840,88604672
activation3,Relu,ACTIVATION_FWD11404165245588578937<CUDNN_ACTIVATION_R...,4.006895,132907008
batchnorm4,BatchNorm,BATCHNORM_FWD_INFERENCE5722518830201903470<CUDNN_BATC...,1.721900,44302336
activation4,Relu,ACTIVATION_FWD8096921656341651302<CUDNN_ACTIVATION_RE...,2.005064,66453504
batchnorm5,BatchNorm,BATCHNORM_FWD_INFERENCE309343917831893305<CUDNN_BATCH...,0.886558,22151168
activation5,Relu,ACTIVATION_FWD9620316750620623884<CUDNN_ACTIVATION_RE...,1.008474,33226752
batchnorm6,BatchNorm,BATCHNORM_FWD_INFERENCE10920519682909109743<CUDNN_BAT...,1.496044,37748736
activation6,Relu,ACTIVATION_FWD1604481517759940826<CUDNN_ACTIVATION_RE...,1.653849,56623104
batchnorm7,BatchNorm,BATCHNORM_FWD_INFERENCE10920519682909109743<CUDNN_BAT...,1.496044,37748736
activation7,Relu,ACTIVATION_FWD1604481517759940826<CUDNN_ACTIVATION_RE...,1.653849,56623104
,,Total,129.900201,3677552640
