LayerName,LayerType,BenchmarkName,RealTime(ms),Theoretical Flops
batchnorm,BatchNorm,BATCHNORM_FWD_INFERENCE16658017616467584502<CUDNN_BAT...,16.508387,354418688
activation,Relu,ACTIVATION_FWD17315341123322895563<CUDNN_ACTIVATION_R...,15.987473,531628032
batchnorm1,BatchNorm,BATCHNORM_FWD_INFERENCE5144071037578962086<CUDNN_BATC...,7.874551,177209344
activation1,Relu,ACTIVATION_FWD5765223918917180827<CUDNN_ACTIVATION_RE...,8.001065,265814016
batchnorm2,BatchNorm,BATCHNORM_FWD_INFERENCE4593220302806436934<CUDNN_BATC...,3.755620,88604672
activation2,Relu,ACTIVATION_FWD2945138956897088891<CUDNN_ACTIVATION_RE...,4.007071,132907008
batchnorm3,BatchNorm,BATCHNORM_FWD_INFERENCE6109524177744274813<CUDNN_BATC...,1.782610,44302336
activation3,Relu,ACTIVATION_FWD4875210504919555136<CUDNN_ACTIVATION_RE...,2.005169,66453504
batchnorm4,BatchNorm,BATCHNORM_FWD_INFERENCE8427814650144125407<CUDNN_BATC...,0.866431,22151168
activation4,Relu,ACTIVATION_FWD9886387398182271691<CUDNN_ACTIVATION_RE...,1.008497,33226752
batchnorm5,BatchNorm,BATCHNORM_FWD_INFERENCE12370610703289465304<CUDNN_BAT...,0.448847,11075584
activation5,Relu,ACTIVATION_FWD13604359784099119333<CUDNN_ACTIVATION_R...,0.510137,16613376
convolution6,Conv,CONV_FWD_010017072541919575219<CUDNN_CONVOLUTION_FWD_...,29.137663,86973087744
batchnorm6,BatchNorm,BATCHNORM_FWD_INFERENCE16948399973379536954<CUDNN_BAT...,0.753836,18874368
activation6,Relu,ACTIVATION_FWD18182604254003773703<CUDNN_ACTIVATION_R...,0.837209,28311552
batchnorm7,BatchNorm,BATCHNORM_FWD_INFERENCE16948399973379536954<CUDNN_BAT...,0.753836,18874368
activation7,Relu,ACTIVATION_FWD18182604254003773703<CUDNN_ACTIVATION_R...,0.837209,28311552
,,Total,94.238402,88811864064
