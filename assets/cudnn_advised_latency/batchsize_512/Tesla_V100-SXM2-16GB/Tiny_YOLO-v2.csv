LayerName,LayerType,BenchmarkName,RealTime(ms),Theoretical Flops
batchnorm,BatchNorm,BATCHNORM_FWD_INFERENCE10192737418752381644<CUDNN_BAT...,15.510372,2835349504
activation,Relu,ACTIVATION_FWD15902962014910814925<CUDNN_ACTIVATION_R...,18.235227,4253024256
convolution1,Conv,CONV_FWD_114890007717820903930<CUDNN_CONVOLUTION_FWD_...,31.266678,204145164288
batchnorm1,BatchNorm,BATCHNORM_FWD_INFERENCE4038308242110099184<CUDNN_BATC...,7.706643,1417674752
activation1,Relu,ACTIVATION_FWD7623390132675700465<CUDNN_ACTIVATION_RE...,8.766830,2126512128
convolution2,Conv,CONV_FWD_010003276336779241172<CUDNN_CONVOLUTION_FWD_...,19.924138,204145164288
batchnorm2,BatchNorm,BATCHNORM_FWD_INFERENCE12675215585998569480<CUDNN_BAT...,3.716745,708837376
activation2,Relu,ACTIVATION_FWD18313362831194179593<CUDNN_ACTIVATION_R...,4.175662,1063256064
batchnorm3,BatchNorm,BATCHNORM_FWD_INFERENCE2385690281876086487<CUDNN_BATC...,1.788630,354418688
activation3,Relu,ACTIVATION_FWD8132066853582804694<CUDNN_ACTIVATION_RE...,1.980968,531628032
batchnorm4,BatchNorm,BATCHNORM_FWD_INFERENCE13061523624665044097<CUDNN_BAT...,0.952538,177209344
activation4,Relu,ACTIVATION_FWD17781638411039652601<CUDNN_ACTIVATION_R...,0.971806,265814016
batchnorm5,BatchNorm,BATCHNORM_FWD_INFERENCE598518193442707970<CUDNN_BATCH...,0.519371,88604672
activation5,Relu,ACTIVATION_FWD6453401238353056259<CUDNN_ACTIVATION_RE...,0.485331,132907008
convolution6,Conv,CONV_FWD_1843968789910403817<CUDNN_CONVOLUTION_FWD_AL...,27.174514,695784701952
batchnorm6,BatchNorm,BATCHNORM_FWD_INFERENCE13012487771625153780<CUDNN_BAT...,0.867535,150994944
activation6,Relu,ACTIVATION_FWD16525096485966032117<CUDNN_ACTIVATION_R...,0.824323,226492416
batchnorm7,BatchNorm,BATCHNORM_FWD_INFERENCE13012487771625153780<CUDNN_BAT...,0.867535,150994944
activation7,Relu,ACTIVATION_FWD16525096485966032117<CUDNN_ACTIVATION_R...,0.824323,226492416
,,Total,145.734846,1118785241088
