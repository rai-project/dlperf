{
  "context": {
    "date": "2019-09-26 13:44:37",
    "executable": "./scope",
    "num_cpus": 4,
    "mhz_per_cpu": 3000,
    "cpu_scaling_enabled": false,
    "caches": [
      {
        "type": "Data",
        "level": 1,
        "size": 32000000,
        "num_sharing": 1
      },
      {
        "type": "Instruction",
        "level": 1,
        "size": 32000000,
        "num_sharing": 1
      },
      {
        "type": "Unified",
        "level": 2,
        "size": 256000000,
        "num_sharing": 1
      },
      {
        "type": "Unified",
        "level": 3,
        "size": 46080000000,
        "num_sharing": 4
      }
    ],
    "library_build_type": "release"
  },
  "benchmarks": [
    {
      "name": "LAYER_CUBLAS_GEMM_FWD_FLOAT32__BatchSize_1024__8632017734986618546/input[0]:1024/input[1]:1000/input[2]:2048/input[3]:0/input[4]:1/input[5]:1/input[6]:1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 1787,
      "real_time": 3.9606564798771241e+05,
      "cpu_time": 4.0903927867935126e+05,
      "time_unit": "ns",
      "items_per_second": 5.2949605972014570e+12,
      "K": 2.0480000000000000e+03,
      "M": 1.0240000000000000e+03,
      "N": 1.0000000000000000e+03,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cublas_gemm_fwd.cpp": 1.3264966594868343e+19,
      "benchmark_func:void iLAYER_CUBLAS_GEMM_FWD_Impl(benchmark::State&) [with T = float]": 7.4787548781531884e+18,
      "beta": 1.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMM_FWD_Impl": 1.7610984762236383e+19,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0000000000000000e+03,
      "input[2]": 2.0480000000000000e+03,
      "input[3]": 0.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": 1.0000000000000000e+00,
      "input[6]": 1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "lda": 1.0240000000000000e+03,
      "ldb": 1.0000000000000000e+03,
      "num_iterations": 1.7870000000000000e+03,
      "predicted_flops": 1.0589921194402914e+13,
      "predicted_flops_count": 4.1943040000000000e+09,
      "transA": 0.0000000000000000e+00,
      "transB": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_1024__16629436241185018615<CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 2473,
      "real_time": 2.8337387569703226e+05,
      "cpu_time": 2.9542352405985352e+05,
      "time_unit": "ns",
      "items_per_second": 9.0658011211543198e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.0002183616584573e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 2.4730000000000000e+03,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 9.0658011211543198e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_1024__16629436241185018615<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 2464,
      "real_time": 2.8394930266042682e+05,
      "cpu_time": 2.9607129017857218e+05,
      "time_unit": "ns",
      "items_per_second": 9.0474291570008331e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.0002183616584573e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 2.4640000000000000e+03,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 9.0474291570008331e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_1024__11592987558580235860<CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 618,
      "real_time": 1.1335348638458762e+06,
      "cpu_time": 1.1649411472492281e+06,
      "time_unit": "ns",
      "items_per_second": 9.0654863187315308e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.0002183616584573e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0276044800000000e+08,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 6.1800000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 9.0654863187315308e+10,
      "predicted_flops_count": 1.0276044800000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_1024__11592987558580235860<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 617,
      "real_time": 1.1333589380942103e+06,
      "cpu_time": 1.1647086094002910e+06,
      "time_unit": "ns",
      "items_per_second": 9.0668935097292221e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.0002183616584573e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0276044800000000e+08,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 6.1700000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 9.0668935097292221e+10,
      "predicted_flops_count": 1.0276044800000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_1024__10378186515612078483<CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 1240,
      "real_time": 5.6354599054752581e+05,
      "cpu_time": 5.7972412016129075e+05,
      "time_unit": "ns",
      "items_per_second": 9.1173080568065765e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.0002183616584573e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.2400000000000000e+03,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 9.1173080568065765e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_1024__10378186515612078483<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 1240,
      "real_time": 5.6338578334919387e+05,
      "cpu_time": 5.7910893467742170e+05,
      "time_unit": "ns",
      "items_per_second": 9.1199007001129578e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.0002183616584573e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.2400000000000000e+03,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 9.1199007001129578e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_1024__11896576823602521232<CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 617,
      "real_time": 1.1334451893948296e+06,
      "cpu_time": 1.1650403338736452e+06,
      "time_unit": "ns",
      "items_per_second": 9.0662035501571960e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.0002183616584573e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 6.1700000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 9.0662035501571960e+10,
      "predicted_flops_count": 1.0276044800000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_1024__11896576823602521232<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 617,
      "real_time": 1.1333688464154589e+06,
      "cpu_time": 1.1646654246353337e+06,
      "time_unit": "ns",
      "items_per_second": 9.0668142436598343e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.0002183616584573e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 6.1700000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 9.0668142436598343e+10,
      "predicted_flops_count": 1.0276044800000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_1024__7322499358198547495<CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 69,
      "real_time": 1.0187375291750051e+07,
      "cpu_time": 1.1732505985507421e+07,
      "time_unit": "ns",
      "items_per_second": 8.0696308956610291e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.0002183616584573e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 8.2208358400000000e+08,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 6.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.2208358400000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 8.0696308956610291e+10,
      "predicted_flops_count": 8.2208358400000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_1024__7322499358198547495<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 68,
      "real_time": 1.0201735545278473e+07,
      "cpu_time": 1.1773810882352551e+07,
      "time_unit": "ns",
      "items_per_second": 8.0582718533659058e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.0002183616584573e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 8.2208358400000000e+08,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 6.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.2208358400000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 8.0582718533659058e+10,
      "predicted_flops_count": 8.2208358400000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_1024__5450682024356214027<CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 144,
      "real_time": 4.8792175625243951e+06,
      "cpu_time": 5.2420641388891311e+06,
      "time_unit": "ns",
      "items_per_second": 8.4243382618777191e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.0002183616584573e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.4400000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 8.4243382618777191e+10,
      "predicted_flops_count": 4.1104179200000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_1024__5450682024356214027<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 143,
      "real_time": 4.8727577070256211e+06,
      "cpu_time": 5.2386521818177477e+06,
      "time_unit": "ns",
      "items_per_second": 8.4355064773147507e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.0002183616584573e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.4300000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 8.4355064773147507e+10,
      "predicted_flops_count": 4.1104179200000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_1024__9628901655057679407<CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 300,
      "real_time": 2.3329825070686638e+06,
      "cpu_time": 2.4271557633335069e+06,
      "time_unit": "ns",
      "items_per_second": 8.8093629239523117e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.0002183616584573e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 3.0000000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 8.8093629239523117e+10,
      "predicted_flops_count": 2.0552089600000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_1024__9628901655057679407<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 300,
      "real_time": 2.3276236785265305e+06,
      "cpu_time": 2.4193352766662929e+06,
      "time_unit": "ns",
      "items_per_second": 8.8296444952004486e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.0002183616584573e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 3.0000000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 8.8296444952004486e+10,
      "predicted_flops_count": 2.0552089600000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_1024__10036264504493669443<CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 300,
      "real_time": 2.3321567010134459e+06,
      "cpu_time": 2.4276688933332008e+06,
      "time_unit": "ns",
      "items_per_second": 8.8124822792006332e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.0002183616584573e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 3.0000000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 8.8124822792006332e+10,
      "predicted_flops_count": 2.0552089600000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_1024__10036264504493669443<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 300,
      "real_time": 2.3358362734628222e+06,
      "cpu_time": 2.4305751033335337e+06,
      "time_unit": "ns",
      "items_per_second": 8.7986002415880005e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.0002183616584573e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 3.0000000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 8.7986002415880005e+10,
      "predicted_flops_count": 2.0552089600000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_1024__8616683104307991559<CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 69,
      "real_time": 1.0182285019992918e+07,
      "cpu_time": 1.1723137579710437e+07,
      "time_unit": "ns",
      "items_per_second": 8.0736650210226761e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.0002183616584573e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 8.2208358400000000e+08,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 6.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 8.2208358400000000e+08,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 8.0736650210226761e+10,
      "predicted_flops_count": 8.2208358400000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_1024__8616683104307991559<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 69,
      "real_time": 1.0183487033498460e+07,
      "cpu_time": 1.1730813260868857e+07,
      "time_unit": "ns",
      "items_per_second": 8.0727120415213943e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.0002183616584573e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 8.2208358400000000e+08,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 6.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 8.2208358400000000e+08,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 8.0727120415213943e+10,
      "predicted_flops_count": 8.2208358400000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_1024__6654794576357619937<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 80,
      "real_time": 8.8027903111651540e+06,
      "cpu_time": 9.9193893125006482e+06,
      "time_unit": "ns",
      "items_per_second": 4.6694488618983559e+10,
      "batch_size": 1.0240000000000000e+03,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.3487223397460840e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 8.0000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.6694488618983559e+10,
      "predicted_flops_count": 4.1104179200000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_1024__16088170121722350794<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 55,
      "real_time": 1.2702646089548415e+07,
      "cpu_time": 1.5026365363637369e+07,
      "time_unit": "ns",
      "items_per_second": 3.2358753373299149e+10,
      "batch_size": 1.0240000000000000e+03,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.3487223397460840e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 3.2358753373299149e+10,
      "predicted_flops_count": 4.1104179200000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_1024__11293298750192284073<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 160,
      "real_time": 4.3635519541567191e+06,
      "cpu_time": 4.6512823812506991e+06,
      "time_unit": "ns",
      "items_per_second": 4.7099449750843651e+10,
      "batch_size": 1.0240000000000000e+03,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.3487223397460840e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.6000000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.7099449750843651e+10,
      "predicted_flops_count": 2.0552089600000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_1024__2281045125469521282<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 114,
      "real_time": 6.1573207157811048e+06,
      "cpu_time": 6.7126864824558403e+06,
      "time_unit": "ns",
      "items_per_second": 3.3378299667459831e+10,
      "batch_size": 1.0240000000000000e+03,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.3487223397460840e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.1400000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 3.3378299667459831e+10,
      "predicted_flops_count": 2.0552089600000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_1024__8241759229335390669<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1024/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 40,
      "real_time": 1.7691263975575566e+07,
      "cpu_time": 2.2124315925002590e+07,
      "time_unit": "ns",
      "items_per_second": 4.6468335170113495e+10,
      "batch_size": 1.0240000000000000e+03,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.3487223397460840e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 8.2208358400000000e+08,
      "input_width": 1.1200000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 4.0000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.2208358400000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 4.6468335170113495e+10,
      "predicted_flops_count": 8.2208358400000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_1024__17401523366778174950<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1024/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 28,
      "real_time": 2.5326921005866356e+07,
      "cpu_time": 3.4386184464285210e+07,
      "time_unit": "ns",
      "items_per_second": 3.2458883723354473e+10,
      "batch_size": 1.0240000000000000e+03,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.3487223397460840e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 8.2208358400000000e+08,
      "input_width": 1.1200000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.2208358400000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 3.2458883723354473e+10,
      "predicted_flops_count": 8.2208358400000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_1024__13194617578994312126<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 485,
      "real_time": 1.4426174799229987e+06,
      "cpu_time": 1.4850646020616028e+06,
      "time_unit": "ns",
      "items_per_second": 7.1231944316579987e+10,
      "batch_size": 1.0240000000000000e+03,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.3487223397460840e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0276044800000000e+08,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 4.8500000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 7.1231944316579987e+10,
      "predicted_flops_count": 1.0276044800000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_1024__3747715978754594709<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 294,
      "real_time": 2.3775747367402627e+06,
      "cpu_time": 2.4723866836734526e+06,
      "time_unit": "ns",
      "items_per_second": 4.3220701503956985e+10,
      "batch_size": 1.0240000000000000e+03,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.3487223397460840e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0276044800000000e+08,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.9400000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.3220701503956985e+10,
      "predicted_flops_count": 1.0276044800000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_1024__17382067324444548893<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 2288,
      "real_time": 3.0646510480233905e+05,
      "cpu_time": 3.1851383173043554e+05,
      "time_unit": "ns",
      "items_per_second": 8.3827201196590927e+10,
      "batch_size": 1.0240000000000000e+03,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.3487223397460840e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.2880000000000000e+03,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 8.3827201196590927e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_1024__8225753487642503990<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 1261,
      "real_time": 5.5594756570773921e+05,
      "cpu_time": 5.7181959080097219e+05,
      "time_unit": "ns",
      "items_per_second": 4.6209595265149971e+10,
      "batch_size": 1.0240000000000000e+03,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.3487223397460840e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.2610000000000000e+03,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.6209595265149971e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_1024__9797752113431354489<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 1136,
      "real_time": 6.1580979519008833e+05,
      "cpu_time": 6.3145907570424420e+05,
      "time_unit": "ns",
      "items_per_second": 8.3435217174712112e+10,
      "batch_size": 1.0240000000000000e+03,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.3487223397460840e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.1360000000000000e+03,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 8.3435217174712112e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_1024__353152924928780370<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 639,
      "real_time": 1.0957936825542615e+06,
      "cpu_time": 1.1253435195627960e+06,
      "time_unit": "ns",
      "items_per_second": 4.6888593006152641e+10,
      "batch_size": 1.0240000000000000e+03,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.3487223397460840e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.3900000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.6888593006152641e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_1024__12891276390688565626<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 485,
      "real_time": 1.4418532370983325e+06,
      "cpu_time": 1.4838753030917430e+06,
      "time_unit": "ns",
      "items_per_second": 7.1269700241337296e+10,
      "batch_size": 1.0240000000000000e+03,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.3487223397460840e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 4.8500000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 7.1269700241337296e+10,
      "predicted_flops_count": 1.0276044800000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_1024__3600978129552842065<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 295,
      "real_time": 2.3771515660682474e+06,
      "cpu_time": 2.4715482847452057e+06,
      "time_unit": "ns",
      "items_per_second": 4.3228395474152863e+10,
      "batch_size": 1.0240000000000000e+03,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.3487223397460840e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.9500000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.3228395474152863e+10,
      "predicted_flops_count": 1.0276044800000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_1024__6947569497180297709<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 40,
      "real_time": 1.7694540554657578e+07,
      "cpu_time": 2.2134687174999356e+07,
      "time_unit": "ns",
      "items_per_second": 4.6459730415753021e+10,
      "batch_size": 1.0240000000000000e+03,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.3487223397460840e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 8.2208358400000000e+08,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 4.0000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 8.2208358400000000e+08,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 4.6459730415753021e+10,
      "predicted_flops_count": 8.2208358400000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_1024__16389870843484237254<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 28,
      "real_time": 2.5329151856047768e+07,
      "cpu_time": 3.4369963464288034e+07,
      "time_unit": "ns",
      "items_per_second": 3.2456024926224030e+10,
      "batch_size": 1.0240000000000000e+03,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.3487223397460840e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 8.2208358400000000e+08,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 8.2208358400000000e+08,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 3.2456024926224030e+10,
      "predicted_flops_count": 8.2208358400000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_1024__10547035665093380549<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 160,
      "real_time": 4.3633855617372319e+06,
      "cpu_time": 4.6520567937507806e+06,
      "time_unit": "ns",
      "items_per_second": 4.7101245831270111e+10,
      "batch_size": 1.0240000000000000e+03,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.3487223397460840e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.6000000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 4.7101245831270111e+10,
      "predicted_flops_count": 2.0552089600000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_1024__1243173931765595630<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 114,
      "real_time": 6.1564676283875052e+06,
      "cpu_time": 6.7121122631570473e+06,
      "time_unit": "ns",
      "items_per_second": 3.3382924820775803e+10,
      "batch_size": 1.0240000000000000e+03,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.3487223397460840e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.1400000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 3.3382924820775803e+10,
      "predicted_flops_count": 2.0552089600000000e+08
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__5188265528089880136<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 33,
      "real_time": 2.1325513776956182e+07,
      "cpu_time": 2.7809423969697177e+07,
      "time_unit": "ns",
      "items_per_second": 6.1678876680632043e+11,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.1323776245117188e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 7.1524010027818652e+11,
      "predicted_advised_flops_count": 1.5252862612313990e+10,
      "predicted_flops": 5.5510989012568838e+12,
      "predicted_flops_count": 1.1838003609600000e+11,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__5188265528089880136<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 38,
      "real_time": 1.8477487083720535e+07,
      "cpu_time": 2.3360308157894325e+07,
      "time_unit": "ns",
      "items_per_second": 7.1185747739413440e+11,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 1.8481151580810547e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 8.2548360300316077e+11,
      "predicted_advised_flops_count": 1.5252862612313990e+10,
      "predicted_flops": 6.4067172965472100e+12,
      "predicted_flops_count": 1.1838003609600000e+11,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__5188265528089880136<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 25,
      "real_time": 2.8099665716290474e+07,
      "cpu_time": 3.9365397959999196e+07,
      "time_unit": "ns",
      "items_per_second": 4.6809586550969171e+11,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.6993761280000000e+09,
      "advised_time": 2.8092416763305664e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 5.4281295607980524e+11,
      "predicted_advised_flops_count": 1.5252862612313990e+10,
      "predicted_flops": 4.2128627895872251e+12,
      "predicted_flops_count": 1.1838003609600000e+11,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.6993761280000000e+09,
      "workspace_megabytes": 3.5280000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__5188265528089880136<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__5188265528089880136<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 82,
      "real_time": 8.5587168066966832e+06,
      "cpu_time": 9.6232209999996256e+06,
      "time_unit": "ns",
      "items_per_second": 1.5368352103563354e+12,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2840468480000000e+09,
      "advised_time": 8.8576002120971680e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 8.2000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 1.7821436269955256e+12,
      "predicted_advised_flops_count": 1.5252862612313990e+10,
      "predicted_flops": 1.7821436269955256e+12,
      "predicted_flops_count": 1.5252862612313990e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.2840468480000000e+09,
      "workspace_megabytes": 1.2245625000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__5188265528089880136<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 95,
      "real_time": 7.4033798796958048e+06,
      "cpu_time": 8.2016281263122438e+06,
      "time_unit": "ns",
      "items_per_second": 1.7766665438948750e+12,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2121784320000000e+09,
      "advised_time": 7.7424640655517578e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 9.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 2.0602566476624878e+12,
      "predicted_advised_flops_count": 1.5252862612313990e+10,
      "predicted_flops": 2.0602566476624878e+12,
      "predicted_flops_count": 1.5252862612313990e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.2121784320000000e+09,
      "workspace_megabytes": 1.1560234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__5188265528089880136<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 57,
      "real_time": 1.2296748886767186e+07,
      "cpu_time": 1.4472433614034878e+07,
      "time_unit": "ns",
      "items_per_second": 1.0696597503226733e+12,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6389120000000000e+06,
      "advised_time": 1.2350463867187500e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnMathType_t math_type = (cudnnMathType_t)0]": 5.7500739770702787e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 5.7000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 1.2403979907833970e+12,
      "predicted_advised_flops_count": 1.5252862612313990e+10,
      "predicted_flops": -8.1322307970045884e+01,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6389120000000000e+06,
      "workspace_megabytes": 1.5629882812500000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__5188265528089880136<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 77,
      "real_time": 9.0802468407850768e+06,
      "cpu_time": 1.0279107987012642e+07,
      "time_unit": "ns",
      "items_per_second": 1.4485660549358772e+12,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8520473600000000e+09,
      "advised_time": 9.5631361007690430e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.2538945752816425e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 7.7000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 1.6797850190375696e+12,
      "predicted_advised_flops_count": 1.5252862612313990e+10,
      "predicted_flops": -1.1012916471701779e+02,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8520473600000000e+09,
      "workspace_megabytes": 1.7662500000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__8798305753556776280<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 26,
      "real_time": 2.6739160601909343e+07,
      "cpu_time": 3.7064142769235805e+07,
      "time_unit": "ns",
      "items_per_second": 4.9191287414836682e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.6750976562500000e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -3.7398331790886274e+01,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 4.4272158673353018e+12,
      "predicted_flops_count": 1.1838003609600000e+11,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__8798305753556776280<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 38,
      "real_time": 1.8540813244487111e+07,
      "cpu_time": 2.3450215894733991e+07,
      "time_unit": "ns",
      "items_per_second": 7.0942612767597925e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 1.8547712326049805e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -5.3935066753198548e+01,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 6.3848351490838135e+12,
      "predicted_flops_count": 1.1838003609600000e+11,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__8798305753556776280<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 18,
      "real_time": 3.9504611450764865e+07,
      "cpu_time": 6.1508670666664034e+07,
      "time_unit": "ns",
      "items_per_second": 3.3295701086424255e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.3987522560000000e+09,
      "advised_time": -1.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -2.5313500456682469e+01,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 2.9966130977781831e+12,
      "predicted_flops_count": 1.1838003609600000e+11,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.3987522560000000e+09,
      "workspace_megabytes": 7.0560000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__8798305753556776280<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__8798305753556776280<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 41,
      "real_time": 1.7031542684246853e+07,
      "cpu_time": 2.1222960317071676e+07,
      "time_unit": "ns",
      "items_per_second": 7.7229277393445056e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.3531520000000000e+09,
      "advised_time": 1.8072576522827148e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.1000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -5.8714587312454057e+01,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 1.0613636371869229e+12,
      "predicted_flops_count": 1.8076660090256569e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.3531520000000000e+09,
      "workspace_megabytes": 2.2441406250000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__8798305753556776280<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 50,
      "real_time": 1.4069452770054340e+07,
      "cpu_time": 1.6896275859999150e+07,
      "time_unit": "ns",
      "items_per_second": 9.3488620765661792e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1587256320000000e+09,
      "advised_time": 1.4856191635131836e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.0000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -7.1075969786715291e+01,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 1.2848161464197981e+12,
      "predicted_flops_count": 1.8076660090256569e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1587256320000000e+09,
      "workspace_megabytes": 1.1050468750000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__8798305753556776280<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 59,
      "real_time": 1.1793234385550022e+07,
      "cpu_time": 1.3818928186438724e+07,
      "time_unit": "ns",
      "items_per_second": 1.1153290873381165e+12,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.0985600000000000e+05,
      "advised_time": 1.1873279571533203e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnMathType_t math_type = (cudnnMathType_t)0]": 5.7500739770702787e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -8.4794380176593194e+01,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": -8.4794380176593194e+01,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.0985600000000000e+05,
      "workspace_megabytes": 3.9086914062500000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__8798305753556776280<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 40,
      "real_time": 1.7590400110930204e+07,
      "cpu_time": 2.2023224874997996e+07,
      "time_unit": "ns",
      "items_per_second": 7.4775657523712988e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.6999659520000000e+09,
      "advised_time": 1.8451456069946289e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.2538945752816425e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.0000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -5.6849190109020128e+01,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": -5.6849190109020128e+01,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.6999659520000000e+09,
      "workspace_megabytes": 3.5285625000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__1754214667856992190<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 57,
      "real_time": 1.2188402609082691e+07,
      "cpu_time": 1.4372550491230596e+07,
      "time_unit": "ns",
      "items_per_second": 4.3166730755015425e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.2194815635681152e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.7000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.3166730755015425e+12,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 4.3166730755015425e+12,
      "predicted_flops_count": 5.2613349376000000e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__1754214667856992190<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 83,
      "real_time": 8.3998102604983803e+06,
      "cpu_time": 9.4458045662660059e+06,
      "time_unit": "ns",
      "items_per_second": 6.2636354565559355e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 8.4285440444946289e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 8.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 6.2636354565559355e+12,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 6.2636354565559355e+12,
      "predicted_flops_count": 5.2613349376000000e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__1754214667856992190<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 51,
      "real_time": 1.3796793716941394e+07,
      "cpu_time": 1.6555486254901553e+07,
      "time_unit": "ns",
      "items_per_second": 3.8134475629214404e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.1104179200000000e+08,
      "advised_time": 1.3772800445556641e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.1000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.8134475629214404e+12,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 3.8134475629214404e+12,
      "predicted_flops_count": 5.2613349376000000e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.1104179200000000e+08,
      "workspace_megabytes": 3.9200000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__1754214667856992190<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__1754214667856992190<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 23,
      "real_time": 2.9905073992584061e+07,
      "cpu_time": 4.2997734565218426e+07,
      "time_unit": "ns",
      "items_per_second": 1.7593452331549888e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.5636648960000000e+09,
      "advised_time": 3.0124031066894531e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.7593452331549888e+12,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 1.9410557148508254e+12,
      "predicted_flops_count": 5.8047414776342087e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.5636648960000000e+09,
      "workspace_megabytes": 4.3522500000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__1754214667856992190<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 31,
      "real_time": 2.2827041786043875e+07,
      "cpu_time": 3.0257072806451347e+07,
      "time_unit": "ns",
      "items_per_second": 2.3048693680565762e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5045241920000000e+09,
      "advised_time": 2.3377920150756836e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.1000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.3048693680565762e+12,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 2.5429232276532407e+12,
      "predicted_flops_count": 5.8047414776342087e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.5045241920000000e+09,
      "workspace_megabytes": 2.3885003967285156e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__1754214667856992190<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__1754214667856992190<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__10673954627667044957<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 44,
      "real_time": 1.5942144038325006e+07,
      "cpu_time": 1.9660162795454863e+07,
      "time_unit": "ns",
      "items_per_second": 3.3002680975355137e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.5947775840759277e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 8.2208358400000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.3002680975355137e+12,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 3.3002680975355137e+12,
      "predicted_flops_count": 5.2613349376000000e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__10673954627667044957<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 76,
      "real_time": 9.1677637231585234e+06,
      "cpu_time": 1.0434396789473658e+07,
      "time_unit": "ns",
      "items_per_second": 5.7389512824260908e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 9.1730241775512695e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 7.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 8.2208358400000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.7389512824260908e+12,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 5.7389512824260908e+12,
      "predicted_flops_count": 5.2613349376000000e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__10673954627667044957<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 43,
      "real_time": 1.6369330675102944e+07,
      "cpu_time": 2.0272706162791375e+07,
      "time_unit": "ns",
      "items_per_second": 3.2141417642703418e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.2208358400000000e+08,
      "advised_time": 1.6336896896362305e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 8.2208358400000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.2141417642703418e+12,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 3.2141417642703418e+12,
      "predicted_flops_count": 5.2613349376000000e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 8.2208358400000000e+08,
      "workspace_megabytes": 7.8400000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__10673954627667044957<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__10673954627667044957<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to perform cudnnFindConvolutionForwardAlgorithm",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__10673954627667044957<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 21,
      "real_time": 3.3575497745048434e+07,
      "cpu_time": 4.9742261190477252e+07,
      "time_unit": "ns",
      "items_per_second": 1.5670162144881140e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.9934508160000000e+09,
      "advised_time": -1.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.1000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 8.2208358400000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.5670162144881140e+12,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 1.9402673977873015e+12,
      "predicted_flops_count": 6.5145443639198532e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.9934508160000000e+09,
      "workspace_megabytes": 4.7621257934570312e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__10673954627667044957<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_1024__10673954627667044957<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__2872450723988025071<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__2872450723988025071<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__2872450723988025071<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__2872450723988025071<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__2872450723988025071<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__2872450723988025071<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__2872450723988025071<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__2872450723988025071<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__15219065505371904877<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 34,
      "real_time": 2.0458977943395868e+07,
      "cpu_time": 2.6497482470586300e+07,
      "time_unit": "ns",
      "items_per_second": 2.0573207330910105e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.0470783233642578e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 3.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.1433018327275264e+12,
      "predicted_advised_flops_count": 1.0522669875200000e+11,
      "predicted_flops": 5.1433018327275264e+12,
      "predicted_flops_count": 1.0522669875200000e+11,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__15219065505371904877<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 39,
      "real_time": 1.7984275777752582e+07,
      "cpu_time": 2.2613602153846376e+07,
      "time_unit": "ns",
      "items_per_second": 2.3404155953206746e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.7922048568725586e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 3.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.8510389883016865e+12,
      "predicted_advised_flops_count": 1.0522669875200000e+11,
      "predicted_flops": 5.8510389883016865e+12,
      "predicted_flops_count": 1.0522669875200000e+11,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__15219065505371904877<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 36,
      "real_time": 1.9545628430528775e+07,
      "cpu_time": 2.4999829222218119e+07,
      "time_unit": "ns",
      "items_per_second": 2.1534574675049887e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.0552089600000000e+08,
      "advised_time": 1.9542015075683594e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 3.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.3836436687624717e+12,
      "predicted_advised_flops_count": 1.0522669875200000e+11,
      "predicted_flops": 5.3836436687624717e+12,
      "predicted_flops_count": 1.0522669875200000e+11,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 2.0552089600000000e+08,
      "workspace_megabytes": 1.9600000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__15219065505371904877<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__15219065505371904877<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__15219065505371904877<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__15219065505371904877<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__15219065505371904877<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__8877859198353515179<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 34,
      "real_time": 2.0411693271906938e+07,
      "cpu_time": 2.6451224058826696e+07,
      "time_unit": "ns",
      "items_per_second": 2.0620866157503125e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.0406272888183594e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 3.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.1552165393757812e+12,
      "predicted_advised_flops_count": 1.0522669875200000e+11,
      "predicted_flops": 5.1552165393757812e+12,
      "predicted_flops_count": 1.0522669875200000e+11,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__8877859198353515179<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 27,
      "real_time": 2.6154325240188174e+07,
      "cpu_time": 3.5873122296291314e+07,
      "time_unit": "ns",
      "items_per_second": 1.6093200307888029e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 2.6136575698852539e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 2.7000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.0233000769720073e+12,
      "predicted_advised_flops_count": 1.0522669875200000e+11,
      "predicted_flops": 4.0233000769720073e+12,
      "predicted_flops_count": 1.0522669875200000e+11,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__8877859198353515179<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 33,
      "real_time": 2.1281574824542709e+07,
      "cpu_time": 2.7764383878794279e+07,
      "time_unit": "ns",
      "items_per_second": 1.9777990984134996e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.1104179200000000e+08,
      "advised_time": 2.1322751998901367e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 3.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.9444977460337490e+12,
      "predicted_advised_flops_count": 1.0522669875200000e+11,
      "predicted_flops": 4.9444977460337490e+12,
      "predicted_flops_count": 1.0522669875200000e+11,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 4.1104179200000000e+08,
      "workspace_megabytes": 3.9200000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__8877859198353515179<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__8877859198353515179<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__8877859198353515179<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5,
      "real_time": 1.5161201059818268e+08,
      "cpu_time": 4.5483431580000800e+08,
      "time_unit": "ns",
      "items_per_second": 2.7762100993669248e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 9.1268300800000000e+09,
      "advised_time": -1.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 5.0000000000000000e+00,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 6.9405252484173120e+11,
      "predicted_advised_flops_count": 1.0522669875200000e+11,
      "predicted_flops": 2.8804775000376875e+12,
      "predicted_flops_count": 4.3671498526354065e+11,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 9.1268300800000000e+09,
      "workspace_megabytes": 8.7040234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__8877859198353515179<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__8877859198353515179<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__12591263391208236878<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 174,
      "real_time": 4.0210657431904613e+06,
      "cpu_time": 4.2729669080491979e+06,
      "time_unit": "ns",
      "items_per_second": 3.2711072596300449e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.0376319885253906e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.7400000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.2711072596300449e+12,
      "predicted_advised_flops_count": 1.3153337344000000e+10,
      "predicted_flops": 3.2711072596300449e+12,
      "predicted_flops_count": 1.3153337344000000e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__12591263391208236878<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 303,
      "real_time": 2.3092787978685042e+06,
      "cpu_time": 2.4016084092407948e+06,
      "time_unit": "ns",
      "items_per_second": 5.6958637285981709e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 2.3142399787902832e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.0300000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.6958637285981709e+12,
      "predicted_advised_flops_count": 1.3153337344000000e+10,
      "predicted_flops": 5.6958637285981709e+12,
      "predicted_flops_count": 1.3153337344000000e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__12591263391208236878<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 114,
      "real_time": 6.1496319943679534e+06,
      "cpu_time": 6.7132050701758824e+06,
      "time_unit": "ns",
      "items_per_second": 2.1388820267694529e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.2208358400000000e+08,
      "advised_time": 6.1552639007568359e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.1400000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.1388820267694529e+12,
      "predicted_advised_flops_count": 1.3153337344000000e+10,
      "predicted_flops": 2.1388820267694529e+12,
      "predicted_flops_count": 1.3153337344000000e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 8.2208358400000000e+08,
      "workspace_megabytes": 7.8400000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__12591263391208236878<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__12591263391208236878<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 41,
      "real_time": 1.7032266935197320e+07,
      "cpu_time": 2.1226983024384603e+07,
      "time_unit": "ns",
      "items_per_second": 7.7225993427912524e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.3531028480000000e+09,
      "advised_time": 1.8068479537963867e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.1000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 7.7225993427912524e+11,
      "predicted_advised_flops_count": 1.3153337344000000e+10,
      "predicted_flops": 1.0613185055772583e+12,
      "predicted_flops_count": 1.8076660090256569e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.3531028480000000e+09,
      "workspace_megabytes": 2.2440937500000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__12591263391208236878<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 63,
      "real_time": 1.1103508254838368e+07,
      "cpu_time": 1.2885003428568635e+07,
      "time_unit": "ns",
      "items_per_second": 1.1846109393639993e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.9970465920000000e+09,
      "advised_time": 1.1591679573059082e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.1846109393639993e+12,
      "predicted_advised_flops_count": 1.3153337344000000e+10,
      "predicted_flops": 1.6280133877848599e+12,
      "predicted_flops_count": 1.8076660090256569e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.9970465920000000e+09,
      "workspace_megabytes": 1.9045320434570312e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__12591263391208236878<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__12591263391208236878<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__3419062712878501989<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 72,
      "real_time": 9.7623893525451422e+06,
      "cpu_time": 1.1135051972220348e+07,
      "time_unit": "ns",
      "items_per_second": 5.3893926451809902e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.7761278152465820e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 7.2000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.3893926451809902e+12,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 5.3893926451809902e+12,
      "predicted_flops_count": 5.2613349376000000e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__3419062712878501989<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 85,
      "real_time": 8.2362608874545377e+06,
      "cpu_time": 9.2194794823532961e+06,
      "time_unit": "ns",
      "items_per_second": 6.3880139416346787e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 8.3005437850952148e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 8.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 6.3880139416346787e+12,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 6.3880139416346787e+12,
      "predicted_flops_count": 5.2613349376000000e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__3419062712878501989<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 59,
      "real_time": 1.1818244279820031e+07,
      "cpu_time": 1.3839273661014462e+07,
      "time_unit": "ns",
      "items_per_second": 4.4518752642335127e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.2208358400000000e+08,
      "advised_time": 1.1899904251098633e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 5.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.4518752642335127e+12,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 4.4518752642335127e+12,
      "predicted_flops_count": 5.2613349376000000e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 8.2208358400000000e+08,
      "workspace_megabytes": 7.8400000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__3419062712878501989<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__3419062712878501989<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 25,
      "real_time": 2.8086722642183304e+07,
      "cpu_time": 3.9334051879995964e+07,
      "time_unit": "ns",
      "items_per_second": 1.8732463038240098e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0209474560000000e+09,
      "advised_time": 2.8571647644042969e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.8732463038240098e+12,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 1.9568257593133523e+12,
      "predicted_flops_count": 5.4960822360913864e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0209474560000000e+09,
      "workspace_megabytes": 2.8810000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__3419062712878501989<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 19,
      "real_time": 3.7592225953152306e+07,
      "cpu_time": 5.7373678526325405e+07,
      "time_unit": "ns",
      "items_per_second": 1.3995805792816611e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5312628800000000e+09,
      "advised_time": 3.8210559844970703e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.3995805792816611e+12,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 1.4620262824927266e+12,
      "predicted_flops_count": 5.4960822360913864e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.5312628800000000e+09,
      "workspace_megabytes": 2.4140003967285156e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__3419062712878501989<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_1024__3419062712878501989<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__8525240284314184685<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 24,
      "real_time": 2.9256064367170136e+07,
      "cpu_time": 4.1601954541668817e+07,
      "time_unit": "ns",
      "items_per_second": 3.3719514983943195e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.9260799407958984e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.5414067200000000e+08,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.2208358400000000e+08,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "predicted_advised_flops": 4.1306405855330415e+12,
      "predicted_advised_flops_count": 1.2084628684800000e+11,
      "predicted_flops": 4.1306405855330415e+12,
      "predicted_flops_count": 1.2084628684800000e+11,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__8525240284314184685<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 34,
      "real_time": 2.0471958772224538e+07,
      "cpu_time": 2.6601670735288963e+07,
      "time_unit": "ns",
      "items_per_second": 4.8187880396595984e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.5272000000000000e+04,
      "advised_time": 2.0471807479858398e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.5414067200000000e+08,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.2208358400000000e+08,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "predicted_advised_flops": 5.9030153485830078e+12,
      "predicted_advised_flops_count": 1.2084628684800000e+11,
      "predicted_flops": 5.9030153485830078e+12,
      "predicted_flops_count": 1.2084628684800000e+11,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 7.5272000000000000e+04,
      "workspace_megabytes": 7.1784973144531250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__8525240284314184685<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 17,
      "real_time": 4.0888500783373326e+07,
      "cpu_time": 6.5159012294122264e+07,
      "time_unit": "ns",
      "items_per_second": 2.4126595054841068e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.5528929280000000e+09,
      "advised_time": -1.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.5414067200000000e+08,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.7000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.2208358400000000e+08,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "predicted_advised_flops": 2.9555078942180308e+12,
      "predicted_advised_flops_count": 1.2084628684800000e+11,
      "predicted_flops": 2.9555078942180308e+12,
      "predicted_flops_count": 1.2084628684800000e+11,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 7.5528929280000000e+09,
      "workspace_megabytes": 7.2030000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__8525240284314184685<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__8525240284314184685<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__8525240284314184685<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 7,
      "real_time": 1.0327303409576416e+08,
      "cpu_time": 2.2565651485714561e+08,
      "time_unit": "ns",
      "items_per_second": 9.5523512932255585e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.9804876800000000e+08,
      "advised_time": 1.0333798217773438e+02,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.5414067200000000e+08,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 7.0000000000000000e+00,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.2208358400000000e+08,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "predicted_advised_flops": 1.1701630334201309e+12,
      "predicted_advised_flops_count": 1.2084628684800000e+11,
      "predicted_flops": 6.1747658358894165e+11,
      "predicted_flops_count": 6.3768680270316734e+10,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 5.9804876800000000e+08,
      "workspace_megabytes": 5.7034375000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__8525240284314184685<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__8525240284314184685<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__12732985189486529861<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 33,
      "real_time": 2.1305747443076335e+07,
      "cpu_time": 2.7786465454541385e+07,
      "time_unit": "ns",
      "items_per_second": 6.1736099046243042e+11,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.1390335083007812e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 6.5867859134428870e+11,
      "predicted_advised_flops_count": 1.4033639713342701e+10,
      "predicted_flops": 5.5562489141618730e+12,
      "predicted_flops_count": 1.1838003609600000e+11,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__12732985189486529861<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 38,
      "real_time": 1.8551942892372608e+07,
      "cpu_time": 2.3466671078945242e+07,
      "time_unit": "ns",
      "items_per_second": 7.0900053004194104e+11,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 1.8431999206542969e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 7.5645121347977258e+11,
      "predicted_advised_flops_count": 1.4033639713342701e+10,
      "predicted_flops": 6.3810047703774697e+12,
      "predicted_flops_count": 1.1838003609600000e+11,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__12732985189486529861<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 28,
      "real_time": 2.4702610115387611e+07,
      "cpu_time": 3.3545300392859191e+07,
      "time_unit": "ns",
      "items_per_second": 5.3246751183619244e+11,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8496880640000000e+09,
      "advised_time": 2.4700927734375000e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 5.6810351812179333e+11,
      "predicted_advised_flops_count": 1.4033639713342701e+10,
      "predicted_flops": 4.7922076065257324e+12,
      "predicted_flops_count": 1.1838003609600000e+11,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8496880640000000e+09,
      "workspace_megabytes": 1.7640000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__12732985189486529861<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__12732985189486529861<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 92,
      "real_time": 7.6221220660954714e+06,
      "cpu_time": 8.4651244891310167e+06,
      "time_unit": "ns",
      "items_per_second": 1.7256791783102424e+12,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.5733401600000000e+08,
      "advised_time": 7.8008317947387695e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 9.2000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 1.8411722603822864e+12,
      "predicted_advised_flops_count": 1.4033639713342701e+10,
      "predicted_flops": 1.8411722603822864e+12,
      "predicted_flops_count": 1.4033639713342701e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.5733401600000000e+08,
      "workspace_megabytes": 7.2225000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__12732985189486529861<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 31,
      "real_time": 2.2308137327913314e+07,
      "cpu_time": 2.9515614999999959e+07,
      "time_unit": "ns",
      "items_per_second": 5.8962060124767725e+11,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5669386240000000e+09,
      "advised_time": 2.2735872268676758e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.1000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 6.2908164438197839e+11,
      "predicted_advised_flops_count": 1.4033639713342701e+10,
      "predicted_flops": 6.2908164438197839e+11,
      "predicted_flops_count": 1.4033639713342701e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.5669386240000000e+09,
      "workspace_megabytes": 2.4480234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__12732985189486529861<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 59,
      "real_time": 1.1862605983801818e+07,
      "cpu_time": 1.3888981966103831e+07,
      "time_unit": "ns",
      "items_per_second": 1.1088067294792268e+12,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.5546240000000000e+06,
      "advised_time": 1.1881471633911133e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnMathType_t math_type = (cudnnMathType_t)0]": 5.7500739770702787e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 5.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 1.1830149068851643e+12,
      "predicted_advised_flops_count": 1.4033639713342701e+10,
      "predicted_flops": -8.4298509228535679e+01,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.5546240000000000e+06,
      "workspace_megabytes": 6.2509765625000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__12732985189486529861<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 84,
      "real_time": 8.3881204814783167e+06,
      "cpu_time": 9.4052752857131902e+06,
      "time_unit": "ns",
      "items_per_second": 1.5680911323393230e+12,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2173967360000000e+09,
      "advised_time": 8.6251516342163086e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.2538945752816425e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 8.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 1.6730374515161257e+12,
      "predicted_advised_flops_count": 1.4033639713342701e+10,
      "predicted_flops": -1.1921621800832321e+02,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.2173967360000000e+09,
      "workspace_megabytes": 1.1610000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__8929759713784515833<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 33,
      "real_time": 2.1271800170793679e+07,
      "cpu_time": 2.7732114636356100e+07,
      "time_unit": "ns",
      "items_per_second": 6.1834622544356250e+11,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.1286912918090820e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 6.3529854301714392e+11,
      "predicted_advised_flops_count": 1.3513943655857056e+10,
      "predicted_flops": 5.5651160289920635e+12,
      "predicted_flops_count": 1.1838003609600000e+11,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__8929759713784515833<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 38,
      "real_time": 1.8631168150980223e+07,
      "cpu_time": 2.3544208605266858e+07,
      "time_unit": "ns",
      "items_per_second": 7.0598564928458215e+11,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.8625535964965820e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 7.2534065209142896e+11,
      "predicted_advised_flops_count": 1.3513943655857056e+10,
      "predicted_flops": 6.3538708435612393e+12,
      "predicted_flops_count": 1.1838003609600000e+11,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__8929759713784515833<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 32,
      "real_time": 2.2179392108228058e+07,
      "cpu_time": 2.9137324875000205e+07,
      "time_unit": "ns",
      "items_per_second": 5.9304318530535413e+11,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 9.2484403200000000e+08,
      "advised_time": 2.2180864334106445e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.2000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 6.0930180547390588e+11,
      "predicted_advised_flops_count": 1.3513943655857056e+10,
      "predicted_flops": 5.3373886677481865e+12,
      "predicted_flops_count": 1.1838003609600000e+11,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 9.2484403200000000e+08,
      "workspace_megabytes": 8.8200000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__8929759713784515833<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__8929759713784515833<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 26,
      "real_time": 2.6653971881247483e+07,
      "cpu_time": 3.6936134384616867e+07,
      "time_unit": "ns",
      "items_per_second": 4.9348507616810712e+11,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8213765120000000e+09,
      "advised_time": 2.6840063095092773e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 5.0701425348785815e+11,
      "predicted_advised_flops_count": 1.3513943655857056e+10,
      "predicted_flops": 5.0701425348785815e+11,
      "predicted_flops_count": 1.3513943655857056e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8213765120000000e+09,
      "workspace_megabytes": 1.7370000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__8929759713784515833<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 9,
      "real_time": 7.8524303105142385e+07,
      "cpu_time": 1.6571394355555135e+08,
      "time_unit": "ns",
      "items_per_second": 1.6750657852242203e+11,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.7042780160000000e+09,
      "advised_time": 7.9164413452148438e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 9.0000000000000000e+00,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 1.7209886775769498e+11,
      "predicted_advised_flops_count": 1.3513943655857056e+10,
      "predicted_flops": 1.7209886775769498e+11,
      "predicted_flops_count": 1.3513943655857056e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.7042780160000000e+09,
      "workspace_megabytes": 5.4400234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__8929759713784515833<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 30,
      "real_time": 2.3369591558972996e+07,
      "cpu_time": 3.1165353466665618e+07,
      "time_unit": "ns",
      "items_per_second": 5.6283984727793164e+11,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.6216448000000000e+07,
      "advised_time": 2.3540735244750977e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnMathType_t math_type = (cudnnMathType_t)0]": 5.7500739770702787e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.0000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 5.7827042555513721e+11,
      "predicted_advised_flops_count": 1.3513943655857056e+10,
      "predicted_flops": -4.2790649441882941e+01,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.6216448000000000e+07,
      "workspace_megabytes": 2.5001953125000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__8929759713784515833<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 98,
      "real_time": 7.1655131914481828e+06,
      "cpu_time": 7.9187869387766924e+06,
      "time_unit": "ns",
      "items_per_second": 1.8356448439308018e+12,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4172851200000000e+08,
      "advised_time": 7.2970237731933594e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.2538945752816425e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 9.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 1.8859701035768838e+12,
      "predicted_advised_flops_count": 1.3513943655857056e+10,
      "predicted_flops": -1.3955734547993978e+02,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.4172851200000000e+08,
      "workspace_megabytes": 6.1200000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__2614859334240452946<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 64,
      "real_time": 1.1011184047674760e+07,
      "cpu_time": 1.2759857421875687e+07,
      "time_unit": "ns",
      "items_per_second": 4.7781736412906836e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1031552314758301e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 6.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.7781736412906836e+12,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 4.7781736412906836e+12,
      "predicted_flops_count": 5.2613349376000000e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__2614859334240452946<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 86,
      "real_time": 8.1992513435178027e+06,
      "cpu_time": 9.1763391860450692e+06,
      "time_unit": "ns",
      "items_per_second": 6.4168479744916318e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 8.1899518966674805e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 8.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 6.4168479744916318e+12,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 6.4168479744916318e+12,
      "predicted_flops_count": 5.2613349376000000e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__2614859334240452946<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 62,
      "real_time": 1.1302697171847666e+07,
      "cpu_time": 1.3155565080651397e+07,
      "time_unit": "ns",
      "items_per_second": 4.6549375406648379e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.0552089600000000e+08,
      "advised_time": 1.1310079574584961e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 6.2000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.6549375406648379e+12,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 4.6549375406648379e+12,
      "predicted_flops_count": 5.2613349376000000e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.0552089600000000e+08,
      "workspace_megabytes": 1.9600000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__2614859334240452946<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__2614859334240452946<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 25,
      "real_time": 2.7857223600149155e+07,
      "cpu_time": 3.9049050760006592e+07,
      "time_unit": "ns",
      "items_per_second": 1.8886788623012056e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4169676800000000e+09,
      "advised_time": 2.7990016937255859e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 2.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.8886788623012056e+12,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 1.9729468790500569e+12,
      "predicted_flops_count": 5.4960822360913864e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.4169676800000000e+09,
      "workspace_megabytes": 2.3050000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__2614859334240452946<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 19,
      "real_time": 3.6257199354861915e+07,
      "cpu_time": 5.5380419631585725e+07,
      "time_unit": "ns",
      "items_per_second": 1.4511145458603882e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5312628800000000e+09,
      "advised_time": 3.6792320251464844e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 1.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.4511145458603882e+12,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 1.5158595627586411e+12,
      "predicted_flops_count": 5.4960822360913864e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.5312628800000000e+09,
      "workspace_megabytes": 2.4140003967285156e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__2614859334240452946<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_1024__2614859334240452946<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__6040395291911947870<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 135,
      "real_time": 5.1960718335100897e+06,
      "cpu_time": 5.5954284740765709e+06,
      "time_unit": "ns",
      "items_per_second": 2.0251201700750250e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.1875839233398438e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.3500000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.0628004251875625e+12,
      "predicted_advised_flops_count": 2.6306674688000000e+10,
      "predicted_flops": 5.0628004251875625e+12,
      "predicted_flops_count": 2.6306674688000000e+10,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__6040395291911947870<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 109,
      "real_time": 6.4007609552883226e+06,
      "cpu_time": 7.0046716055045063e+06,
      "time_unit": "ns",
      "items_per_second": 1.6439717009750453e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 6.4020481109619141e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.0900000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.1099292524376133e+12,
      "predicted_advised_flops_count": 2.6306674688000000e+10,
      "predicted_flops": 4.1099292524376133e+12,
      "predicted_flops_count": 2.6306674688000000e+10,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__6040395291911947870<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 100,
      "real_time": 7.0289510255679488e+06,
      "cpu_time": 7.7482219200021513e+06,
      "time_unit": "ns",
      "items_per_second": 1.4970469757042807e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.1104179200000000e+08,
      "advised_time": 7.0266880989074707e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.0000000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.7426174392607017e+12,
      "predicted_advised_flops_count": 2.6306674688000000e+10,
      "predicted_flops": 3.7426174392607017e+12,
      "predicted_flops_count": 2.6306674688000000e+10,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 4.1104179200000000e+08,
      "workspace_megabytes": 3.9200000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__6040395291911947870<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__6040395291911947870<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__6040395291911947870<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 16,
      "real_time": 4.3139392044395208e+07,
      "cpu_time": 7.0084588250004739e+07,
      "time_unit": "ns",
      "items_per_second": 2.4392253521725591e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.9930019840000000e+09,
      "advised_time": 4.3890689849853516e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 6.0980633804313977e+11,
      "predicted_advised_flops_count": 2.6306674688000000e+10,
      "predicted_flops": 2.5995447936167412e+12,
      "predicted_flops_count": 1.1214278198879903e+11,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.9930019840000000e+09,
      "workspace_megabytes": 3.8080234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__6040395291911947870<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__6040395291911947870<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__2270938613504052066<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 71,
      "real_time": 9.8957917587438095e+06,
      "cpu_time": 1.1310855436625253e+07,
      "time_unit": "ns",
      "items_per_second": 5.3167397474296523e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.9143676757812500e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 7.1000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.3167397474296523e+12,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 5.3167397474296523e+12,
      "predicted_flops_count": 5.2613349376000000e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__2270938613504052066<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 85,
      "real_time": 8.2933760302908281e+06,
      "cpu_time": 9.2889304352946263e+06,
      "time_unit": "ns",
      "items_per_second": 6.3440207201306631e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 8.2923517227172852e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 8.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 6.3440207201306631e+12,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 6.3440207201306631e+12,
      "predicted_flops_count": 5.2613349376000000e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__2270938613504052066<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 49,
      "real_time": 1.4318215793796947e+07,
      "cpu_time": 1.7264573367345765e+07,
      "time_unit": "ns",
      "items_per_second": 3.6745744116242178e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6441671680000000e+09,
      "advised_time": 1.4307328224182129e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 4.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.6745744116242178e+12,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 3.6745744116242178e+12,
      "predicted_flops_count": 5.2613349376000000e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6441671680000000e+09,
      "workspace_megabytes": 1.5680000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__2270938613504052066<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__2270938613504052066<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 24,
      "real_time": 2.9764266607041162e+07,
      "cpu_time": 4.2195202208335541e+07,
      "time_unit": "ns",
      "items_per_second": 1.7676682604218296e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.1340902400000000e+09,
      "advised_time": 3.0557184219360352e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.7676682604218296e+12,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 1.9502383694752332e+12,
      "predicted_flops_count": 5.8047414776342087e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.1340902400000000e+09,
      "workspace_megabytes": 4.8962500000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__2270938613504052066<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 30,
      "real_time": 2.3553228626648586e+07,
      "cpu_time": 3.1420337999988608e+07,
      "time_unit": "ns",
      "items_per_second": 2.2338062526371533e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5045241920000000e+09,
      "advised_time": 2.4356864929199219e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.0000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.2338062526371533e+12,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 2.4645204993537959e+12,
      "predicted_flops_count": 5.8047414776342087e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.5045241920000000e+09,
      "workspace_megabytes": 2.3885003967285156e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__2270938613504052066<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__2270938613504052066<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__10331357586442814541<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 136,
      "real_time": 5.1420084577437267e+06,
      "cpu_time": 5.5360451397047304e+06,
      "time_unit": "ns",
      "items_per_second": 2.0464124012384969e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.1517438888549805e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.3600000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.1160310030962422e+12,
      "predicted_advised_flops_count": 2.6306674688000000e+10,
      "predicted_flops": 5.1160310030962422e+12,
      "predicted_flops_count": 2.6306674688000000e+10,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__10331357586442814541<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 160,
      "real_time": 4.3997695785947144e+06,
      "cpu_time": 4.6903563312515216e+06,
      "time_unit": "ns",
      "items_per_second": 2.3916411273885254e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 4.3786239624023438e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.6000000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.9791028184713135e+12,
      "predicted_advised_flops_count": 2.6306674688000000e+10,
      "predicted_flops": 5.9791028184713135e+12,
      "predicted_flops_count": 2.6306674688000000e+10,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__10331357586442814541<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 116,
      "real_time": 6.0350587631672109e+06,
      "cpu_time": 6.5694437586226538e+06,
      "time_unit": "ns",
      "items_per_second": 1.7435902926780588e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.0552089600000000e+08,
      "advised_time": 6.0416002273559570e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.1600000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.3589757316951470e+12,
      "predicted_advised_flops_count": 2.6306674688000000e+10,
      "predicted_flops": 4.3589757316951470e+12,
      "predicted_flops_count": 2.6306674688000000e+10,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 2.0552089600000000e+08,
      "workspace_megabytes": 1.9600000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__10331357586442814541<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__10331357586442814541<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__10331357586442814541<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5,
      "real_time": 1.5433134138584137e+08,
      "cpu_time": 4.6258982500000918e+08,
      "time_unit": "ns",
      "items_per_second": 6.8182326290370520e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 9.1268300800000000e+09,
      "advised_time": -1.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.0000000000000000e+00,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.7045581572592630e+11,
      "predicted_advised_flops_count": 2.6306674688000000e+10,
      "predicted_flops": 7.0210406880987549e+11,
      "predicted_flops_count": 1.0835666273188516e+11,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 9.1268300800000000e+09,
      "workspace_megabytes": 8.7040234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__10331357586442814541<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__10331357586442814541<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__7179222300116828454<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 68,
      "real_time": 1.0239924673977144e+07,
      "cpu_time": 1.1768568691172900e+07,
      "time_unit": "ns",
      "items_per_second": 5.1380601958632568e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.0236927986145020e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 6.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.1380601958632568e+12,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 5.1380601958632568e+12,
      "predicted_flops_count": 5.2613349376000000e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__7179222300116828454<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 84,
      "real_time": 8.2819657400250435e+06,
      "cpu_time": 9.2897614642818589e+06,
      "time_unit": "ns",
      "items_per_second": 6.3527610506441074e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 8.2677755355834961e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 8.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 6.3527610506441074e+12,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 6.3527610506441074e+12,
      "predicted_flops_count": 5.2613349376000000e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__7179222300116828454<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 68,
      "real_time": 1.0244261226890719e+07,
      "cpu_time": 1.1778713441176713e+07,
      "time_unit": "ns",
      "items_per_second": 5.1358851761698887e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0276044800000000e+08,
      "advised_time": 1.0343423843383789e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 6.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.1358851761698887e+12,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 5.1358851761698887e+12,
      "predicted_flops_count": 5.2613349376000000e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.0276044800000000e+08,
      "workspace_megabytes": 9.8000000000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__7179222300116828454<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__7179222300116828454<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 7,
      "real_time": 1.0264649029288973e+08,
      "cpu_time": 2.4943649671427336e+08,
      "time_unit": "ns",
      "items_per_second": 5.1256842027305536e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.8360325120000000e+09,
      "advised_time": 1.0267238616943359e+02,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 7.0000000000000000e+00,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.1256842027305536e+11,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 5.2240507099845959e+11,
      "predicted_flops_count": 5.3623047049199753e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.8360325120000000e+09,
      "workspace_megabytes": 4.6120000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__7179222300116828454<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 11,
      "real_time": 6.4074193889444523e+07,
      "cpu_time": 1.2240638009091692e+08,
      "time_unit": "ns",
      "items_per_second": 8.2113166287789124e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.6382176320000000e+09,
      "advised_time": 6.4636924743652344e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.1000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 8.2113166287789124e+11,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 8.3688992079592163e+11,
      "predicted_flops_count": 5.3623047049199753e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.6382176320000000e+09,
      "workspace_megabytes": 2.5160003967285156e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__7179222300116828454<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__7179222300116828454<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__7174872035706510278<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 73,
      "real_time": 9.6297801587067246e+06,
      "cpu_time": 1.0962698383560278e+07,
      "time_unit": "ns",
      "items_per_second": 5.4636085672661875e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.7013759613037109e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0276044800000000e+08,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 7.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.4636085672661875e+12,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 5.4636085672661875e+12,
      "predicted_flops_count": 5.2613349376000000e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__7174872035706510278<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 85,
      "real_time": 8.2368511816158015e+06,
      "cpu_time": 9.2180669646997079e+06,
      "time_unit": "ns",
      "items_per_second": 6.3875561444438984e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 8.2913284301757812e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0276044800000000e+08,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 8.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 6.3875561444438984e+12,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 6.3875561444438984e+12,
      "predicted_flops_count": 5.2613349376000000e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__7174872035706510278<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 68,
      "real_time": 1.0276849367929732e+07,
      "cpu_time": 1.1800869441176707e+07,
      "time_unit": "ns",
      "items_per_second": 5.1195991584917959e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.1104179200000000e+08,
      "advised_time": 1.0291199684143066e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0276044800000000e+08,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 6.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.1195991584917959e+12,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 5.1195991584917959e+12,
      "predicted_flops_count": 5.2613349376000000e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.1104179200000000e+08,
      "workspace_megabytes": 3.9200000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__7174872035706510278<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__7174872035706510278<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 7,
      "real_time": 1.0312674726758684e+08,
      "cpu_time": 2.5032736171428791e+08,
      "time_unit": "ns",
      "items_per_second": 5.1018141044904834e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.2519516160000000e+09,
      "advised_time": 1.0335334777832031e+02,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0276044800000000e+08,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 7.0000000000000000e+00,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.1018141044904834e+11,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 5.1997225230096722e+11,
      "predicted_flops_count": 5.3623047049199753e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.2519516160000000e+09,
      "workspace_megabytes": 6.9160000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__7174872035706510278<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 11,
      "real_time": 6.5959563986821607e+07,
      "cpu_time": 1.2589359627273987e+08,
      "time_unit": "ns",
      "items_per_second": 7.9766066049969470e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.6382176320000000e+09,
      "advised_time": 6.6472961425781250e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 1.3448635149818148e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0276044800000000e+08,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.1000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 7.9766066049969470e+11,
      "predicted_advised_flops_count": 5.2613349376000000e+10,
      "predicted_flops": 8.1296848869275989e+11,
      "predicted_flops_count": 5.3623047049199753e+10,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.6382176320000000e+09,
      "workspace_megabytes": 2.5160003967285156e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__7174872035706510278<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__7174872035706510278<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__10788563348464301730<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__10788563348464301730<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__10788563348464301730<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__10788563348464301730<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__10788563348464301730<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__10788563348464301730<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__10788563348464301730<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__10788563348464301730<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__4156363478265467956<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__4156363478265467956<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__4156363478265467956<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__4156363478265467956<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__4156363478265467956<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__4156363478265467956<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__4156363478265467956<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_1024__4156363478265467956<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_1024__9880772936333470776/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 223,
      "real_time": 3.1439553802173100e+06,
      "cpu_time": 3.2993957264590072e+06,
      "time_unit": "ns",
      "items_per_second": 6.5370169466525444e+10,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_op_tensor.cpp": 1.6753608662293881e+19,
      "benchmark_func:void iLAYER_CUDNN_OP_TENSOR_Impl(benchmark::State&) [with T = float; cudnnOpTensorOp_t op_type = (cudnnOpTensorOp_t)0]": 1.4844646694895837e+19,
      "beta": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_OP_TENSOR_Impl": 3.0075642356307840e+18,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_c": 1.0240000000000000e+03,
      "input_h": 1.4000000000000000e+01,
      "input_n": 1.0240000000000000e+03,
      "input_size": 2.0552089600000000e+08,
      "input_w": 1.4000000000000000e+01,
      "num_iterations": 2.2300000000000000e+02,
      "op_type": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_1024__5331348998867133808/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 106,
      "real_time": 6.6318297143674120e+06,
      "cpu_time": 7.2776816509415442e+06,
      "time_unit": "ns",
      "items_per_second": 6.1980148722682922e+10,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_op_tensor.cpp": 1.6753608662293881e+19,
      "benchmark_func:void iLAYER_CUDNN_OP_TENSOR_Impl(benchmark::State&) [with T = float; cudnnOpTensorOp_t op_type = (cudnnOpTensorOp_t)0]": 1.4844646694895837e+19,
      "beta": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_OP_TENSOR_Impl": 3.0075642356307840e+18,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_c": 5.1200000000000000e+02,
      "input_h": 2.8000000000000000e+01,
      "input_n": 1.0240000000000000e+03,
      "input_size": 4.1104179200000000e+08,
      "input_w": 2.8000000000000000e+01,
      "num_iterations": 1.0600000000000000e+02,
      "op_type": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_1024__11725938591777783343/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 453,
      "real_time": 1.5459462060237399e+06,
      "cpu_time": 1.5916997019866041e+06,
      "time_unit": "ns",
      "items_per_second": 6.6470907978296104e+10,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_op_tensor.cpp": 1.6753608662293881e+19,
      "benchmark_func:void iLAYER_CUDNN_OP_TENSOR_Impl(benchmark::State&) [with T = float; cudnnOpTensorOp_t op_type = (cudnnOpTensorOp_t)0]": 1.4844646694895837e+19,
      "beta": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_OP_TENSOR_Impl": 3.0075642356307840e+18,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_c": 2.0480000000000000e+03,
      "input_h": 7.0000000000000000e+00,
      "input_n": 1.0240000000000000e+03,
      "input_size": 1.0276044800000000e+08,
      "input_w": 7.0000000000000000e+00,
      "num_iterations": 4.5300000000000000e+02,
      "op_type": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_1024__8488419327767512188/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:1024/manual_time",
      "iterations": 51,
      "real_time": 1.3818438310979629e+07,
      "cpu_time": 1.6532827666660344e+07,
      "time_unit": "ns",
      "items_per_second": 5.9491786662086288e+10,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_op_tensor.cpp": 1.6753608662293881e+19,
      "benchmark_func:void iLAYER_CUDNN_OP_TENSOR_Impl(benchmark::State&) [with T = float; cudnnOpTensorOp_t op_type = (cudnnOpTensorOp_t)0]": 1.4844646694895837e+19,
      "beta": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_OP_TENSOR_Impl": 3.0075642356307840e+18,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_c": 2.5600000000000000e+02,
      "input_h": 5.6000000000000000e+01,
      "input_n": 1.0240000000000000e+03,
      "input_size": 8.2208358400000000e+08,
      "input_w": 5.6000000000000000e+01,
      "num_iterations": 5.1000000000000000e+01,
      "op_type": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_1024__7807550374400416345<CUDNN_POOLING_MAX>/input[0]:1024/input[1]:64/input[2]:112/input[3]:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:1024/manual_time",
      "iterations": 106,
      "real_time": 6.5764760914838538e+06,
      "cpu_time": 7.2261237358496673e+06,
      "time_unit": "ns",
      "items_per_second": 1.2500366040477962e+11,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_pooling_fwd.cpp": 1.3320989691465509e+19,
      "benchmark_func:void iLAYER_CUDNN_POOLING_FWD_Impl(benchmark::State&) [with T = float; cudnnPoolingMode_t pooling_mode = (cudnnPoolingMode_t)0]": 1.5686689287215342e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_POOLING_FWD_Impl": 1.4645785230092718e+19,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "horizontal_padding": 1.0000000000000000e+00,
      "horizontal_stride": 2.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 8.2208358400000000e+08,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 1.0600000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "pooling_mode": 0.0000000000000000e+00,
      "predicted_flops": 1.2500366040477962e+11,
      "predicted_flops_count": 8.2208358400000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "vertical_padding": 1.0000000000000000e+00,
      "vertical_stride": 2.0000000000000000e+00,
      "window_height": 3.0000000000000000e+00,
      "window_width": 3.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_1024__7807550374400416345<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:1024/input[1]:64/input[2]:112/input[3]:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:1024/manual_time",
      "iterations": 106,
      "real_time": 6.5796443630220760e+06,
      "cpu_time": 7.2292978962234380e+06,
      "time_unit": "ns",
      "items_per_second": 1.2494346785977524e+11,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_pooling_fwd.cpp": 1.3320989691465509e+19,
      "benchmark_func:void iLAYER_CUDNN_POOLING_FWD_Impl(benchmark::State&) [with T = float; cudnnPoolingMode_t pooling_mode = (cudnnPoolingMode_t)3]": 1.5689715143215610e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_POOLING_FWD_Impl": 1.4645785230092718e+19,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "horizontal_padding": 1.0000000000000000e+00,
      "horizontal_stride": 2.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 8.2208358400000000e+08,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 1.0600000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "pooling_mode": 3.0000000000000000e+00,
      "predicted_flops": 1.2494346785977524e+11,
      "predicted_flops_count": 8.2208358400000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "vertical_padding": 1.0000000000000000e+00,
      "vertical_stride": 2.0000000000000000e+00,
      "window_height": 3.0000000000000000e+00,
      "window_width": 3.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 66,
      "real_time": 1.0640818498690020e+07,
      "cpu_time": 1.2267988500005258e+07,
      "time_unit": "ns",
      "items_per_second": 4.9444833010239932e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1006976127624512e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 6.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 66,
      "real_time": 1.0641097712020079e+07,
      "cpu_time": 1.2269026151508996e+07,
      "time_unit": "ns",
      "items_per_second": 4.9443535619984463e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1020288467407227e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 6.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 66,
      "real_time": 1.0641113177619196e+07,
      "cpu_time": 1.2267905848485690e+07,
      "time_unit": "ns",
      "items_per_second": 4.9443463759654805e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.0998784065246582e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 6.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 66,
      "real_time": 1.0641066583268570e+07,
      "cpu_time": 1.2267800863632988e+07,
      "time_unit": "ns",
      "items_per_second": 4.9443680259201035e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1008000373840332e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 6.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 66,
      "real_time": 1.0639639147980647e+07,
      "cpu_time": 1.2267424924233995e+07,
      "time_unit": "ns",
      "items_per_second": 4.9450313722327480e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1005951881408691e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 6.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 85,
      "real_time": 8.1999992513481304e+06,
      "cpu_time": 9.1798583411686849e+06,
      "time_unit": "ns",
      "items_per_second": 6.4162627048228135e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 8.1981439590454102e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 8.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 85,
      "real_time": 8.2008907681002337e+06,
      "cpu_time": 9.1812441058824770e+06,
      "time_unit": "ns",
      "items_per_second": 6.4155651945341143e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 8.2063360214233398e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 8.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 85,
      "real_time": 8.2012763027759157e+06,
      "cpu_time": 9.1803398000004515e+06,
      "time_unit": "ns",
      "items_per_second": 6.4152636045430840e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 8.2001924514770508e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 8.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 85,
      "real_time": 8.1933131331906598e+06,
      "cpu_time": 9.1705887058878932e+06,
      "time_unit": "ns",
      "items_per_second": 6.4214986685747705e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 8.1827840805053711e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 8.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 85,
      "real_time": 8.1994209986399198e+06,
      "cpu_time": 9.1790480352970269e+06,
      "time_unit": "ns",
      "items_per_second": 6.4167152027841045e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 8.2032642364501953e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 8.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 63,
      "real_time": 1.1045546699610967e+07,
      "cpu_time": 1.2813471841266416e+07,
      "time_unit": "ns",
      "items_per_second": 4.7633087620600146e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.0552089600000000e+08,
      "advised_time": 1.1302911758422852e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 6.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.0552089600000000e+08,
      "workspace_megabytes": 1.9600000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 63,
      "real_time": 1.1048553629763542e+07,
      "cpu_time": 1.2816145380938111e+07,
      "time_unit": "ns",
      "items_per_second": 4.7620123990044854e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.0552089600000000e+08,
      "advised_time": 1.1295743942260742e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 6.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.0552089600000000e+08,
      "workspace_megabytes": 1.9600000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 63,
      "real_time": 1.1043433661735248e+07,
      "cpu_time": 1.2812459111113105e+07,
      "time_unit": "ns",
      "items_per_second": 4.7642201680716123e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.0552089600000000e+08,
      "advised_time": 1.1321344375610352e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 6.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.0552089600000000e+08,
      "workspace_megabytes": 1.9600000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 25,
      "real_time": 2.7950366586446762e+07,
      "cpu_time": 3.9136936439999774e+07,
      "time_unit": "ns",
      "items_per_second": 1.8823849488082354e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4169676800000000e+09,
      "advised_time": 2.7988992691040039e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 2.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.4169676800000000e+09,
      "workspace_megabytes": 2.3050000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 25,
      "real_time": 2.7951800152659416e+07,
      "cpu_time": 3.9139361559982717e+07,
      "time_unit": "ns",
      "items_per_second": 1.8822884067806350e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4169676800000000e+09,
      "advised_time": 2.8011520385742188e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 2.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.4169676800000000e+09,
      "workspace_megabytes": 2.3050000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 25,
      "real_time": 2.7952291890978813e+07,
      "cpu_time": 3.9139505440007269e+07,
      "time_unit": "ns",
      "items_per_second": 1.8822552934552095e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4169676800000000e+09,
      "advised_time": 2.8008447647094727e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 2.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.4169676800000000e+09,
      "workspace_megabytes": 2.3050000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 19,
      "real_time": 3.6566554715758875e+07,
      "cpu_time": 5.5807966421076871e+07,
      "time_unit": "ns",
      "items_per_second": 1.4388380252112056e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5312628800000000e+09,
      "advised_time": 3.6779006958007812e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 1.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.5312628800000000e+09,
      "workspace_megabytes": 2.4140003967285156e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 19,
      "real_time": 3.6563644675832048e+07,
      "cpu_time": 5.5800503526322581e+07,
      "time_unit": "ns",
      "items_per_second": 1.4389525399467778e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5312628800000000e+09,
      "advised_time": 3.6780033111572266e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 1.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.5312628800000000e+09,
      "workspace_megabytes": 2.4140003967285156e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 19,
      "real_time": 3.6566339433193207e+07,
      "cpu_time": 5.5804189736848362e+07,
      "time_unit": "ns",
      "items_per_second": 1.4388464963009141e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5312628800000000e+09,
      "advised_time": 3.6765697479248047e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 1.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.5312628800000000e+09,
      "workspace_megabytes": 2.4140003967285156e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_FLOAT32__BatchSize_1024__8105050370632572335<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9447277581003279812<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 34,
      "real_time": 2.0364047082908012e+07,
      "cpu_time": 2.6365789235281974e+07,
      "time_unit": "ns",
      "items_per_second": 2.0669113231489051e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.0481023788452148e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 3.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 34,
      "real_time": 2.0370040636728793e+07,
      "cpu_time": 2.6373793235293038e+07,
      "time_unit": "ns",
      "items_per_second": 2.0663031680411664e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.0488191604614258e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 3.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 34,
      "real_time": 2.0368112798999339e+07,
      "cpu_time": 2.6372365794128761e+07,
      "time_unit": "ns",
      "items_per_second": 2.0664987432153199e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.0464639663696289e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 3.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 34,
      "real_time": 2.0366396371494323e+07,
      "cpu_time": 2.6362807852953717e+07,
      "time_unit": "ns",
      "items_per_second": 2.0666729024144848e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.0449279785156250e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 3.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 34,
      "real_time": 2.0366366130902488e+07,
      "cpu_time": 2.6368983294115450e+07,
      "time_unit": "ns",
      "items_per_second": 2.0666759710724523e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.0441087722778320e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 3.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 39,
      "real_time": 1.7984932288527489e+07,
      "cpu_time": 2.2596845307697177e+07,
      "time_unit": "ns",
      "items_per_second": 2.3403301622463969e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.8007040023803711e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 3.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 39,
      "real_time": 1.7981808632612228e+07,
      "cpu_time": 2.2599844384613693e+07,
      "time_unit": "ns",
      "items_per_second": 2.3407367056761664e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.8081792831420898e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 3.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 39,
      "real_time": 1.8003232824878816e+07,
      "cpu_time": 2.2622500589754496e+07,
      "time_unit": "ns",
      "items_per_second": 2.3379511841136969e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.7997823715209961e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 3.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 39,
      "real_time": 1.7991496393313773e+07,
      "cpu_time": 2.2611685461534321e+07,
      "time_unit": "ns",
      "items_per_second": 2.3394763048415621e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.7946624755859375e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 3.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 39,
      "real_time": 1.7988214173760168e+07,
      "cpu_time": 2.2605888564093664e+07,
      "time_unit": "ns",
      "items_per_second": 2.3399031773925988e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.7971200942993164e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 3.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 36,
      "real_time": 1.9463765383180644e+07,
      "cpu_time": 2.4886698444441259e+07,
      "time_unit": "ns",
      "items_per_second": 2.1625147381385980e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.0552089600000000e+08,
      "advised_time": 1.9513343811035156e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 3.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 2.0552089600000000e+08,
      "workspace_megabytes": 1.9600000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 36,
      "real_time": 1.9468686284704342e+07,
      "cpu_time": 2.4883094166672964e+07,
      "time_unit": "ns",
      "items_per_second": 2.1619681413156637e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.0552089600000000e+08,
      "advised_time": 1.9569664001464844e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 3.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 2.0552089600000000e+08,
      "workspace_megabytes": 1.9600000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 36,
      "real_time": 1.9467689821289644e+07,
      "cpu_time": 2.4886986555552918e+07,
      "time_unit": "ns",
      "items_per_second": 2.1620788027334453e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.0552089600000000e+08,
      "advised_time": 1.9562496185302734e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 3.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 2.0552089600000000e+08,
      "workspace_megabytes": 1.9600000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__8643389688213616710<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 35,
      "real_time": 2.0069814899138041e+07,
      "cpu_time": 2.5815023114280067e+07,
      "time_unit": "ns",
      "items_per_second": 2.0972131388520035e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.0430847167968750e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 3.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 35,
      "real_time": 2.0067035300391059e+07,
      "cpu_time": 2.5808446285710875e+07,
      "time_unit": "ns",
      "items_per_second": 2.0975036357253902e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.0407295227050781e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 3.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 35,
      "real_time": 2.0061974014554705e+07,
      "cpu_time": 2.5804921771431770e+07,
      "time_unit": "ns",
      "items_per_second": 2.0980327992780645e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.0433919906616211e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 3.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 35,
      "real_time": 2.0074233572397914e+07,
      "cpu_time": 2.5820115714285359e+07,
      "time_unit": "ns",
      "items_per_second": 2.0967515072991238e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.0405248641967773e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 3.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 35,
      "real_time": 2.0068673789501190e+07,
      "cpu_time": 2.5814299200000539e+07,
      "time_unit": "ns",
      "items_per_second": 2.0973323868974090e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.0409343719482422e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 3.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 27,
      "real_time": 2.6141847725267764e+07,
      "cpu_time": 3.5827230296292700e+07,
      "time_unit": "ns",
      "items_per_second": 1.6100881599167404e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 2.6194944381713867e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 2.7000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 27,
      "real_time": 2.6144350982374616e+07,
      "cpu_time": 3.5830356407393113e+07,
      "time_unit": "ns",
      "items_per_second": 1.6099339979476143e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 2.6199039459228516e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 2.7000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 27,
      "real_time": 2.6144844031444304e+07,
      "cpu_time": 3.5834040999997407e+07,
      "time_unit": "ns",
      "items_per_second": 1.6099036372210789e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 2.6134527206420898e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 2.7000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 27,
      "real_time": 2.6145110320713785e+07,
      "cpu_time": 3.5836782111122951e+07,
      "time_unit": "ns",
      "items_per_second": 1.6098872402712006e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 2.6089471817016602e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 2.7000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 27,
      "real_time": 2.6125425886776712e+07,
      "cpu_time": 3.5803948148150593e+07,
      "time_unit": "ns",
      "items_per_second": 1.6111002240964057e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 2.6108928680419922e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 2.7000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 32,
      "real_time": 2.1598528081085533e+07,
      "cpu_time": 2.8359201718757275e+07,
      "time_unit": "ns",
      "items_per_second": 1.9487753675983156e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.1104179200000000e+08,
      "advised_time": 2.1307392120361328e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 3.2000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 4.1104179200000000e+08,
      "workspace_megabytes": 3.9200000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 32,
      "real_time": 2.1616927988361567e+07,
      "cpu_time": 2.8383653875007298e+07,
      "time_unit": "ns",
      "items_per_second": 1.9471166080333609e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.1104179200000000e+08,
      "advised_time": 2.1264383316040039e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 3.2000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 4.1104179200000000e+08,
      "workspace_megabytes": 3.9200000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 32,
      "real_time": 2.1608384035062045e+07,
      "cpu_time": 2.8350882656251740e+07,
      "time_unit": "ns",
      "items_per_second": 1.9478864977826715e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.1104179200000000e+08,
      "advised_time": 2.1311487197875977e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 3.2000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 4.1104179200000000e+08,
      "workspace_megabytes": 3.9200000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5,
      "real_time": 1.5159644186496735e+08,
      "cpu_time": 4.5469277499996680e+08,
      "time_unit": "ns",
      "items_per_second": 2.7764952120902515e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 9.1268300800000000e+09,
      "advised_time": -1.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 5.0000000000000000e+00,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 9.1268300800000000e+09,
      "workspace_megabytes": 8.7040234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5,
      "real_time": 1.5160422325134277e+08,
      "cpu_time": 4.5474642620001757e+08,
      "time_unit": "ns",
      "items_per_second": 2.7763527029862739e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 9.1268300800000000e+09,
      "advised_time": -1.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 5.0000000000000000e+00,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 9.1268300800000000e+09,
      "workspace_megabytes": 8.7040234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5,
      "real_time": 1.5159480571746826e+08,
      "cpu_time": 4.5470900659997827e+08,
      "time_unit": "ns",
      "items_per_second": 2.7765251785239692e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 9.1268300800000000e+09,
      "advised_time": -1.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 5.0000000000000000e+00,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 9.1268300800000000e+09,
      "workspace_megabytes": 8.7040234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__16137518650845512064<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 73,
      "real_time": 9.5792254815771151e+06,
      "cpu_time": 1.0906026082189061e+07,
      "time_unit": "ns",
      "items_per_second": 5.4924429409440918e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.6389122009277344e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0276044800000000e+08,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 7.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 73,
      "real_time": 9.5792816033306196e+06,
      "cpu_time": 1.0906422808232006e+07,
      "time_unit": "ns",
      "items_per_second": 5.4924107625885928e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.6348161697387695e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0276044800000000e+08,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 7.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 73,
      "real_time": 9.5778928737934325e+06,
      "cpu_time": 1.0904023410961449e+07,
      "time_unit": "ns",
      "items_per_second": 5.4932071249155547e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.6368637084960938e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0276044800000000e+08,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 7.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 73,
      "real_time": 9.5780191636861190e+06,
      "cpu_time": 1.0905171356177425e+07,
      "time_unit": "ns",
      "items_per_second": 5.4931346948518379e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.6327676773071289e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0276044800000000e+08,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 7.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 73,
      "real_time": 9.5770087169661913e+06,
      "cpu_time": 1.0904511205478217e+07,
      "time_unit": "ns",
      "items_per_second": 5.4937142620317959e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.6512002944946289e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0276044800000000e+08,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 7.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 85,
      "real_time": 8.2357549053781172e+06,
      "cpu_time": 9.2194190352957398e+06,
      "time_unit": "ns",
      "items_per_second": 6.3884064036002822e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 8.2257919311523438e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0276044800000000e+08,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 8.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 85,
      "real_time": 8.2344779087340133e+06,
      "cpu_time": 9.2182365882522650e+06,
      "time_unit": "ns",
      "items_per_second": 6.3893971128630898e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 8.2227201461791992e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0276044800000000e+08,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 8.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 85,
      "real_time": 8.2332611741388543e+06,
      "cpu_time": 9.2166141058923509e+06,
      "time_unit": "ns",
      "items_per_second": 6.3903413560183838e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 8.2165756225585938e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0276044800000000e+08,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 8.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 85,
      "real_time": 8.2296109374831701e+06,
      "cpu_time": 9.2116104352900200e+06,
      "time_unit": "ns",
      "items_per_second": 6.3931757862772715e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 8.2237443923950195e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0276044800000000e+08,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 8.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 85,
      "real_time": 8.2368993912549578e+06,
      "cpu_time": 9.2210319764597118e+06,
      "time_unit": "ns",
      "items_per_second": 6.3875187588012939e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 8.2216958999633789e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0276044800000000e+08,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 8.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 69,
      "real_time": 1.0175042812698994e+07,
      "cpu_time": 1.1667154768118685e+07,
      "time_unit": "ns",
      "items_per_second": 5.1708233905744111e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.1104179200000000e+08,
      "advised_time": 1.0289152145385742e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0276044800000000e+08,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 6.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.1104179200000000e+08,
      "workspace_megabytes": 3.9200000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 69,
      "real_time": 1.0190105970031109e+07,
      "cpu_time": 1.1672991507246980e+07,
      "time_unit": "ns",
      "items_per_second": 5.1631798070338789e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.1104179200000000e+08,
      "advised_time": 1.0274815559387207e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0276044800000000e+08,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 6.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.1104179200000000e+08,
      "workspace_megabytes": 3.9200000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 69,
      "real_time": 1.0181913597752219e+07,
      "cpu_time": 1.1669269536225224e+07,
      "time_unit": "ns",
      "items_per_second": 5.1673341038383037e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.1104179200000000e+08,
      "advised_time": 1.0262528419494629e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0276044800000000e+08,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 6.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.1104179200000000e+08,
      "workspace_megabytes": 3.9200000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 7,
      "real_time": 1.0314181553465979e+08,
      "cpu_time": 2.5045593500002334e+08,
      "time_unit": "ns",
      "items_per_second": 5.1010687666555377e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.2519516160000000e+09,
      "advised_time": 1.0318950653076172e+02,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0276044800000000e+08,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 7.0000000000000000e+00,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.2519516160000000e+09,
      "workspace_megabytes": 6.9160000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 7,
      "real_time": 1.0314942151308060e+08,
      "cpu_time": 2.5041175057143456e+08,
      "time_unit": "ns",
      "items_per_second": 5.1006926266986371e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.2519516160000000e+09,
      "advised_time": 1.0317619323730469e+02,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0276044800000000e+08,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 7.0000000000000000e+00,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.2519516160000000e+09,
      "workspace_megabytes": 6.9160000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 7,
      "real_time": 1.0312440778527941e+08,
      "cpu_time": 2.5041824128571275e+08,
      "time_unit": "ns",
      "items_per_second": 5.1019298443438275e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.2519516160000000e+09,
      "advised_time": 1.0343936157226562e+02,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0276044800000000e+08,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 7.0000000000000000e+00,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.2519516160000000e+09,
      "workspace_megabytes": 6.9160000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 11,
      "real_time": 6.6117164086211808e+07,
      "cpu_time": 1.2619853081818375e+08,
      "time_unit": "ns",
      "items_per_second": 7.9575931761677112e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.6382176320000000e+09,
      "advised_time": 6.6473983764648438e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0276044800000000e+08,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.1000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.6382176320000000e+09,
      "workspace_megabytes": 2.5160003967285156e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 11,
      "real_time": 6.6123961725018241e+07,
      "cpu_time": 1.2619860227273835e+08,
      "time_unit": "ns",
      "items_per_second": 7.9567751240914453e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.6382176320000000e+09,
      "advised_time": 6.6496513366699219e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0276044800000000e+08,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.1000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.6382176320000000e+09,
      "workspace_megabytes": 2.5160003967285156e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 11,
      "real_time": 6.6122006963599809e+07,
      "cpu_time": 1.2619602590910457e+08,
      "time_unit": "ns",
      "items_per_second": 7.9570103498164636e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.6382176320000000e+09,
      "advised_time": 6.6478080749511719e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0276044800000000e+08,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.1000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.6382176320000000e+09,
      "workspace_megabytes": 2.5160003967285156e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_FLOAT32__BatchSize_1024__9728247162349781871<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 24,
      "real_time": 2.9760511824861169e+07,
      "cpu_time": 4.2167161749953642e+07,
      "time_unit": "ns",
      "items_per_second": 3.3147961520470319e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.9247488021850586e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.5414067200000000e+08,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.2208358400000000e+08,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 24,
      "real_time": 2.9769898857921362e+07,
      "cpu_time": 4.2179237166682996e+07,
      "time_unit": "ns",
      "items_per_second": 3.3137509317990369e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.9251583099365234e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.5414067200000000e+08,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.2208358400000000e+08,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 23,
      "real_time": 2.9753522056600321e+07,
      "cpu_time": 4.2693477173938647e+07,
      "time_unit": "ns",
      "items_per_second": 3.3155748718534027e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.9236223220825195e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.5414067200000000e+08,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.2208358400000000e+08,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 24,
      "real_time": 2.9765333359440167e+07,
      "cpu_time": 4.2172421416675359e+07,
      "time_unit": "ns",
      "items_per_second": 3.3142592051203363e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.9247488021850586e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.5414067200000000e+08,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.2208358400000000e+08,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 24,
      "real_time": 2.9791700498511393e+07,
      "cpu_time": 4.2211179916658163e+07,
      "time_unit": "ns",
      "items_per_second": 3.3113259206176990e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.9268991470336914e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.5414067200000000e+08,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.2208358400000000e+08,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 34,
      "real_time": 2.0468735957846921e+07,
      "cpu_time": 2.6491986764700841e+07,
      "time_unit": "ns",
      "items_per_second": 4.8195467606382111e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.5272000000000000e+04,
      "advised_time": 2.0468736648559570e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.5414067200000000e+08,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.2208358400000000e+08,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 7.5272000000000000e+04,
      "workspace_megabytes": 7.1784973144531250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 34,
      "real_time": 2.0465904901571132e+07,
      "cpu_time": 2.6488198882381823e+07,
      "time_unit": "ns",
      "items_per_second": 4.8202134503432977e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.5272000000000000e+04,
      "advised_time": 2.0466688156127930e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.5414067200000000e+08,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.2208358400000000e+08,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 7.5272000000000000e+04,
      "workspace_megabytes": 7.1784973144531250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 34,
      "real_time": 2.0470121491919547e+07,
      "cpu_time": 2.6493577294124458e+07,
      "time_unit": "ns",
      "items_per_second": 4.8192205463431903e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.5272000000000000e+04,
      "advised_time": 2.0466688156127930e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.5414067200000000e+08,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.2208358400000000e+08,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 7.5272000000000000e+04,
      "workspace_megabytes": 7.1784973144531250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 34,
      "real_time": 2.0469127661165070e+07,
      "cpu_time": 2.6491751970585190e+07,
      "time_unit": "ns",
      "items_per_second": 4.8194545323571936e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.5272000000000000e+04,
      "advised_time": 2.0470783233642578e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.5414067200000000e+08,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.2208358400000000e+08,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 7.5272000000000000e+04,
      "workspace_megabytes": 7.1784973144531250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 34,
      "real_time": 2.0469308337744545e+07,
      "cpu_time": 2.6492736764693934e+07,
      "time_unit": "ns",
      "items_per_second": 4.8194119924459534e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.5272000000000000e+04,
      "advised_time": 2.0466688156127930e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.5414067200000000e+08,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.2208358400000000e+08,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 7.5272000000000000e+04,
      "workspace_megabytes": 7.1784973144531250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to perform cudnnFindConvolutionForwardAlgorithm",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to perform cudnnFindConvolutionForwardAlgorithm",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to perform cudnnFindConvolutionForwardAlgorithm",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 7,
      "real_time": 1.0355156340769359e+08,
      "cpu_time": 2.2624210385720292e+08,
      "time_unit": "ns",
      "items_per_second": 9.5266577184937592e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.9804876800000000e+08,
      "advised_time": 1.0352845001220703e+02,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.5414067200000000e+08,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 7.0000000000000000e+00,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.2208358400000000e+08,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 5.9804876800000000e+08,
      "workspace_megabytes": 5.7034375000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 7,
      "real_time": 1.0362061006682260e+08,
      "cpu_time": 2.2638824499988785e+08,
      "time_unit": "ns",
      "items_per_second": 9.5203097160287720e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.9804876800000000e+08,
      "advised_time": 1.0345983886718750e+02,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.5414067200000000e+08,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 7.0000000000000000e+00,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.2208358400000000e+08,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 5.9804876800000000e+08,
      "workspace_megabytes": 5.7034375000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 7,
      "real_time": 1.0347680853945868e+08,
      "cpu_time": 2.2614166228572685e+08,
      "time_unit": "ns",
      "items_per_second": 9.5335400726416779e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.9804876800000000e+08,
      "advised_time": 1.0355916595458984e+02,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.5414067200000000e+08,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 7.0000000000000000e+00,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.2208358400000000e+08,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 5.9804876800000000e+08,
      "workspace_megabytes": 5.7034375000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3511873498779961824<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 72,
      "real_time": 9.7892978228628635e+06,
      "cpu_time": 1.1164680416691732e+07,
      "time_unit": "ns",
      "items_per_second": 5.3745784762132529e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.9010562896728516e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 7.2000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 71,
      "real_time": 9.7927274707127623e+06,
      "cpu_time": 1.1187727873249687e+07,
      "time_unit": "ns",
      "items_per_second": 5.3726961700252998e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.9153919219970703e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 7.1000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 72,
      "real_time": 9.7821296917067636e+06,
      "cpu_time": 1.1154311124998786e+07,
      "time_unit": "ns",
      "items_per_second": 5.3785168500275879e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.8928642272949219e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 7.2000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 71,
      "real_time": 9.7778154353440646e+06,
      "cpu_time": 1.1166726915487897e+07,
      "time_unit": "ns",
      "items_per_second": 5.3808900079886426e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.8744316101074219e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 7.1000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 72,
      "real_time": 9.7931946834756266e+06,
      "cpu_time": 1.1168261499979811e+07,
      "time_unit": "ns",
      "items_per_second": 5.3724398499680801e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.8662395477294922e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 7.2000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 84,
      "real_time": 8.2917180954523031e+06,
      "cpu_time": 9.2936333452479672e+06,
      "time_unit": "ns",
      "items_per_second": 6.3452892115153379e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 8.2831363677978516e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 8.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 84,
      "real_time": 8.2923642004884426e+06,
      "cpu_time": 9.2950381428522635e+06,
      "time_unit": "ns",
      "items_per_second": 6.3447948141135596e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 8.2984962463378906e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 8.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 84,
      "real_time": 8.2838065434424654e+06,
      "cpu_time": 9.2832362499956656e+06,
      "time_unit": "ns",
      "items_per_second": 6.3513493585444961e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 8.3517436981201172e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 8.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 84,
      "real_time": 8.2922788514267830e+06,
      "cpu_time": 9.2930298214192968e+06,
      "time_unit": "ns",
      "items_per_second": 6.3448601185122061e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 8.3558397293090820e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 8.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 84,
      "real_time": 8.2882682216309365e+06,
      "cpu_time": 9.2860446190484036e+06,
      "time_unit": "ns",
      "items_per_second": 6.3479303479451016e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 8.3599357604980469e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 8.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 49,
      "real_time": 1.4371254861506881e+07,
      "cpu_time": 1.7314983959179197e+07,
      "time_unit": "ns",
      "items_per_second": 3.6610128957439761e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6441671680000000e+09,
      "advised_time": 1.4382080078125000e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 4.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6441671680000000e+09,
      "workspace_megabytes": 1.5680000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 49,
      "real_time": 1.4377085358968804e+07,
      "cpu_time": 1.7326200693898909e+07,
      "time_unit": "ns",
      "items_per_second": 3.6595282049416514e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6441671680000000e+09,
      "advised_time": 1.4399488449096680e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 4.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6441671680000000e+09,
      "workspace_megabytes": 1.5680000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 49,
      "real_time": 1.4373052105003474e+07,
      "cpu_time": 1.7317535285702452e+07,
      "time_unit": "ns",
      "items_per_second": 3.6605551132514512e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6441671680000000e+09,
      "advised_time": 1.4334976196289062e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 4.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6441671680000000e+09,
      "workspace_megabytes": 1.5680000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 24,
      "real_time": 2.9769301181659102e+07,
      "cpu_time": 4.2186133791678533e+07,
      "time_unit": "ns",
      "items_per_second": 1.7673693129355398e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.1340902400000000e+09,
      "advised_time": 2.9799423217773438e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.1340902400000000e+09,
      "workspace_megabytes": 4.8962500000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 24,
      "real_time": 2.9769514609749120e+07,
      "cpu_time": 4.2186502291656323e+07,
      "time_unit": "ns",
      "items_per_second": 1.7673566420451421e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.1340902400000000e+09,
      "advised_time": 2.9772800445556641e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.1340902400000000e+09,
      "workspace_megabytes": 4.8962500000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 24,
      "real_time": 2.9767936017985146e+07,
      "cpu_time": 4.2188018125007905e+07,
      "time_unit": "ns",
      "items_per_second": 1.7674503648560703e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.1340902400000000e+09,
      "advised_time": 2.9826047897338867e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.1340902400000000e+09,
      "workspace_megabytes": 4.8962500000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 30,
      "real_time": 2.3635933858652908e+07,
      "cpu_time": 3.1514907333303202e+07,
      "time_unit": "ns",
      "items_per_second": 2.2259898716351631e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5045241920000000e+09,
      "advised_time": 2.3728128433227539e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.0000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.5045241920000000e+09,
      "workspace_megabytes": 2.3885003967285156e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 30,
      "real_time": 2.3634397735198338e+07,
      "cpu_time": 3.1515411133364070e+07,
      "time_unit": "ns",
      "items_per_second": 2.2261345503906689e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5045241920000000e+09,
      "advised_time": 2.3741439819335938e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.0000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.5045241920000000e+09,
      "workspace_megabytes": 2.3885003967285156e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 30,
      "real_time": 2.3631940347452957e+07,
      "cpu_time": 3.1509070500002660e+07,
      "time_unit": "ns",
      "items_per_second": 2.2263660369162471e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5045241920000000e+09,
      "advised_time": 2.3752704620361328e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.0000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.5045241920000000e+09,
      "workspace_megabytes": 2.3885003967285156e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11633884600602448754<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 137,
      "real_time": 5.1198803962473450e+06,
      "cpu_time": 5.5102063722792296e+06,
      "time_unit": "ns",
      "items_per_second": 2.0552569710246883e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.1230721473693848e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.3700000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 137,
      "real_time": 5.1226238040321497e+06,
      "cpu_time": 5.5122945547511177e+06,
      "time_unit": "ns",
      "items_per_second": 2.0541562835274637e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.1496958732604980e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.3700000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 137,
      "real_time": 5.1205979734931113e+06,
      "cpu_time": 5.5110992773628104e+06,
      "time_unit": "ns",
      "items_per_second": 2.0549689566864715e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.1445760726928711e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.3700000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 137,
      "real_time": 5.1092816462373212e+06,
      "cpu_time": 5.4944735401457464e+06,
      "time_unit": "ns",
      "items_per_second": 2.0595204186775090e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.1343359947204590e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.3700000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 137,
      "real_time": 5.1094983928721314e+06,
      "cpu_time": 5.4937285109475730e+06,
      "time_unit": "ns",
      "items_per_second": 2.0594330531308840e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.1517438888549805e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.3700000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 159,
      "real_time": 4.4006105957541075e+06,
      "cpu_time": 4.6914218364605093e+06,
      "time_unit": "ns",
      "items_per_second": 2.3911840519024133e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 4.4257278442382812e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.5900000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 159,
      "real_time": 4.4014997569457544e+06,
      "cpu_time": 4.6932518113187924e+06,
      "time_unit": "ns",
      "items_per_second": 2.3907010010837281e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 4.4308481216430664e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.5900000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 159,
      "real_time": 4.4023307514781095e+06,
      "cpu_time": 4.6945254842788437e+06,
      "time_unit": "ns",
      "items_per_second": 2.3902497266174172e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 4.4113922119140625e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.5900000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 159,
      "real_time": 4.4046812427212605e+06,
      "cpu_time": 4.6977814528340874e+06,
      "time_unit": "ns",
      "items_per_second": 2.3889742061559438e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 4.3837437629699707e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.5900000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 159,
      "real_time": 4.3913241499250038e+06,
      "cpu_time": 4.6791218050225470e+06,
      "time_unit": "ns",
      "items_per_second": 2.3962407501572637e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 4.3929600715637207e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.5900000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 116,
      "real_time": 6.0165122769580316e+06,
      "cpu_time": 6.5513582758657755e+06,
      "time_unit": "ns",
      "items_per_second": 1.7489650799017893e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.0552089600000000e+08,
      "advised_time": 6.0293121337890625e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.1600000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 2.0552089600000000e+08,
      "workspace_megabytes": 1.9600000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 116,
      "real_time": 6.0180832896831222e+06,
      "cpu_time": 6.5523183103374355e+06,
      "time_unit": "ns",
      "items_per_second": 1.7485085148687039e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.0552089600000000e+08,
      "advised_time": 6.0600318908691406e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.1600000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 2.0552089600000000e+08,
      "workspace_megabytes": 1.9600000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 116,
      "real_time": 6.0173770822263481e+06,
      "cpu_time": 6.5529662069017272e+06,
      "time_unit": "ns",
      "items_per_second": 1.7487137221765656e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.0552089600000000e+08,
      "advised_time": 6.0375041961669922e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.1600000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 2.0552089600000000e+08,
      "workspace_megabytes": 1.9600000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5,
      "real_time": 1.5402782857418060e+08,
      "cpu_time": 4.6228580360002530e+08,
      "time_unit": "ns",
      "items_per_second": 6.8316679996123083e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 9.1268300800000000e+09,
      "advised_time": -1.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.0000000000000000e+00,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 9.1268300800000000e+09,
      "workspace_megabytes": 8.7040234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5,
      "real_time": 1.5405997931957245e+08,
      "cpu_time": 4.6221783700002563e+08,
      "time_unit": "ns",
      "items_per_second": 6.8302423002228418e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 9.1268300800000000e+09,
      "advised_time": -1.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.0000000000000000e+00,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 9.1268300800000000e+09,
      "workspace_megabytes": 8.7040234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5,
      "real_time": 1.5404625833034515e+08,
      "cpu_time": 4.6208553540004683e+08,
      "time_unit": "ns",
      "items_per_second": 6.8308506738505884e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 9.1268300800000000e+09,
      "advised_time": -1.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.0000000000000000e+00,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 9.1268300800000000e+09,
      "workspace_megabytes": 8.7040234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__3571486688550935645<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 33,
      "real_time": 2.1136104834802222e+07,
      "cpu_time": 2.7549752515135352e+07,
      "time_unit": "ns",
      "items_per_second": 6.2231605335066370e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.1303295135498047e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 33,
      "real_time": 2.1130115922653314e+07,
      "cpu_time": 2.7543896787854079e+07,
      "time_unit": "ns",
      "items_per_second": 6.2249243648959277e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.1312511444091797e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 33,
      "real_time": 2.1129309058640942e+07,
      "cpu_time": 2.7542076151541658e+07,
      "time_unit": "ns",
      "items_per_second": 6.2251620758137732e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.1328895568847656e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 33,
      "real_time": 2.1130115866209522e+07,
      "cpu_time": 2.7542056363637872e+07,
      "time_unit": "ns",
      "items_per_second": 6.2249243815242480e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.1303295135498047e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 33,
      "real_time": 2.1131295089920361e+07,
      "cpu_time": 2.7547143090907522e+07,
      "time_unit": "ns",
      "items_per_second": 6.2245770020381519e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.1308416366577148e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 38,
      "real_time": 1.8480046211104643e+07,
      "cpu_time": 2.3352082289474502e+07,
      "time_unit": "ns",
      "items_per_second": 7.1175889896293494e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 1.8478080749511719e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 38,
      "real_time": 1.8480289629415464e+07,
      "cpu_time": 2.3351883473675404e+07,
      "time_unit": "ns",
      "items_per_second": 7.1174952383124768e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 1.8475008010864258e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 38,
      "real_time": 1.8479077145457268e+07,
      "cpu_time": 2.3350877578967523e+07,
      "time_unit": "ns",
      "items_per_second": 7.1179622447939722e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 1.8477056503295898e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 38,
      "real_time": 1.8479077096440289e+07,
      "cpu_time": 2.3351612789485302e+07,
      "time_unit": "ns",
      "items_per_second": 7.1179622636748389e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 1.8477056503295898e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 38,
      "real_time": 1.8479400167339727e+07,
      "cpu_time": 2.3352266210520755e+07,
      "time_unit": "ns",
      "items_per_second": 7.1178378220560718e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 1.8481151580810547e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 25,
      "real_time": 2.7942666485905647e+07,
      "cpu_time": 3.9130290560005963e+07,
      "time_unit": "ns",
      "items_per_second": 4.7072591839560400e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.6993761280000000e+09,
      "advised_time": 2.8059648513793945e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.6993761280000000e+09,
      "workspace_megabytes": 3.5280000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 25,
      "real_time": 2.7939225584268570e+07,
      "cpu_time": 3.9121938400012366e+07,
      "time_unit": "ns",
      "items_per_second": 4.7078389142632874e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.6993761280000000e+09,
      "advised_time": 2.8061695098876953e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.6993761280000000e+09,
      "workspace_megabytes": 3.5280000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 25,
      "real_time": 2.7943935841321945e+07,
      "cpu_time": 3.9131249239990212e+07,
      "time_unit": "ns",
      "items_per_second": 4.7070453563486835e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.6993761280000000e+09,
      "advised_time": 2.8063743591308594e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.6993761280000000e+09,
      "workspace_megabytes": 3.5280000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 82,
      "real_time": 8.5531097450634334e+06,
      "cpu_time": 9.6126383048740756e+06,
      "time_unit": "ns",
      "items_per_second": 1.5378426953531917e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2840468480000000e+09,
      "advised_time": 8.8586244583129883e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 8.2000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.2840468480000000e+09,
      "workspace_megabytes": 1.2245625000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 82,
      "real_time": 8.5530473578085266e+06,
      "cpu_time": 9.6115339024436250e+06,
      "time_unit": "ns",
      "items_per_second": 1.5378539126164932e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2840468480000000e+09,
      "advised_time": 8.8668155670166016e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 8.2000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.2840468480000000e+09,
      "workspace_megabytes": 1.2245625000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 82,
      "real_time": 8.5541837757862192e+06,
      "cpu_time": 9.6128203658348117e+06,
      "time_unit": "ns",
      "items_per_second": 1.5376496096836626e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2840468480000000e+09,
      "advised_time": 8.8668155670166016e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 8.2000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.2840468480000000e+09,
      "workspace_megabytes": 1.2245625000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 95,
      "real_time": 7.4006420413130205e+06,
      "cpu_time": 8.1918990842065169e+06,
      "time_unit": "ns",
      "items_per_second": 1.7773238146870750e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2121784320000000e+09,
      "advised_time": 7.7250561714172363e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 9.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.2121784320000000e+09,
      "workspace_megabytes": 1.1560234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 95,
      "real_time": 7.3998116888105869e+06,
      "cpu_time": 8.1913971578902230e+06,
      "time_unit": "ns",
      "items_per_second": 1.7775232529078330e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2121784320000000e+09,
      "advised_time": 7.7527041435241699e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 9.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.2121784320000000e+09,
      "workspace_megabytes": 1.1560234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 95,
      "real_time": 7.4050614022110635e+06,
      "cpu_time": 8.1981644631588627e+06,
      "time_unit": "ns",
      "items_per_second": 1.7762631029734026e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2121784320000000e+09,
      "advised_time": 7.7168641090393066e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 9.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.2121784320000000e+09,
      "workspace_megabytes": 1.1560234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 57,
      "real_time": 1.2299246105708575e+07,
      "cpu_time": 1.4467931298249345e+07,
      "time_unit": "ns",
      "items_per_second": 1.0694425683453076e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6389120000000000e+06,
      "advised_time": 1.2336128234863281e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.1941256922983490e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 5.7000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6389120000000000e+06,
      "workspace_megabytes": 1.5629882812500000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 57,
      "real_time": 1.2283814188681150e+07,
      "cpu_time": 1.4449018877198078e+07,
      "time_unit": "ns",
      "items_per_second": 1.0707860882591392e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6389120000000000e+06,
      "advised_time": 1.2341247558593750e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.1941256922983490e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 5.7000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6389120000000000e+06,
      "workspace_megabytes": 1.5629882812500000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 57,
      "real_time": 1.2302407847815439e+07,
      "cpu_time": 1.4473618508789418e+07,
      "time_unit": "ns",
      "items_per_second": 1.0691677195806561e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6389120000000000e+06,
      "advised_time": 1.2338175773620605e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.1941256922983490e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 5.7000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6389120000000000e+06,
      "workspace_megabytes": 1.5629882812500000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 77,
      "real_time": 9.0600726884100344e+06,
      "cpu_time": 1.0252279961008895e+07,
      "time_unit": "ns",
      "items_per_second": 1.4517915911233489e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8520473600000000e+09,
      "advised_time": 9.5180797576904297e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.0444073425867530e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 7.7000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8520473600000000e+09,
      "workspace_megabytes": 1.7662500000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 77,
      "real_time": 9.0556575541759469e+06,
      "cpu_time": 1.0245081792207841e+07,
      "time_unit": "ns",
      "items_per_second": 1.4524994198719937e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8520473600000000e+09,
      "advised_time": 9.5457277297973633e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.0444073425867530e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 7.7000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8520473600000000e+09,
      "workspace_megabytes": 1.7662500000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 77,
      "real_time": 9.0514685015206207e+06,
      "cpu_time": 1.0238658766237170e+07,
      "time_unit": "ns",
      "items_per_second": 1.4531716419043250e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 5.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8520473600000000e+09,
      "advised_time": 9.5508480072021484e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.0444073425867530e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 7.7000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8520473600000000e+09,
      "workspace_megabytes": 1.7662500000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__11407193061016732844<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 33,
      "real_time": 2.1204123104160484e+07,
      "cpu_time": 2.7637822484869257e+07,
      "time_unit": "ns",
      "items_per_second": 6.2031979721053259e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.1256191253662109e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 33,
      "real_time": 2.1203316409479488e+07,
      "cpu_time": 2.7636769939376928e+07,
      "time_unit": "ns",
      "items_per_second": 6.2034339770166626e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.1285888671875000e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 33,
      "real_time": 2.1192455551389493e+07,
      "cpu_time": 2.7620117636360824e+07,
      "time_unit": "ns",
      "items_per_second": 6.2066131563209045e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.1263359069824219e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 33,
      "real_time": 2.1208994880770192e+07,
      "cpu_time": 2.7644876696995471e+07,
      "time_unit": "ns",
      "items_per_second": 6.2017730769155359e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.1301248550415039e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 33,
      "real_time": 2.1195589931625307e+07,
      "cpu_time": 2.7624663757595759e+07,
      "time_unit": "ns",
      "items_per_second": 6.2056953292789917e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.1250047683715820e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 38,
      "real_time": 1.8605891566135380e+07,
      "cpu_time": 2.3508037657901887e+07,
      "time_unit": "ns",
      "items_per_second": 7.0694474904607178e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.8610176086425781e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 38,
      "real_time": 1.8610552737587377e+07,
      "cpu_time": 2.3512972447358485e+07,
      "time_unit": "ns",
      "items_per_second": 7.0676768871213892e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.8625535964965820e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 38,
      "real_time": 1.8626452325598191e+07,
      "cpu_time": 2.3536357684209082e+07,
      "time_unit": "ns",
      "items_per_second": 7.0616438998012891e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.8623487472534180e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 38,
      "real_time": 1.8626452129530281e+07,
      "cpu_time": 2.3530310921034325e+07,
      "time_unit": "ns",
      "items_per_second": 7.0616439741343811e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.8699264526367188e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 38,
      "real_time": 1.8631976489958011e+07,
      "cpu_time": 2.3538487710538901e+07,
      "time_unit": "ns",
      "items_per_second": 7.0595502045041724e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.8696191787719727e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 31,
      "real_time": 2.2356133066838786e+07,
      "cpu_time": 2.9565844903250001e+07,
      "time_unit": "ns",
      "items_per_second": 5.8835476174144617e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 9.2484403200000000e+08,
      "advised_time": 2.2268928527832031e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.1000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 9.2484403200000000e+08,
      "workspace_megabytes": 8.8200000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 31,
      "real_time": 2.2373739329557266e+07,
      "cpu_time": 2.9594462935480598e+07,
      "time_unit": "ns",
      "items_per_second": 5.8789177572224268e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 9.2484403200000000e+08,
      "advised_time": 2.2239231109619141e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.1000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 9.2484403200000000e+08,
      "workspace_megabytes": 8.8200000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 31,
      "real_time": 2.2351508659701195e+07,
      "cpu_time": 2.9565082709664680e+07,
      "time_unit": "ns",
      "items_per_second": 5.8847648918280408e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 9.2484403200000000e+08,
      "advised_time": 2.2205440521240234e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.1000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 9.2484403200000000e+08,
      "workspace_megabytes": 8.8200000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 26,
      "real_time": 2.6677838741586760e+07,
      "cpu_time": 3.6941423615355864e+07,
      "time_unit": "ns",
      "items_per_second": 4.9304358840343073e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8213765120000000e+09,
      "advised_time": 2.6934272766113281e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8213765120000000e+09,
      "workspace_megabytes": 1.7370000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 26,
      "real_time": 2.6664841848497208e+07,
      "cpu_time": 3.6921793923082843e+07,
      "time_unit": "ns",
      "items_per_second": 4.9328390615379944e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8213765120000000e+09,
      "advised_time": 2.6928127288818359e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8213765120000000e+09,
      "workspace_megabytes": 1.7370000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 26,
      "real_time": 2.6677445007058289e+07,
      "cpu_time": 3.6946534461540416e+07,
      "time_unit": "ns",
      "items_per_second": 4.9305086527288892e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8213765120000000e+09,
      "advised_time": 2.6838016510009766e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8213765120000000e+09,
      "workspace_megabytes": 1.7370000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 9,
      "real_time": 7.8525325490368739e+07,
      "cpu_time": 1.6581626611110148e+08,
      "time_unit": "ns",
      "items_per_second": 1.6750439761772498e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.7042780160000000e+09,
      "advised_time": 7.8635009765625000e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 9.0000000000000000e+00,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.7042780160000000e+09,
      "workspace_megabytes": 5.4400234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 9,
      "real_time": 7.8532723916901484e+07,
      "cpu_time": 1.6583214999999049e+08,
      "time_unit": "ns",
      "items_per_second": 1.6748861732999426e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.7042780160000000e+09,
      "advised_time": 7.8573570251464844e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 9.0000000000000000e+00,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.7042780160000000e+09,
      "workspace_megabytes": 5.4400234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 9,
      "real_time": 7.8540458447403371e+07,
      "cpu_time": 1.6586873755555743e+08,
      "time_unit": "ns",
      "items_per_second": 1.6747212333638806e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.7042780160000000e+09,
      "advised_time": 7.8578689575195312e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 9.0000000000000000e+00,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.7042780160000000e+09,
      "workspace_megabytes": 5.4400234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 30,
      "real_time": 2.3359044268727303e+07,
      "cpu_time": 3.1168073366643511e+07,
      "time_unit": "ns",
      "items_per_second": 5.6309398589605261e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.6216448000000000e+07,
      "advised_time": 2.3588863372802734e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.1941256922983490e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.0000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.6216448000000000e+07,
      "workspace_megabytes": 2.5001953125000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 30,
      "real_time": 2.3363788922627766e+07,
      "cpu_time": 3.1151714133352470e+07,
      "time_unit": "ns",
      "items_per_second": 5.6297963432040027e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.6216448000000000e+07,
      "advised_time": 2.3590911865234375e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.1941256922983490e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.0000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.6216448000000000e+07,
      "workspace_megabytes": 2.5001953125000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 30,
      "real_time": 2.3349179637928803e+07,
      "cpu_time": 3.1150760699999105e+07,
      "time_unit": "ns",
      "items_per_second": 5.6333188351651965e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.6216448000000000e+07,
      "advised_time": 2.3645183563232422e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.1941256922983490e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.0000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.6216448000000000e+07,
      "workspace_megabytes": 2.5001953125000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 98,
      "real_time": 7.1571954259915007e+06,
      "cpu_time": 7.9017808877640115e+06,
      "time_unit": "ns",
      "items_per_second": 1.8377781464836614e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4172851200000000e+08,
      "advised_time": 7.3953280448913574e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.0444073425867530e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 9.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.4172851200000000e+08,
      "workspace_megabytes": 6.1200000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 98,
      "real_time": 7.1582096457785489e+06,
      "cpu_time": 7.9021441326487409e+06,
      "time_unit": "ns",
      "items_per_second": 1.8375177586139841e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4172851200000000e+08,
      "advised_time": 7.3635840415954590e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.0444073425867530e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 9.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.4172851200000000e+08,
      "workspace_megabytes": 6.1200000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 98,
      "real_time": 7.1572061837175675e+06,
      "cpu_time": 7.9041249285864979e+06,
      "time_unit": "ns",
      "items_per_second": 1.8377753841887991e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.4172851200000000e+08,
      "advised_time": 7.3031678199768066e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.0444073425867530e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 9.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5690112000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.4172851200000000e+08,
      "workspace_megabytes": 6.1200000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__4404506881729408756<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 73,
      "real_time": 9.6309023131042309e+06,
      "cpu_time": 1.0965775767112037e+07,
      "time_unit": "ns",
      "items_per_second": 5.4629719693462109e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.7638397216796875e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 7.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 73,
      "real_time": 9.6283633619138636e+06,
      "cpu_time": 1.0962612698648790e+07,
      "time_unit": "ns",
      "items_per_second": 5.4644125276906729e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.7433595657348633e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 7.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 73,
      "real_time": 9.6363028103154004e+06,
      "cpu_time": 1.0971204602751579e+07,
      "time_unit": "ns",
      "items_per_second": 5.4599103423440410e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.7771520614624023e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 7.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 73,
      "real_time": 9.6286439706813805e+06,
      "cpu_time": 1.0966225452062795e+07,
      "time_unit": "ns",
      "items_per_second": 5.4642532776374707e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.7034244537353516e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 7.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 73,
      "real_time": 9.6337217837572098e+06,
      "cpu_time": 1.0969666013701102e+07,
      "time_unit": "ns",
      "items_per_second": 5.4613731387497549e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.7116155624389648e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 7.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 85,
      "real_time": 8.2336711423362000e+06,
      "cpu_time": 9.2168319058788139e+06,
      "time_unit": "ns",
      "items_per_second": 6.3900231702807148e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 8.2309122085571289e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 8.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 85,
      "real_time": 8.2312132286674837e+06,
      "cpu_time": 9.2139152470629010e+06,
      "time_unit": "ns",
      "items_per_second": 6.3919312881799023e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 8.2370557785034180e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 8.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 85,
      "real_time": 8.2351766417131703e+06,
      "cpu_time": 9.2190942588251121e+06,
      "time_unit": "ns",
      "items_per_second": 6.3888549894000576e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 8.2288637161254883e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 8.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 85,
      "real_time": 8.2329841111512743e+06,
      "cpu_time": 9.2157421999806557e+06,
      "time_unit": "ns",
      "items_per_second": 6.3905564089134033e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 8.2432003021240234e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 8.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 85,
      "real_time": 8.2327673211693764e+06,
      "cpu_time": 9.2160325529381651e+06,
      "time_unit": "ns",
      "items_per_second": 6.3907246887340479e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 8.2350082397460938e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 8.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 59,
      "real_time": 1.1807310142380707e+07,
      "cpu_time": 1.3827328508503312e+07,
      "time_unit": "ns",
      "items_per_second": 4.4559979149824873e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.2208358400000000e+08,
      "advised_time": 1.1860992431640625e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 5.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 8.2208358400000000e+08,
      "workspace_megabytes": 7.8400000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 59,
      "real_time": 1.1813714468883255e+07,
      "cpu_time": 1.3832539186458204e+07,
      "time_unit": "ns",
      "items_per_second": 4.4535822763095371e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.2208358400000000e+08,
      "advised_time": 1.1840512275695801e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 5.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 8.2208358400000000e+08,
      "workspace_megabytes": 7.8400000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 59,
      "real_time": 1.1811944135164810e+07,
      "cpu_time": 1.3830771559295792e+07,
      "time_unit": "ns",
      "items_per_second": 4.4542497639628311e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.2208358400000000e+08,
      "advised_time": 1.1835391998291016e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 5.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 8.2208358400000000e+08,
      "workspace_megabytes": 7.8400000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 25,
      "real_time": 2.8114493191242218e+07,
      "cpu_time": 3.9364739799984820e+07,
      "time_unit": "ns",
      "items_per_second": 1.8713959742439631e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0209474560000000e+09,
      "advised_time": 2.8436479568481445e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0209474560000000e+09,
      "workspace_megabytes": 2.8810000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 25,
      "real_time": 2.8109003603458405e+07,
      "cpu_time": 3.9360329879982598e+07,
      "time_unit": "ns",
      "items_per_second": 1.8717614511788206e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0209474560000000e+09,
      "advised_time": 2.8506111145019531e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0209474560000000e+09,
      "workspace_megabytes": 2.8810000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 25,
      "real_time": 2.8106752038002014e+07,
      "cpu_time": 3.9362030319971383e+07,
      "time_unit": "ns",
      "items_per_second": 1.8719113935634966e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0209474560000000e+09,
      "advised_time": 2.8452863693237305e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0209474560000000e+09,
      "workspace_megabytes": 2.8810000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 19,
      "real_time": 3.7661426553600714e+07,
      "cpu_time": 5.7478349526311494e+07,
      "time_unit": "ns",
      "items_per_second": 1.3970089343567305e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5312628800000000e+09,
      "advised_time": 3.8129665374755859e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.5312628800000000e+09,
      "workspace_megabytes": 2.4140003967285156e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 19,
      "real_time": 3.7650593605480693e+07,
      "cpu_time": 5.7461173842081107e+07,
      "time_unit": "ns",
      "items_per_second": 1.3974108861949314e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5312628800000000e+09,
      "advised_time": 3.8099967956542969e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.5312628800000000e+09,
      "workspace_megabytes": 2.4140003967285156e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 19,
      "real_time": 3.7658624154956721e+07,
      "cpu_time": 5.7472416157883056e+07,
      "time_unit": "ns",
      "items_per_second": 1.3971128939684033e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5312628800000000e+09,
      "advised_time": 3.8090751647949219e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.5312628800000000e+09,
      "workspace_megabytes": 2.4140003967285156e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_FLOAT32__BatchSize_1024__15120482409311613943<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 33,
      "real_time": 2.1231708935264386e+07,
      "cpu_time": 2.7658432303035099e+07,
      "time_unit": "ns",
      "items_per_second": 6.1951383113364111e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.1269504547119141e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 33,
      "real_time": 2.1193696693940595e+07,
      "cpu_time": 2.7634088242421333e+07,
      "time_unit": "ns",
      "items_per_second": 6.2062496854362439e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.1299200057983398e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 33,
      "real_time": 2.1177809233918335e+07,
      "cpu_time": 2.7609228939361472e+07,
      "time_unit": "ns",
      "items_per_second": 6.2109055751308032e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.1276672363281250e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 33,
      "real_time": 2.1214673295617104e+07,
      "cpu_time": 2.7666140848464925e+07,
      "time_unit": "ns",
      "items_per_second": 6.2001130824472534e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.1285888671875000e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 33,
      "real_time": 2.1188606987848427e+07,
      "cpu_time": 2.7619880727246653e+07,
      "time_unit": "ns",
      "items_per_second": 6.2077404859806885e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.1472255706787109e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 38,
      "real_time": 1.8564122974088319e+07,
      "cpu_time": 2.3459806894714732e+07,
      "time_unit": "ns",
      "items_per_second": 7.0853534865931140e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 1.8714624404907227e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 38,
      "real_time": 1.8511818133686718e+07,
      "cpu_time": 2.3411979131579805e+07,
      "time_unit": "ns",
      "items_per_second": 7.1053730373810938e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 1.8492416381835938e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 38,
      "real_time": 1.8544343300163746e+07,
      "cpu_time": 2.3425676710542720e+07,
      "time_unit": "ns",
      "items_per_second": 7.0929108305948242e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 1.8712575912475586e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 38,
      "real_time": 1.8558409996330738e+07,
      "cpu_time": 2.3434355263134420e+07,
      "time_unit": "ns",
      "items_per_second": 7.0875346253265247e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 1.8495487213134766e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 38,
      "real_time": 1.8551484583631944e+07,
      "cpu_time": 2.3431567684251845e+07,
      "time_unit": "ns",
      "items_per_second": 7.0901804568272925e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 1.8494464874267578e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 28,
      "real_time": 2.4708681207682405e+07,
      "cpu_time": 3.3542717000078224e+07,
      "time_unit": "ns",
      "items_per_second": 5.3233668091967505e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8496880640000000e+09,
      "advised_time": 2.4787967681884766e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8496880640000000e+09,
      "workspace_megabytes": 1.7640000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 28,
      "real_time": 2.4721078840749603e+07,
      "cpu_time": 3.3553199607143011e+07,
      "time_unit": "ns",
      "items_per_second": 5.3206971381517419e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8496880640000000e+09,
      "advised_time": 2.4781824111938477e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8496880640000000e+09,
      "workspace_megabytes": 1.7640000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 28,
      "real_time": 2.4715154365237270e+07,
      "cpu_time": 3.3542167142822366e+07,
      "time_unit": "ns",
      "items_per_second": 5.3219725637241534e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8496880640000000e+09,
      "advised_time": 2.4825855255126953e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8496880640000000e+09,
      "workspace_megabytes": 1.7640000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 92,
      "real_time": 7.6423902520100055e+06,
      "cpu_time": 8.4856770652639009e+06,
      "time_unit": "ns",
      "items_per_second": 1.7211025491063577e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.5733401600000000e+08,
      "advised_time": 7.8510079383850098e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 9.2000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.5733401600000000e+08,
      "workspace_megabytes": 7.2225000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 92,
      "real_time": 7.6487011822831370e+06,
      "cpu_time": 8.4942085651836470e+06,
      "time_unit": "ns",
      "items_per_second": 1.7196824703346208e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.5733401600000000e+08,
      "advised_time": 7.8776321411132812e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 9.2000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.5733401600000000e+08,
      "workspace_megabytes": 7.2225000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 92,
      "real_time": 7.6488903723657131e+06,
      "cpu_time": 8.4937396304222494e+06,
      "time_unit": "ns",
      "items_per_second": 1.7196399351624941e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.5733401600000000e+08,
      "advised_time": 7.8786559104919434e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 9.2000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.5733401600000000e+08,
      "workspace_megabytes": 7.2225000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 31,
      "real_time": 2.2302653700593978e+07,
      "cpu_time": 2.9501667290318321e+07,
      "time_unit": "ns",
      "items_per_second": 5.8976557321740112e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5669386240000000e+09,
      "advised_time": 2.2763519287109375e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.1000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.5669386240000000e+09,
      "workspace_megabytes": 2.4480234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 31,
      "real_time": 2.2302885029104449e+07,
      "cpu_time": 2.9498547193563882e+07,
      "time_unit": "ns",
      "items_per_second": 5.8975945608989050e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5669386240000000e+09,
      "advised_time": 2.2696960449218750e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.1000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.5669386240000000e+09,
      "workspace_megabytes": 2.4480234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 31,
      "real_time": 2.2307641984474275e+07,
      "cpu_time": 2.9496121516155154e+07,
      "time_unit": "ns",
      "items_per_second": 5.8963369383256604e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5669386240000000e+09,
      "advised_time": 2.2681600570678711e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 3.1000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.5669386240000000e+09,
      "workspace_megabytes": 2.4480234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 59,
      "real_time": 1.1862224252042124e+07,
      "cpu_time": 1.3884452322068004e+07,
      "time_unit": "ns",
      "items_per_second": 1.1088424113829753e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.5546240000000000e+06,
      "advised_time": 1.1886591911315918e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.1941256922983490e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 5.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.5546240000000000e+06,
      "workspace_megabytes": 6.2509765625000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 59,
      "real_time": 1.1864029249902500e+07,
      "cpu_time": 1.3886158983056657e+07,
      "time_unit": "ns",
      "items_per_second": 1.1086737116825718e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.5546240000000000e+06,
      "advised_time": 1.1876352310180664e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.1941256922983490e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 5.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.5546240000000000e+06,
      "workspace_megabytes": 6.2509765625000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 59,
      "real_time": 1.1869617864110712e+07,
      "cpu_time": 1.3895344169468137e+07,
      "time_unit": "ns",
      "items_per_second": 1.1081517109131858e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.5546240000000000e+06,
      "advised_time": 1.1879424095153809e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.1941256922983490e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 5.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.5546240000000000e+06,
      "workspace_megabytes": 6.2509765625000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 83,
      "real_time": 8.3868931305695726e+06,
      "cpu_time": 9.4140279879427981e+06,
      "time_unit": "ns",
      "items_per_second": 1.5683206092202498e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2173967360000000e+09,
      "advised_time": 8.6435842514038086e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.0444073425867530e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 8.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.2173967360000000e+09,
      "workspace_megabytes": 1.1610000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 83,
      "real_time": 8.3876082628785847e+06,
      "cpu_time": 9.4134653614750579e+06,
      "time_unit": "ns",
      "items_per_second": 1.5681868933022681e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2173967360000000e+09,
      "advised_time": 8.6343679428100586e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.0444073425867530e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 8.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.2173967360000000e+09,
      "workspace_megabytes": 1.1610000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 84,
      "real_time": 8.3878521497050924e+06,
      "cpu_time": 9.4024007738274429e+06,
      "time_unit": "ns",
      "items_per_second": 1.5681412963940308e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2173967360000000e+09,
      "advised_time": 8.6312961578369141e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.0444073425867530e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 8.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.2173967360000000e+09,
      "workspace_megabytes": 1.1610000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_FLOAT32__BatchSize_1024__5916609887380257933<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 136,
      "real_time": 5.1500574130948409e+06,
      "cpu_time": 5.5441390073503815e+06,
      "time_unit": "ns",
      "items_per_second": 2.0432140908651688e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.1978240013122559e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.3600000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 136,
      "real_time": 5.1534305812845770e+06,
      "cpu_time": 5.5481597205972746e+06,
      "time_unit": "ns",
      "items_per_second": 2.0418767089663699e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.1886081695556641e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.3600000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 136,
      "real_time": 5.1462701247895462e+06,
      "cpu_time": 5.5373911102880323e+06,
      "time_unit": "ns",
      "items_per_second": 2.0447177509226293e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.1845121383666992e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.3600000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 136,
      "real_time": 5.1505091661751708e+06,
      "cpu_time": 5.5446518897062615e+06,
      "time_unit": "ns",
      "items_per_second": 2.0430348797950512e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.1968002319335938e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.3600000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 136,
      "real_time": 5.1541910575264515e+06,
      "cpu_time": 5.5487484705903465e+06,
      "time_unit": "ns",
      "items_per_second": 2.0415754398227402e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.1742720603942871e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.3600000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 109,
      "real_time": 6.4070925560839679e+06,
      "cpu_time": 7.0097808991145324e+06,
      "time_unit": "ns",
      "items_per_second": 1.6423470994200033e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 6.4040961265563965e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.0900000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 110,
      "real_time": 6.4036209390244698e+06,
      "cpu_time": 7.0002160091007678e+06,
      "time_unit": "ns",
      "items_per_second": 1.6432374707056016e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 6.4358401298522949e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.1000000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 109,
      "real_time": 6.4002066901927693e+06,
      "cpu_time": 7.0010855321274363e+06,
      "time_unit": "ns",
      "items_per_second": 1.6441140707727777e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 6.4143362045288086e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.0900000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 110,
      "real_time": 6.4013591247864747e+06,
      "cpu_time": 6.9985886272826809e+06,
      "time_unit": "ns",
      "items_per_second": 1.6438180814532879e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 6.3856639862060547e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.1000000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 109,
      "real_time": 6.4051388036630573e+06,
      "cpu_time": 7.0093558440330029e+06,
      "time_unit": "ns",
      "items_per_second": 1.6428480627433326e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 6.4081921577453613e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.0900000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 100,
      "real_time": 7.0262169232591987e+06,
      "cpu_time": 7.7435875299852351e+06,
      "time_unit": "ns",
      "items_per_second": 1.4976295195735186e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.1104179200000000e+08,
      "advised_time": 7.0420479774475098e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.0000000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 4.1104179200000000e+08,
      "workspace_megabytes": 3.9200000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 100,
      "real_time": 7.0185676729306579e+06,
      "cpu_time": 7.7381330500065815e+06,
      "time_unit": "ns",
      "items_per_second": 1.4992617248365402e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.1104179200000000e+08,
      "advised_time": 7.0574078559875488e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.0000000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 4.1104179200000000e+08,
      "workspace_megabytes": 3.9200000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 100,
      "real_time": 7.0208608079701662e+06,
      "cpu_time": 7.7378634399838122e+06,
      "time_unit": "ns",
      "items_per_second": 1.4987720399262920e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.1104179200000000e+08,
      "advised_time": 7.0174717903137207e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.0000000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 4.1104179200000000e+08,
      "workspace_megabytes": 3.9200000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 16,
      "real_time": 4.3113791383802891e+07,
      "cpu_time": 7.0025367937461168e+07,
      "time_unit": "ns",
      "items_per_second": 2.4406737467197529e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.9930019840000000e+09,
      "advised_time": 4.3839488983154297e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.9930019840000000e+09,
      "workspace_megabytes": 3.8080234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 16,
      "real_time": 4.3096190318465233e+07,
      "cpu_time": 6.9994187374987856e+07,
      "time_unit": "ns",
      "items_per_second": 2.4416705507937666e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.9930019840000000e+09,
      "advised_time": 4.3737087249755859e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.9930019840000000e+09,
      "workspace_megabytes": 3.8080234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 16,
      "real_time": 4.3091583764180541e+07,
      "cpu_time": 6.9997202312436000e+07,
      "time_unit": "ns",
      "items_per_second": 2.4419315690009209e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.9930019840000000e+09,
      "advised_time": 4.3760639190673828e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 3.9930019840000000e+09,
      "workspace_megabytes": 3.8080234375000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__5219595357189046057<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 69,
      "real_time": 1.0099073871970177e+07,
      "cpu_time": 1.1578987362290850e+07,
      "time_unit": "ns",
      "items_per_second": 5.2097202221708203e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.0251263618469238e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 6.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 69,
      "real_time": 1.0090050894929016e+07,
      "cpu_time": 1.1569219826067612e+07,
      "time_unit": "ns",
      "items_per_second": 5.2143789881616982e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.0230784416198730e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 6.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 69,
      "real_time": 1.0097901350346165e+07,
      "cpu_time": 1.1578039521756854e+07,
      "time_unit": "ns",
      "items_per_second": 5.2103251507994150e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.0228735923767090e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 6.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 69,
      "real_time": 1.0093761351553427e+07,
      "cpu_time": 1.1571762173916532e+07,
      "time_unit": "ns",
      "items_per_second": 5.2124621876366064e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.0248191833496094e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 6.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 69,
      "real_time": 1.0086993632865125e+07,
      "cpu_time": 1.1562625652149491e+07,
      "time_unit": "ns",
      "items_per_second": 5.2159594117891426e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.0235903739929199e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 6.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 85,
      "real_time": 8.2655351828126349e+06,
      "cpu_time": 9.2487820352663901e+06,
      "time_unit": "ns",
      "items_per_second": 6.3653893199080771e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 8.2954244613647461e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 8.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 85,
      "real_time": 8.2812084761612555e+06,
      "cpu_time": 9.2707715765005983e+06,
      "time_unit": "ns",
      "items_per_second": 6.3533419702517686e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 8.2821121215820312e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 8.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 85,
      "real_time": 8.2684506059569474e+06,
      "cpu_time": 9.2537502706417236e+06,
      "time_unit": "ns",
      "items_per_second": 6.3631449086839902e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 8.2759675979614258e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 8.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 85,
      "real_time": 8.2814252990133623e+06,
      "cpu_time": 9.2695030941232461e+06,
      "time_unit": "ns",
      "items_per_second": 6.3531756281455898e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 8.2452478408813477e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 8.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 85,
      "real_time": 8.2659087856026255e+06,
      "cpu_time": 9.2494668941232227e+06,
      "time_unit": "ns",
      "items_per_second": 6.3651016168531582e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 8.2472963333129883e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 8.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 67,
      "real_time": 1.0440856955055870e+07,
      "cpu_time": 1.2004865358184319e+07,
      "time_unit": "ns",
      "items_per_second": 5.0391792170395137e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0276044800000000e+08,
      "advised_time": 1.0232831954956055e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 6.7000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.0276044800000000e+08,
      "workspace_megabytes": 9.8000000000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 67,
      "real_time": 1.0436729750415282e+07,
      "cpu_time": 1.2000238985059859e+07,
      "time_unit": "ns",
      "items_per_second": 5.0411719603936748e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0276044800000000e+08,
      "advised_time": 1.0286080360412598e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 6.7000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.0276044800000000e+08,
      "workspace_megabytes": 9.8000000000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 67,
      "real_time": 1.0418970763349712e+07,
      "cpu_time": 1.1995736776145296e+07,
      "time_unit": "ns",
      "items_per_second": 5.0497645661004570e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0276044800000000e+08,
      "advised_time": 1.0258432388305664e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 6.7000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.0276044800000000e+08,
      "workspace_megabytes": 9.8000000000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 7,
      "real_time": 1.0278955847024918e+08,
      "cpu_time": 2.4959892357134908e+08,
      "time_unit": "ns",
      "items_per_second": 5.1185499927240283e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.8360325120000000e+09,
      "advised_time": 1.0265497589111328e+02,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 7.0000000000000000e+00,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.8360325120000000e+09,
      "workspace_megabytes": 4.6120000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 7,
      "real_time": 1.0278824184622084e+08,
      "cpu_time": 2.4959666271427393e+08,
      "time_unit": "ns",
      "items_per_second": 5.1186155567008960e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.8360325120000000e+09,
      "advised_time": 1.0266316986083984e+02,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 7.0000000000000000e+00,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.8360325120000000e+09,
      "workspace_megabytes": 4.6120000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 7,
      "real_time": 1.0278751381805965e+08,
      "cpu_time": 2.4959788400006539e+08,
      "time_unit": "ns",
      "items_per_second": 5.1186518110681158e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.8360325120000000e+09,
      "advised_time": 1.0263961791992188e+02,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 7.0000000000000000e+00,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.8360325120000000e+09,
      "workspace_megabytes": 4.6120000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 11,
      "real_time": 6.4774515953930944e+07,
      "cpu_time": 1.2363094918179160e+08,
      "time_unit": "ns",
      "items_per_second": 8.1225384089971082e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.6382176320000000e+09,
      "advised_time": 6.4602111816406250e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.1000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.6382176320000000e+09,
      "workspace_megabytes": 2.5160003967285156e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 11,
      "real_time": 6.4775724979964167e+07,
      "cpu_time": 1.2362987218181263e+08,
      "time_unit": "ns",
      "items_per_second": 8.1223868034319763e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.6382176320000000e+09,
      "advised_time": 6.4596992492675781e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.1000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.6382176320000000e+09,
      "workspace_megabytes": 2.5160003967285156e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 11,
      "real_time": 6.4773026515137069e+07,
      "cpu_time": 1.2363060372734419e+08,
      "time_unit": "ns",
      "items_per_second": 8.1227251846421875e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.6382176320000000e+09,
      "advised_time": 6.4616447448730469e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5690112000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.1000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0276044800000000e+08,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.6382176320000000e+09,
      "workspace_megabytes": 2.5160003967285156e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__8655295559195408465<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 26,
      "real_time": 2.6887128631082866e+07,
      "cpu_time": 3.7235956923163585e+07,
      "time_unit": "ns",
      "items_per_second": 4.8920572830503308e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.6754047393798828e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 26,
      "real_time": 2.6878148890458621e+07,
      "cpu_time": 3.7222756192302488e+07,
      "time_unit": "ns",
      "items_per_second": 4.8936916740829785e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.6738687515258789e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 26,
      "real_time": 2.6859521507643737e+07,
      "cpu_time": 3.7196881076904625e+07,
      "time_unit": "ns",
      "items_per_second": 4.8970855047647803e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.6730495452880859e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 26,
      "real_time": 2.6882087525266867e+07,
      "cpu_time": 3.7227000999984317e+07,
      "time_unit": "ns",
      "items_per_second": 4.8929746737997882e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.6753023147583008e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 26,
      "real_time": 2.6876297707741078e+07,
      "cpu_time": 3.7220573807731993e+07,
      "time_unit": "ns",
      "items_per_second": 4.8940287412471600e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.6743808746337891e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 38,
      "real_time": 1.8545825524549734e+07,
      "cpu_time": 2.3434829710499559e+07,
      "time_unit": "ns",
      "items_per_second": 7.0923439490943579e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 1.8546688079833984e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 38,
      "real_time": 1.8537445189921480e+07,
      "cpu_time": 2.3422987789504796e+07,
      "time_unit": "ns",
      "items_per_second": 7.0955502277904321e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 1.8544639587402344e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 38,
      "real_time": 1.8545771556857385e+07,
      "cpu_time": 2.3434787263173155e+07,
      "time_unit": "ns",
      "items_per_second": 7.0923645876229358e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 1.8542591094970703e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 38,
      "real_time": 1.8544909495272133e+07,
      "cpu_time": 2.3434088842099011e+07,
      "time_unit": "ns",
      "items_per_second": 7.0926942767519739e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 1.8547712326049805e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 38,
      "real_time": 1.8544100911209457e+07,
      "cpu_time": 2.3433211236842427e+07,
      "time_unit": "ns",
      "items_per_second": 7.0930035416541162e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 1.8543615341186523e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 18,
      "real_time": 3.9673344749543399e+07,
      "cpu_time": 6.1713177055632204e+07,
      "time_unit": "ns",
      "items_per_second": 3.3154092318246954e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.3987522560000000e+09,
      "advised_time": -1.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.3987522560000000e+09,
      "workspace_megabytes": 7.0560000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 18,
      "real_time": 3.9673570336567029e+07,
      "cpu_time": 6.1712943166614622e+07,
      "time_unit": "ns",
      "items_per_second": 3.3153903801485199e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.3987522560000000e+09,
      "advised_time": -1.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.3987522560000000e+09,
      "workspace_megabytes": 7.0560000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 18,
      "real_time": 3.9669930727945432e+07,
      "cpu_time": 6.1719111000027418e+07,
      "time_unit": "ns",
      "items_per_second": 3.3156945582297546e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.3987522560000000e+09,
      "advised_time": -1.0000000000000000e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.8000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.3987522560000000e+09,
      "workspace_megabytes": 7.0560000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 41,
      "real_time": 1.7044605460108779e+07,
      "cpu_time": 2.1217180902478900e+07,
      "time_unit": "ns",
      "items_per_second": 7.7170089825687610e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.3531520000000000e+09,
      "advised_time": 1.7038335800170898e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.1000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.3531520000000000e+09,
      "workspace_megabytes": 2.2441406250000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 41,
      "real_time": 1.7042980960956436e+07,
      "cpu_time": 2.1212533560983725e+07,
      "time_unit": "ns",
      "items_per_second": 7.7177445507524927e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.3531520000000000e+09,
      "advised_time": 1.7122304916381836e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.1000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.3531520000000000e+09,
      "workspace_megabytes": 2.2441406250000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 41,
      "real_time": 1.7040708715595849e+07,
      "cpu_time": 2.1206792999980349e+07,
      "time_unit": "ns",
      "items_per_second": 7.7187736516861633e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.3531520000000000e+09,
      "advised_time": 1.7125375747680664e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.1000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.3531520000000000e+09,
      "workspace_megabytes": 2.2441406250000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 50,
      "real_time": 1.4073774088174105e+07,
      "cpu_time": 1.6889514799995597e+07,
      "time_unit": "ns",
      "items_per_second": 9.3459915311930945e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1587256320000000e+09,
      "advised_time": 1.4143487930297852e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.0000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1587256320000000e+09,
      "workspace_megabytes": 1.1050468750000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 50,
      "real_time": 1.4053477719426155e+07,
      "cpu_time": 1.6867309819954243e+07,
      "time_unit": "ns",
      "items_per_second": 9.3594892357626978e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1587256320000000e+09,
      "advised_time": 1.4147583961486816e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.0000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1587256320000000e+09,
      "workspace_megabytes": 1.1050468750000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 50,
      "real_time": 1.4056202340871096e+07,
      "cpu_time": 1.6869483380032763e+07,
      "time_unit": "ns",
      "items_per_second": 9.3576750142207019e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1587256320000000e+09,
      "advised_time": 1.4261247634887695e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.0000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1587256320000000e+09,
      "workspace_megabytes": 1.1050468750000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 59,
      "real_time": 1.1786326797584357e+07,
      "cpu_time": 1.3797117271170171e+07,
      "time_unit": "ns",
      "items_per_second": 1.1159827459302942e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.0985600000000000e+05,
      "advised_time": 1.1860992431640625e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.1941256922983490e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.0985600000000000e+05,
      "workspace_megabytes": 3.9086914062500000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 59,
      "real_time": 1.1788809261584686e+07,
      "cpu_time": 1.3798571050841220e+07,
      "time_unit": "ns",
      "items_per_second": 1.1157477445039170e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.0985600000000000e+05,
      "advised_time": 1.1863039970397949e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.1941256922983490e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.0985600000000000e+05,
      "workspace_megabytes": 3.9086914062500000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 59,
      "real_time": 1.1787871356611535e+07,
      "cpu_time": 1.3798173016959358e+07,
      "time_unit": "ns",
      "items_per_second": 1.1158365192560918e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.0985600000000000e+05,
      "advised_time": 1.1866111755371094e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.1941256922983490e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.0985600000000000e+05,
      "workspace_megabytes": 3.9086914062500000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 40,
      "real_time": 1.7585382377728820e+07,
      "cpu_time": 2.1993710599997483e+07,
      "time_unit": "ns",
      "items_per_second": 7.4796993670482666e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.6999659520000000e+09,
      "advised_time": 1.8489343643188477e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.0444073425867530e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.0000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.6999659520000000e+09,
      "workspace_megabytes": 3.5285625000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 40,
      "real_time": 1.7588607687503099e+07,
      "cpu_time": 2.1997307025026202e+07,
      "time_unit": "ns",
      "items_per_second": 7.4783277776703113e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.6999659520000000e+09,
      "advised_time": 1.8476032257080078e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.0444073425867530e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.0000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.6999659520000000e+09,
      "workspace_megabytes": 3.5285625000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 40,
      "real_time": 1.7590118199586868e+07,
      "cpu_time": 2.1998865150032997e+07,
      "time_unit": "ns",
      "items_per_second": 7.4776855929876172e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.6999659520000000e+09,
      "advised_time": 1.8464767456054688e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.0444073425867530e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.0000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.6999659520000000e+09,
      "workspace_megabytes": 3.5285625000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__656292746498635483<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 169,
      "real_time": 4.1428918801468504e+06,
      "cpu_time": 4.4038672662733952e+06,
      "time_unit": "ns",
      "items_per_second": 3.1749168755844438e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.0314879417419434e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.6900000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 169,
      "real_time": 4.1427042296696343e+06,
      "cpu_time": 4.4032567988130711e+06,
      "time_unit": "ns",
      "items_per_second": 3.1750606885707915e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.0202240943908691e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.6900000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 169,
      "real_time": 4.1417527569116219e+06,
      "cpu_time": 4.4016563668738585e+06,
      "time_unit": "ns",
      "items_per_second": 3.1757900859847656e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.0263681411743164e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.6900000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 169,
      "real_time": 4.1416679376725261e+06,
      "cpu_time": 4.4019242307636971e+06,
      "time_unit": "ns",
      "items_per_second": 3.1758551245399263e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.0263681411743164e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.6900000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 169,
      "real_time": 4.1422433544986346e+06,
      "cpu_time": 4.4019973609508583e+06,
      "time_unit": "ns",
      "items_per_second": 3.1754139528559985e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.0110077857971191e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.6900000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 303,
      "real_time": 2.3091469842190593e+06,
      "cpu_time": 2.3984323861531275e+06,
      "time_unit": "ns",
      "items_per_second": 5.6961888670973389e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 2.3183360099792480e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.0300000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 303,
      "real_time": 2.3096741035752762e+06,
      "cpu_time": 2.3991645610342678e+06,
      "time_unit": "ns",
      "items_per_second": 5.6948888692301650e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 2.3255040645599365e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.0300000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 303,
      "real_time": 2.3104548746283497e+06,
      "cpu_time": 2.3999002409233889e+06,
      "time_unit": "ns",
      "items_per_second": 5.6929643978075068e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 2.3203840255737305e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.0300000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 303,
      "real_time": 2.3055342540894896e+06,
      "cpu_time": 2.3935131914363154e+06,
      "time_unit": "ns",
      "items_per_second": 5.7051146911692998e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 2.3224320411682129e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.0300000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 304,
      "real_time": 2.3126669226545156e+06,
      "cpu_time": 2.4026721381550198e+06,
      "time_unit": "ns",
      "items_per_second": 5.6875191213883896e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 2.3142399787902832e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.0400000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 109,
      "real_time": 6.4063224890226619e+06,
      "cpu_time": 7.0107651926339315e+06,
      "time_unit": "ns",
      "items_per_second": 2.0531806456104041e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.2208358400000000e+08,
      "advised_time": 6.1368322372436523e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.0900000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 8.2208358400000000e+08,
      "workspace_megabytes": 7.8400000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 109,
      "real_time": 6.4082859562487779e+06,
      "cpu_time": 7.0139167523222510e+06,
      "time_unit": "ns",
      "items_per_second": 2.0525515611821382e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.2208358400000000e+08,
      "advised_time": 6.1440000534057617e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.0900000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 8.2208358400000000e+08,
      "workspace_megabytes": 7.8400000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 109,
      "real_time": 6.4064352602245063e+06,
      "cpu_time": 7.0118739357510991e+06,
      "time_unit": "ns",
      "items_per_second": 2.0531445038810952e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.2208358400000000e+08,
      "advised_time": 6.1337599754333496e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.0900000000000000e+02,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 8.2208358400000000e+08,
      "workspace_megabytes": 7.8400000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 41,
      "real_time": 1.7053197160726640e+07,
      "cpu_time": 2.1225547195149932e+07,
      "time_unit": "ns",
      "items_per_second": 7.7131210177362036e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.3531028480000000e+09,
      "advised_time": 1.8031616210937500e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.1000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.3531028480000000e+09,
      "workspace_megabytes": 2.2440937500000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 41,
      "real_time": 1.7057643022115637e+07,
      "cpu_time": 2.1233300682935096e+07,
      "time_unit": "ns",
      "items_per_second": 7.7111106891769202e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.3531028480000000e+09,
      "advised_time": 1.8045951843261719e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.1000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.3531028480000000e+09,
      "workspace_megabytes": 2.2440937500000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 41,
      "real_time": 1.7055694150125109e+07,
      "cpu_time": 2.1230062926850047e+07,
      "time_unit": "ns",
      "items_per_second": 7.7119918006406775e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.3531028480000000e+09,
      "advised_time": 1.8054143905639648e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.1000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.3531028480000000e+09,
      "workspace_megabytes": 2.2440937500000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 63,
      "real_time": 1.1095088788322987e+07,
      "cpu_time": 1.2866129349211926e+07,
      "time_unit": "ns",
      "items_per_second": 1.1855098769325051e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.9970465920000000e+09,
      "advised_time": 1.1560959815979004e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.9970465920000000e+09,
      "workspace_megabytes": 1.9045320434570312e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 63,
      "real_time": 1.1098307054785509e+07,
      "cpu_time": 1.2868667682517024e+07,
      "time_unit": "ns",
      "items_per_second": 1.1851661049807031e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.9970465920000000e+09,
      "advised_time": 1.1542528152465820e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.9970465920000000e+09,
      "workspace_megabytes": 1.9045320434570312e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 63,
      "real_time": 1.1094780032715155e+07,
      "cpu_time": 1.2864526857118195e+07,
      "time_unit": "ns",
      "items_per_second": 1.1855428683772712e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.9970465920000000e+09,
      "advised_time": 1.1569151878356934e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0552089600000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.9970465920000000e+09,
      "workspace_megabytes": 1.9045320434570312e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__17678099192574731707<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__10233547132013252565<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__2455076831850065219<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_BIAS_ACTIVATION_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 60,
      "real_time": 1.1736968625336885e+07,
      "cpu_time": 1.3706380249990011e+07,
      "time_unit": "ns",
      "items_per_second": 4.4827034181911553e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.2096511840820312e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 6.0000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 60,
      "real_time": 1.1735227641959986e+07,
      "cpu_time": 1.3712068216636907e+07,
      "time_unit": "ns",
      "items_per_second": 4.4833684510625020e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.2119039535522461e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 6.0000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 59,
      "real_time": 1.1720113835092319e+07,
      "cpu_time": 1.3723040508489633e+07,
      "time_unit": "ns",
      "items_per_second": 4.4891500301358271e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.2114944458007812e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.9000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 60,
      "real_time": 1.1710548788929978e+07,
      "cpu_time": 1.3681545783341182e+07,
      "time_unit": "ns",
      "items_per_second": 4.4928167180120176e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.2105728149414062e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 6.0000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 60,
      "real_time": 1.1738555785268545e+07,
      "cpu_time": 1.3719341466692943e+07,
      "time_unit": "ns",
      "items_per_second": 4.4820973157556416e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.2111871719360352e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 6.0000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 84,
      "real_time": 8.3981774902592096e+06,
      "cpu_time": 9.4123522500294279e+06,
      "time_unit": "ns",
      "items_per_second": 6.2648532300043213e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 8.3927040100097656e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 8.4000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 83,
      "real_time": 8.3931230726730395e+06,
      "cpu_time": 9.4185558192589544e+06,
      "time_unit": "ns",
      "items_per_second": 6.2686259834914727e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 8.3978242874145508e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 8.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 83,
      "real_time": 8.4033758009234108e+06,
      "cpu_time": 9.4299071325534545e+06,
      "time_unit": "ns",
      "items_per_second": 6.2609778049219873e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 8.3988475799560547e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 8.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 83,
      "real_time": 8.3980707182403076e+06,
      "cpu_time": 9.4236442048139609e+06,
      "time_unit": "ns",
      "items_per_second": 6.2649328805633535e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 8.4091196060180664e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 8.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 83,
      "real_time": 8.4013154797525294e+06,
      "cpu_time": 9.4278249638679326e+06,
      "time_unit": "ns",
      "items_per_second": 6.2625132341238770e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 8.3998718261718750e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 8.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 55,
      "real_time": 1.2669914723797278e+07,
      "cpu_time": 1.4980721200002087e+07,
      "time_unit": "ns",
      "items_per_second": 4.1526206389675957e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.1104179200000000e+08,
      "advised_time": 1.3001728057861328e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.5000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.1104179200000000e+08,
      "workspace_megabytes": 3.9200000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 56,
      "real_time": 1.2581504016582455e+07,
      "cpu_time": 1.4845407482174065e+07,
      "time_unit": "ns",
      "items_per_second": 4.1818012621269658e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.1104179200000000e+08,
      "advised_time": 1.2960767745971680e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.1104179200000000e+08,
      "workspace_megabytes": 3.9200000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 56,
      "real_time": 1.2562907417304814e+07,
      "cpu_time": 1.4819302178563833e+07,
      "time_unit": "ns",
      "items_per_second": 4.1879914918044834e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.1104179200000000e+08,
      "advised_time": 1.2937215805053711e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.1104179200000000e+08,
      "workspace_megabytes": 3.9200000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 23,
      "real_time": 2.9879073409930520e+07,
      "cpu_time": 4.2880354869517446e+07,
      "time_unit": "ns",
      "items_per_second": 1.7608762043642754e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.5636648960000000e+09,
      "advised_time": 3.0200832366943359e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.5636648960000000e+09,
      "workspace_megabytes": 4.3522500000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 23,
      "real_time": 2.9871638054433078e+07,
      "cpu_time": 4.2873197739125952e+07,
      "time_unit": "ns",
      "items_per_second": 1.7613145044180781e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.5636648960000000e+09,
      "advised_time": 3.0148607254028320e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.5636648960000000e+09,
      "workspace_megabytes": 4.3522500000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 23,
      "real_time": 2.9875867635659549e+07,
      "cpu_time": 4.2873779391218551e+07,
      "time_unit": "ns",
      "items_per_second": 1.7610651519021062e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.5636648960000000e+09,
      "advised_time": 3.0132223129272461e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.5608866559154586e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.5636648960000000e+09,
      "workspace_megabytes": 4.3522500000000000e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 30,
      "real_time": 2.3240806410710018e+07,
      "cpu_time": 3.0990930866710186e+07,
      "time_unit": "ns",
      "items_per_second": 2.2638349309494824e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5045241920000000e+09,
      "advised_time": 2.3455743789672852e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.0000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.5045241920000000e+09,
      "workspace_megabytes": 2.3885003967285156e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 30,
      "real_time": 2.3241967024902504e+07,
      "cpu_time": 3.0992876933366157e+07,
      "time_unit": "ns",
      "items_per_second": 2.2637218837642983e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5045241920000000e+09,
      "advised_time": 2.3442432403564453e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.0000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.5045241920000000e+09,
      "workspace_megabytes": 2.3885003967285156e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 30,
      "real_time": 2.3239918860296410e+07,
      "cpu_time": 3.0989896500038106e+07,
      "time_unit": "ns",
      "items_per_second": 2.2639213885503623e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5045241920000000e+09,
      "advised_time": 2.3440383911132812e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4482905588559884e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 3.0000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.5045241920000000e+09,
      "workspace_megabytes": 2.3885003967285156e+03
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__7735629738224702525<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 43,
      "real_time": 1.6463014708701955e+07,
      "cpu_time": 2.0304678069763657e+07,
      "time_unit": "ns",
      "items_per_second": 3.1958514468306855e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.5940608024597168e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 8.2208358400000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 43,
      "real_time": 1.6455465797768082e+07,
      "cpu_time": 2.0293203976761170e+07,
      "time_unit": "ns",
      "items_per_second": 3.1973175370785400e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.5931391716003418e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 3.7948729185673933e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 8.2208358400000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 43,
      "real_time": 1.6465610672914704e+07,
      "cpu_time": 2.0307776651184954e+07,
      "time_unit": "ns",
      "items_per_second": 3.1953475896613379e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.5921152114868164e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 8.2208358400000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 43,
      "real_time": 1.6461871651022933e+07,
      "cpu_time": 2.0300940813941386e+07,
      "time_unit": "ns",
      "items_per_second": 3.1960733561381299e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.5944704055786133e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4991874974232711e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 8.2208358400000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 43,
      "real_time": 1.6461680924823118e+07,
      "cpu_time": 2.0302936790686060e+07,
      "time_unit": "ns",
      "items_per_second": 3.1961103860701475e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.5941632270812988e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2315062669022114e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.3000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 8.2208358400000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 76,
      "real_time": 9.1663763588784561e+06,
      "cpu_time": 1.0384250815832274e+07,
      "time_unit": "ns",
      "items_per_second": 5.7398198935001465e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 9.1740159988403320e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 7.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 8.2208358400000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 76,
      "real_time": 9.1727769100352339e+06,
      "cpu_time": 1.0393788921030471e+07,
      "time_unit": "ns",
      "items_per_second": 5.7358147801937441e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 9.1668481826782227e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.3805875302202324e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 7.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 8.2208358400000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 76,
      "real_time": 9.1756059003895838e+06,
      "cpu_time": 1.0396675828976760e+07,
      "time_unit": "ns",
      "items_per_second": 5.7340463340700049e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 9.1658239364624023e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 7.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 8.2208358400000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 76,
      "real_time": 9.1730594071314521e+06,
      "cpu_time": 1.0393520750037504e+07,
      "time_unit": "ns",
      "items_per_second": 5.7356381378165469e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 9.1668481826782227e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 7.3632461532209244e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 7.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 8.2208358400000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 76,
      "real_time": 9.1740295266438480e+06,
      "cpu_time": 1.0394696039467914e+07,
      "time_unit": "ns",
      "items_per_second": 5.7350316154092041e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 9.1586561203002930e+00,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.1554158113550264e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 7.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 8.2208358400000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 46,
      "real_time": 1.5199320957712505e+07,
      "cpu_time": 1.8526353130433246e+07,
      "time_unit": "ns",
      "items_per_second": 3.4615592053342822e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.2208358400000000e+08,
      "advised_time": 1.5992832183837891e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 8.2208358400000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 8.2208358400000000e+08,
      "workspace_megabytes": 7.8400000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 46,
      "real_time": 1.5198786803723678e+07,
      "cpu_time": 1.8518722978253368e+07,
      "time_unit": "ns",
      "items_per_second": 3.4616808601532471e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.2208358400000000e+08,
      "advised_time": 1.5956992149353027e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 8.2208358400000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 8.2208358400000000e+08,
      "workspace_megabytes": 7.8400000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 46,
      "real_time": 1.5191908196910568e+07,
      "cpu_time": 1.8508108956528146e+07,
      "time_unit": "ns",
      "items_per_second": 3.4632482433444058e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.2208358400000000e+08,
      "advised_time": 1.5942655563354492e+01,
      "batch_size": 1.0240000000000000e+03,
      "benchmark_file:/home/ubuntu/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 4.7673584156587141e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4433935009319416e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.5.1": 1.5291830479059431e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Tesla V100-SXM2-16GB": 6.4152751867444204e+18,
      "group": 1.0000000000000000e+00,
      "host_name:ip-172-31-26-210": 1.4989209596316645e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0240000000000000e+03,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0552089600000000e+08,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.6000000000000000e+01,
      "output_batch_size": 1.0240000000000000e+03,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 8.2208358400000000e+08,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 8.2208358400000000e+08,
      "workspace_megabytes": 7.8400000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to perform cudnnFindConvolutionForwardAlgorithm",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to perform cudnnFindConvolutionForwardAlgorithm",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to perform cudnnFindConvolutionForwardAlgorithm",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_FLOAT32__BatchSize_1024__16655370936610630110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:1024/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:1024/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    }
  ]
}
